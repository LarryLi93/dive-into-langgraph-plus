{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05f4b436",
   "metadata": {},
   "source": [
    "# 内存知识智能体 (Agent RAG)\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea133d1f",
   "metadata": {},
   "source": [
    "本示例演示如何将 `files` 目录下的 txt 文件按空行分段，写入内存向量库，\n",
    "并通过 ReAct Agent 检索回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a765d8",
   "metadata": {},
   "source": [
    "## TXT数据示例\n",
    "\n",
    "问题:公司的考勤方式是什么？<br />\n",
    "答案:公司实行固定世界打卡。<br />\n",
    "\n",
    "问题:考勤有问题找谁？ <br />\n",
    "答案:找LarryLi。 <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b02fcaa",
   "metadata": {},
   "source": [
    "该文件由 TXT 数据示例组成，每个问题-答案-关键词三元组占一行，问题、答案、关键词之间用空格分隔。\n",
    "EXCEL可以转为同样的参考格式。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798439c9",
   "metadata": {},
   "source": [
    "引入依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78885cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "# 加载模型配置\n",
    "_ = load_dotenv()\n",
    "\n",
    "# 配置大模型\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"qwen3-coder-plus\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# 创建 OpenAI 客户端\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f712b89",
   "metadata": {},
   "source": [
    "配置嵌入模型和文本切割策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff1055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DashScopeEmbeddings(Embeddings):\n",
    "    \"\"\"DashScope 兼容的 Embeddings 封装。\"\"\"\n",
    "\n",
    "    def __init__(self, model: str = \"text-embedding-v4\", dimensions: int = 1024):\n",
    "        self.model = model\n",
    "        self.dimensions = dimensions\n",
    "\n",
    "    def embed_documents(self, texts: list[str]) -> list[list[float]]:\n",
    "        vectors: list[list[float]] = []\n",
    "        for i in range(0, len(texts), 10):\n",
    "            chunk = texts[i : i + 10]\n",
    "            response = client.embeddings.create(\n",
    "                model=self.model,\n",
    "                input=chunk,\n",
    "                dimensions=self.dimensions,\n",
    "            )\n",
    "            vectors.extend([item.embedding for item in response.data])\n",
    "        return vectors\n",
    "\n",
    "    def embed_query(self, text: str) -> list[float]:\n",
    "        response = client.embeddings.create(\n",
    "            model=self.model,\n",
    "            input=[text],\n",
    "            dimensions=self.dimensions,\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "\n",
    "\n",
    "def load_txt_documents(data_dir: Path) -> list[Document]:\n",
    "    \"\"\"读取目录下的 txt 文件并按空行分割为 Document。\"\"\"\n",
    "\n",
    "    def split_on_blank(text: str) -> Iterable[str]:\n",
    "        for block in re.split(r\"\\n\\s*\\n\", text):\n",
    "            cleaned = block.strip()\n",
    "            if cleaned:\n",
    "                yield cleaned\n",
    "\n",
    "    documents: list[Document] = []\n",
    "    for path in sorted(data_dir.glob(\"*.txt\")):\n",
    "        content = path.read_text(encoding=\"utf-8\")\n",
    "        for idx, part in enumerate(split_on_blank(content)):\n",
    "            documents.append(\n",
    "                Document(\n",
    "                    page_content=part,\n",
    "                    metadata={\"source\": path.name, \"chunk_id\": idx},\n",
    "                )\n",
    "            )\n",
    "    if not documents:\n",
    "        raise ValueError(f\"目录 {data_dir} 下未找到 txt 文档\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424f36fe",
   "metadata": {},
   "source": [
    "将TXT数据示例存入为向量库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b062a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vector_store(data_dir: Path | None = None) -> InMemoryVectorStore:\n",
    "    \"\"\"读取 txt 文件并构建内存向量库。\"\"\"\n",
    "    # 默认指向仓库根目录下的 files，而非 tests/files\n",
    "    target_dir = data_dir or (Path(__file__).parent.parent / \"files\")\n",
    "    documents = load_txt_documents(target_dir)\n",
    "\n",
    "    print(f\"成功加载 {len(documents)} 个文档到向量库\")\n",
    "\n",
    "    embeddings = DashScopeEmbeddings()\n",
    "    vector_store = InMemoryVectorStore(embedding=embeddings)\n",
    "    _ = vector_store.add_documents(documents)\n",
    "    \n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7d7a53",
   "metadata": {},
   "source": [
    "创建一个带有相似向量检索功能的智能体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e0458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_react_agent(vector_store: InMemoryVectorStore):\n",
    "    \"\"\"基于给定向量库创建带检索工具的 ReAct Agent。\"\"\"\n",
    "\n",
    "    @tool(response_format=\"content_and_artifact\")\n",
    "    def retrieve_context(query: str):\n",
    "        \"\"\"基于向量库检索与问题最相关的文本片段。\"\"\"\n",
    "        retrieved = vector_store.similarity_search(query, k=3)\n",
    "        serialized = \"\\n\\n\".join(\n",
    "            f\"[{doc.metadata['source']}#{doc.metadata['chunk_id']}] {doc.page_content}\"\n",
    "            for doc in retrieved\n",
    "        )\n",
    "        return serialized, retrieved\n",
    "\n",
    "    return create_agent(\n",
    "        llm,\n",
    "        tools=[retrieve_context],\n",
    "        system_prompt=(\n",
    "            \"你可以使用检索工具获得参考资料。回答时结合检索到的内容，\"\n",
    "            \"如有必要可以在答案中简单引用来源标识。\"\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c600e1e",
   "metadata": {},
   "source": [
    "运行智能体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac6c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_demo():\n",
    "    \"\"\"简单演示：针对 txt 知识库发起提问。\"\"\"\n",
    "    query = \"考勤缺卡怎么处理？\"\n",
    "\n",
    "    # 嵌入向量数据库\n",
    "    vector_store = build_vector_store()\n",
    "\n",
    "    print('嵌入完成' + '\\n')\n",
    "\n",
    "    # 检索向量数据库\n",
    "    agent = create_react_agent(vector_store)\n",
    "    for event in agent.stream({\"messages\": [{\"role\": \"user\", \"content\": query}]}, stream_mode=\"values\"):\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_demo()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
