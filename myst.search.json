{"version":"1","records":[{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹"},"type":"lvl1","url":"/introduce","position":0},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹"},"content":"","type":"content","url":"/introduce","position":1},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl2":"å¼•è¨€ï¼šä»â€œå¤§è„‘â€åˆ°â€œæ‰‹è„šâ€çš„è¿›åŒ–"},"type":"lvl2","url":"/introduce#id","position":2},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl2":"å¼•è¨€ï¼šä»â€œå¤§è„‘â€åˆ°â€œæ‰‹è„šâ€çš„è¿›åŒ–"},"content":"å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„çˆ†å‘è®©æˆ‘ä»¬è§è¯†äº† AI çš„â€œè„‘åŠ›â€ï¼Œä½†å…‰æœ‰å¤§è„‘æ˜¯ä¸å¤Ÿçš„ã€‚è¦è®© AI çœŸæ­£æ›¿æˆ‘ä»¬å¹²æ´»â€”â€”å†™ä»£ç ã€åšè°ƒç ”ã€è‡ªåŠ¨åŒ–åŠå…¬ï¼Œæˆ‘ä»¬éœ€è¦ç»™å®ƒè£…ä¸Šâ€œæ‰‹è„šâ€å’Œâ€œæ„Ÿå®˜â€ã€‚\n\nè¿™å°±æ˜¯ AI Agentï¼ˆæ™ºèƒ½ä½“ï¼‰ çš„æ ¸å¿ƒä½¿å‘½ã€‚\n\nç„¶è€Œï¼Œä»é›¶æ‰‹æ“ä¸€ä¸ª Agent æ—¢ç—›è‹¦åˆä½æ•ˆã€‚äºæ˜¯ï¼ŒAgent æ¡†æ¶å¦‚é›¨åæ˜¥ç¬‹èˆ¬æ¶Œç°ã€‚é¢å¯¹ LangChainã€AutoGPTã€MetaGPTã€CrewAI ç­‰ä¼—å¤šé€‰æ‹©ï¼Œå¼€å‘è€…è¯¥å¦‚ä½•æŠ‰æ‹©ï¼Ÿ\n\næœ¬æ–‡å°†æ·±å…¥å‰–æå½“å‰ä¸»æµçš„ AI Agent æ¡†æ¶ï¼Œå¯¹æ¯”å…¶ä¼˜åŠ£åŠ¿ï¼Œå¹¶æ¢è®¨å®ƒä»¬æœ€é€‚åˆçš„åº”ç”¨åœºæ™¯ã€‚","type":"content","url":"/introduce#id","position":3},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl2":"ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸»æµç©å®¶å…¥åœºâ€”â€”æ¡†æ¶ç‰¹ç‚¹è§£æ"},"type":"lvl2","url":"/introduce#id-1","position":4},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl2":"ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸»æµç©å®¶å…¥åœºâ€”â€”æ¡†æ¶ç‰¹ç‚¹è§£æ"},"content":"","type":"content","url":"/introduce#id-1","position":5},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"1. LangChain / LangGraphï¼šè¡Œä¸šçš„â€œç‘å£«å†›åˆ€â€","lvl2":"ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸»æµç©å®¶å…¥åœºâ€”â€”æ¡†æ¶ç‰¹ç‚¹è§£æ"},"type":"lvl3","url":"/introduce#id-1-langchain-langgraph","position":6},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"1. LangChain / LangGraphï¼šè¡Œä¸šçš„â€œç‘å£«å†›åˆ€â€","lvl2":"ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸»æµç©å®¶å…¥åœºâ€”â€”æ¡†æ¶ç‰¹ç‚¹è§£æ"},"content":"å®šä½ï¼šæœ€é€šç”¨çš„ LLM åº”ç”¨å¼€å‘æ¡†æ¶ï¼ŒAgent å¼€å‘çš„åŸºçŸ³ã€‚\n\næ ¸å¿ƒç‰¹ç‚¹ï¼š\n\nç»„ä»¶åŒ–ï¼šæä¾›äº† Prompt ç®¡ç†ã€è®°å¿†ï¼ˆMemoryï¼‰ã€ç´¢å¼•ï¼ˆIndexï¼‰å’Œé“¾ï¼ˆChainï¼‰çš„é«˜åº¦æŠ½è±¡ã€‚\n\nLangGraphï¼šLangChain æ¨å‡ºçš„æœ€æ–°åˆ©å™¨ï¼Œä¸“é—¨ç”¨äºæ„å»ºæœ‰çŠ¶æ€ã€å¤šè§’è‰²çš„ Agentã€‚å®ƒç”¨å›¾ï¼ˆGraphï¼‰çš„ç»“æ„æ¥æ§åˆ¶ Agent çš„å¾ªç¯é€»è¾‘ï¼Œè§£å†³äº†ä¼ ç»Ÿ Chain éš¾ä»¥å¤„ç†å¤æ‚å¾ªç¯ä»»åŠ¡çš„é—®é¢˜ã€‚\n\nç”Ÿæ€ä¸°å¯Œï¼šæ‹¥æœ‰æœ€å¤§çš„ç¤¾åŒºå’Œæœ€å¤šçš„é›†æˆï¼ˆIntegrationsï¼‰ã€‚\n\nä¼˜ç‚¹ï¼šæå…¶çµæ´»ï¼Œå‡ ä¹èƒ½æ„å»ºä»»ä½•ç±»å‹çš„åº”ç”¨ï¼›æ–‡æ¡£å’Œæ•™ç¨‹æœ€ä¸°å¯Œã€‚\n\nç¼ºç‚¹ï¼šå­¦ä¹ æ›²çº¿é™¡å³­ï¼Œå…¥é—¨éš¾åº¦é«˜ã€‚","type":"content","url":"/introduce#id-1-langchain-langgraph","position":7},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"2. AutoGPTï¼šå®Œå…¨è‡ªä¸»çš„â€œç‹¬è¡Œä¾ â€","lvl2":"ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸»æµç©å®¶å…¥åœºâ€”â€”æ¡†æ¶ç‰¹ç‚¹è§£æ"},"type":"lvl3","url":"/introduce#id-2-autogpt","position":8},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"2. AutoGPTï¼šå®Œå…¨è‡ªä¸»çš„â€œç‹¬è¡Œä¾ â€","lvl2":"ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸»æµç©å®¶å…¥åœºâ€”â€”æ¡†æ¶ç‰¹ç‚¹è§£æ"},"content":"å®šä½ï¼šæ¢ç´¢é€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰é›å½¢çš„å®éªŒæ€§é¡¹ç›®ã€‚\n\næ ¸å¿ƒç‰¹ç‚¹ï¼š\n\nç›®æ ‡å¯¼å‘ï¼šä½ åªéœ€ç»™å®ƒä¸€ä¸ªæœ€ç»ˆç›®æ ‡ï¼ˆä¾‹å¦‚â€œå¸®æˆ‘è°ƒç ”å¹¶å°†ç»“æœå­˜ä¸ºæ–‡ä»¶â€ï¼‰ï¼Œå®ƒä¼šè‡ªåŠ¨æ‹†è§£ä»»åŠ¡ã€æ‰§è¡Œã€åæ€ã€çº é”™ï¼Œç›´åˆ°å®Œæˆã€‚\n\nè‡ªä¸»å¾ªç¯ï¼šä¸éœ€è¦äººç±»å¹²é¢„æ¯ä¸€æ­¥ï¼Œå®ƒè‡ªå·±ä¼šè¿›è¡Œâ€œæ€è€ƒ-è¡ŒåŠ¨-è§‚å¯Ÿâ€çš„å¾ªç¯ã€‚\n\nä¼˜ç‚¹ï¼šå±•ç¤ºäº† AI çš„æé™è‡ªä¸»èƒ½åŠ›ï¼Œæ¦‚å¿µéªŒè¯ï¼ˆPoCï¼‰çš„ç¥å™¨ã€‚\n\nç¼ºç‚¹ï¼šåœ¨å¤æ‚ä»»åŠ¡ä¸­å®¹æ˜“é™·å…¥æ­»å¾ªç¯ï¼ˆLoopï¼‰ï¼›Token æ¶ˆè€—å·¨å¤§ï¼›ä¸å¯æ§æ€§è¾ƒå¼ºï¼Œéš¾ä»¥ç”¨äºä¸¥è‚ƒçš„ç”Ÿäº§ç¯å¢ƒã€‚","type":"content","url":"/introduce#id-2-autogpt","position":9},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"3. MetaGPTï¼šæŠŠ AI å˜æˆâ€œè½¯ä»¶å…¬å¸â€","lvl2":"ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸»æµç©å®¶å…¥åœºâ€”â€”æ¡†æ¶ç‰¹ç‚¹è§£æ"},"type":"lvl3","url":"/introduce#id-3-metagpt-ai","position":10},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"3. MetaGPTï¼šæŠŠ AI å˜æˆâ€œè½¯ä»¶å…¬å¸â€","lvl2":"ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸»æµç©å®¶å…¥åœºâ€”â€”æ¡†æ¶ç‰¹ç‚¹è§£æ"},"content":"å®šä½ï¼šå¤šæ™ºèƒ½ä½“åä½œæ¡†æ¶ï¼Œå¼•å…¥äº† SOPï¼ˆæ ‡å‡†ä½œä¸šç¨‹åºï¼‰ã€‚\n\næ ¸å¿ƒç‰¹ç‚¹ï¼š\n\nè§’è‰²æ‰®æ¼”ï¼šå®ƒä¸ä»…ä»…æ˜¯ä¸€ä¸ª Agentï¼Œè€Œæ˜¯ä¸€ä¸ªå›¢é˜Ÿã€‚å®ƒå†…éƒ¨é¢„è®¾äº†äº§å“ç»ç†ã€æ¶æ„å¸ˆã€å·¥ç¨‹å¸ˆç­‰è§’è‰²ã€‚\n\nSOP çº¦æŸï¼šå®ƒå°†ç°å®ä¸–ç•Œçš„æ ‡å‡†åŒ–å·¥ä½œæµï¼ˆSOPï¼‰ç¼–ç è¿› Promptï¼Œè®© Agent æŒ‰ç…§è§„èŒƒè¾“å‡ºï¼ˆä¾‹å¦‚ï¼šå…ˆå†™éœ€æ±‚æ–‡æ¡£ï¼Œå†å†™è®¾è®¡å›¾ï¼Œæœ€åå†™ä»£ç ï¼‰ã€‚\n\nä¼˜ç‚¹ï¼šåœ¨è½¯ä»¶å¼€å‘ã€ä»£ç ç”Ÿæˆé¢†åŸŸè¡¨ç°æä½³ï¼›è¾“å‡ºç»“æœéå¸¸ç¨³å®šã€ç»“æ„åŒ–ã€‚\n\nç¼ºç‚¹ï¼šå¯¹äºéæµç¨‹åŒ–ã€éæ ‡å‡†åŒ–çš„åˆ›æ„ä»»åŠ¡ï¼ŒSOP æœºåˆ¶å¯èƒ½æ˜¾å¾—è¿‡äºåƒµåŒ–ã€‚","type":"content","url":"/introduce#id-3-metagpt-ai","position":11},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"4. CrewAIï¼šè½»é‡çº§çš„â€œå›¢é˜ŸæŒ‡æŒ¥å®˜â€","lvl2":"ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸»æµç©å®¶å…¥åœºâ€”â€”æ¡†æ¶ç‰¹ç‚¹è§£æ"},"type":"lvl3","url":"/introduce#id-4-crewai","position":12},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"4. CrewAIï¼šè½»é‡çº§çš„â€œå›¢é˜ŸæŒ‡æŒ¥å®˜â€","lvl2":"ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸»æµç©å®¶å…¥åœºâ€”â€”æ¡†æ¶ç‰¹ç‚¹è§£æ"},"content":"å®šä½ï¼šåŸºäº LangChain æ„å»ºçš„ã€æ˜“äºä¸Šæ‰‹çš„å¤šæ™ºèƒ½ä½“ç¼–æ’æ¡†æ¶ã€‚\n\næ ¸å¿ƒç‰¹ç‚¹ï¼š\n\nè§’è‰²ï¼ˆRoleï¼‰ä¸ä»»åŠ¡ï¼ˆTaskï¼‰ï¼šæ ¸å¿ƒé€»è¾‘éå¸¸ç›´è§‚â€”â€”å®šä¹‰å‡ ä¸ªè§’è‰²ï¼ˆå¦‚â€œç ”ç©¶å‘˜â€ã€â€œå†™æ‰‹â€ï¼‰ï¼Œåˆ†é…ä»»åŠ¡ï¼Œç„¶åè®©ä»–ä»¬æŒ‰é¡ºåºæˆ–å±‚çº§åä½œã€‚\n\nProcess ç®¡ç†ï¼šæ”¯æŒé¡ºåºæ‰§è¡Œæˆ–å±‚çº§æµç¨‹ï¼ˆHierarchicalï¼‰ï¼Œå…è®¸ç®¡ç†è€… Agent å§”æ´¾ä»»åŠ¡ã€‚\n\nä¼˜ç‚¹ï¼šAPI è®¾è®¡æå…¶äººæ€§åŒ–ï¼Œä¸Šæ‰‹æå¿«ï¼›å®Œç¾å…¼å®¹ LangChain çš„å·¥å…·åº“ï¼›éå¸¸é€‚åˆå†…å®¹åˆ›ä½œã€å¸‚åœºè°ƒç ”ç­‰åä½œåœºæ™¯ã€‚\n\nç¼ºç‚¹ï¼šç›¸æ¯” LangGraphï¼Œåœ¨å¤„ç†æåº¦å¤æ‚çš„è‡ªå®šä¹‰é€»è¾‘æ—¶ï¼Œçµæ´»æ€§ç¨å¼±ã€‚","type":"content","url":"/introduce#id-4-crewai","position":13},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"5. Microsoft Semantic Kernelï¼šä¼ä¸šçº§çš„â€œåŠ¡å®æ´¾â€","lvl2":"ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸»æµç©å®¶å…¥åœºâ€”â€”æ¡†æ¶ç‰¹ç‚¹è§£æ"},"type":"lvl3","url":"/introduce#id-5-microsoft-semantic-kernel","position":14},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"5. Microsoft Semantic Kernelï¼šä¼ä¸šçº§çš„â€œåŠ¡å®æ´¾â€","lvl2":"ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸»æµç©å®¶å…¥åœºâ€”â€”æ¡†æ¶ç‰¹ç‚¹è§£æ"},"content":"å®šä½ï¼šå¾®è½¯æ¨å‡ºçš„è½»é‡çº§ SDKï¼Œæ—¨åœ¨å°† LLM ä¸ç°æœ‰ç¼–ç¨‹è¯­è¨€ï¼ˆC#, Pythonï¼‰æ·±åº¦èåˆã€‚\n\næ ¸å¿ƒç‰¹ç‚¹ï¼š\n\næ’ä»¶ï¼ˆPluginï¼‰æ¶æ„ï¼šå¼ºè°ƒå°†ç°æœ‰çš„ä¸šåŠ¡ä»£ç å°è£…æˆâ€œæŠ€èƒ½â€æˆ–â€œæ’ä»¶â€ä¾› AI è°ƒç”¨ã€‚\n\nè§„åˆ’å™¨ï¼ˆPlannerï¼‰ï¼šè‡ªåŠ¨å°†ç”¨æˆ·æ„å›¾è½¬åŒ–ä¸ºä¸€ç³»åˆ—æ’ä»¶è°ƒç”¨çš„æ­¥éª¤ã€‚\n\nä¼˜ç‚¹ï¼šä¼ä¸šçº§ç¨³å®šæ€§ï¼Œä¸å¾®è½¯ç”Ÿæ€ï¼ˆAzure OpenAIï¼‰ç»“åˆç´§å¯†ï¼›è½»é‡ï¼Œä¸å¼ºè¡Œæ”¹å˜å¼€å‘è€…çš„ç¼–ç ä¹ æƒ¯ã€‚\n\nç¼ºç‚¹ï¼šç¤¾åŒºçƒ­åº¦ä¸å¦‚ LangChainï¼ŒPython ç‰ˆæœ¬çš„åŠŸèƒ½è¿­ä»£æœ‰æ—¶è½åäº C# ç‰ˆæœ¬ã€‚","type":"content","url":"/introduce#id-5-microsoft-semantic-kernel","position":15},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl2":"ç¬¬äºŒéƒ¨åˆ†ï¼šæ¡†æ¶æ¨ªå‘å¯¹æ¯”"},"type":"lvl2","url":"/introduce#id-2","position":16},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl2":"ç¬¬äºŒéƒ¨åˆ†ï¼šæ¡†æ¶æ¨ªå‘å¯¹æ¯”"},"content":"ç‰¹æ€§ç»´åº¦\n\nLangChain (LangGraph)\n\nAutoGPT\n\nMetaGPT\n\nCrewAI\n\nSemantic Kernel\n\nä¸Šæ‰‹éš¾åº¦\n\nâ­â­â­â­ (è¾ƒéš¾)\n\nâ­ (ç®€å•)\n\nâ­â­ (ä¸­ç­‰)\n\nâ­ (ç®€å•)\n\nâ­â­ (ä¸­ç­‰)\n\nçµæ´»åº¦/å®šåˆ¶åŒ–\n\nâ­â­â­â­â­ (æé«˜)\n\nâ­â­\n\nâ­â­â­\n\nâ­â­â­\n\nâ­â­â­â­\n\nå¤šæ™ºèƒ½ä½“åä½œ\n\nå¼º (éœ€è‡ªå»ºé€»è¾‘)\n\nå¼± (å•ä½“ä¸ºä¸»)\n\næå¼º (SOPæµç¨‹)\n\næå¼º (è§’è‰²æ‰®æ¼”)\n\nä¸­ (éœ€è‡ªå»º)\n\nç”Ÿäº§ç¯å¢ƒå°±ç»ª\n\næ˜¯\n\nå¦\n\næ˜¯ (ç‰¹å®šé¢†åŸŸ)\n\næ˜¯\n\næ˜¯\n\næ ¸å¿ƒä¼˜åŠ¿\n\nç”Ÿæ€ç»Ÿæ²»åŠ›ï¼Œåº•å±‚æ§åˆ¶\n\nå…¨è‡ªåŠ¨ï¼Œæ¦‚å¿µè¶…å‰\n\nè½¯ä»¶å·¥ç¨‹ï¼Œç»“æ„åŒ–è¾“å‡º\n\nå›¢é˜Ÿåä½œï¼Œæ˜“ç”¨æ€§\n\nä¼ä¸šé›†æˆï¼Œè½»é‡","type":"content","url":"/introduce#id-2","position":17},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl2":"ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®æˆ˜è½åœ°â€”â€”ä»€ä¹ˆåœºæ™¯é€‰ä»€ä¹ˆï¼Ÿ"},"type":"lvl2","url":"/introduce#id-3","position":18},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl2":"ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®æˆ˜è½åœ°â€”â€”ä»€ä¹ˆåœºæ™¯é€‰ä»€ä¹ˆï¼Ÿ"},"content":"","type":"content","url":"/introduce#id-3","position":19},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"åœºæ™¯ Aï¼šå¤æ‚çš„ä¼ä¸šçº§ RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç³»ç»Ÿ","lvl2":"ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®æˆ˜è½åœ°â€”â€”ä»€ä¹ˆåœºæ™¯é€‰ä»€ä¹ˆï¼Ÿ"},"type":"lvl3","url":"/introduce#id-a-rag","position":20},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"åœºæ™¯ Aï¼šå¤æ‚çš„ä¼ä¸šçº§ RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç³»ç»Ÿ","lvl2":"ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®æˆ˜è½åœ°â€”â€”ä»€ä¹ˆåœºæ™¯é€‰ä»€ä¹ˆï¼Ÿ"},"content":"æ¨èï¼šLangChain / LangGraph\n\nç†ç”±ï¼šä½ éœ€è¦ç²¾ç»†æ§åˆ¶æ£€ç´¢ç­–ç•¥ã€é‡æ’åºï¼ˆRerankï¼‰ã€ä»¥åŠæ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€è°ƒæ•´æŸ¥è¯¢è·¯å¾„ã€‚LangGraph çš„å›¾ç»“æ„éå¸¸é€‚åˆå¤„ç†è¿™ç§å¤æ‚çš„é€»è¾‘è·³è½¬ã€‚","type":"content","url":"/introduce#id-a-rag","position":21},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"åœºæ™¯ Bï¼šå…¨è‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªè´ªåƒè›‡æ¸¸æˆæˆ–å°å‹ App","lvl2":"ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®æˆ˜è½åœ°â€”â€”ä»€ä¹ˆåœºæ™¯é€‰ä»€ä¹ˆï¼Ÿ"},"type":"lvl3","url":"/introduce#id-b-app","position":22},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"åœºæ™¯ Bï¼šå…¨è‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªè´ªåƒè›‡æ¸¸æˆæˆ–å°å‹ App","lvl2":"ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®æˆ˜è½åœ°â€”â€”ä»€ä¹ˆåœºæ™¯é€‰ä»€ä¹ˆï¼Ÿ"},"content":"æ¨èï¼šMetaGPT\n\nç†ç”±ï¼šMetaGPT å†…éƒ¨çš„äº§å“ç»ç†å’Œæ¶æ„å¸ˆè§’è‰²ä¼šå¸®ä½ å†™å¥½ PRD å’Œè®¾è®¡æ–‡æ¡£ï¼Œç”Ÿæˆçš„ä»£ç è´¨é‡è¿œé«˜äºè®©å•ä¸ª LLM ç›´æ¥å†™ä»£ç ã€‚","type":"content","url":"/introduce#id-b-app","position":23},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"åœºæ™¯ Cï¼šè‡ªåŠ¨åŒ–è¿è¥å›¢é˜Ÿï¼ˆæœé›†æ–°é—» -> æ’°å†™æ¨æ–‡ -> å‘å¸ƒï¼‰","lvl2":"ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®æˆ˜è½åœ°â€”â€”ä»€ä¹ˆåœºæ™¯é€‰ä»€ä¹ˆï¼Ÿ"},"type":"lvl3","url":"/introduce#id-c","position":24},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"åœºæ™¯ Cï¼šè‡ªåŠ¨åŒ–è¿è¥å›¢é˜Ÿï¼ˆæœé›†æ–°é—» -> æ’°å†™æ¨æ–‡ -> å‘å¸ƒï¼‰","lvl2":"ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®æˆ˜è½åœ°â€”â€”ä»€ä¹ˆåœºæ™¯é€‰ä»€ä¹ˆï¼Ÿ"},"content":"æ¨èï¼šCrewAI\n\nç†ç”±ï¼šä½ å¯ä»¥å®šä¹‰ä¸€ä¸ªâ€œä¿¡æ¯æœé›†å‘˜â€Agent å’Œä¸€ä¸ªâ€œæ–‡æ¡ˆæ’°å†™å‘˜â€Agentã€‚CrewAI èƒ½éå¸¸é¡ºç•…åœ°æŠŠæœé›†å‘˜çš„ç»“æœä¼ é€’ç»™æ’°å†™å‘˜ï¼Œä»£ç å†™èµ·æ¥å°±åƒåˆ†é…ä»»åŠ¡ä¸€æ ·è‡ªç„¶ã€‚","type":"content","url":"/introduce#id-c","position":25},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"åœºæ™¯ Dï¼šå°† AI èƒ½åŠ›é›†æˆåˆ°ç°æœ‰çš„ .NET/Java/Python ä¸šåŠ¡ç³»ç»Ÿä¸­","lvl2":"ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®æˆ˜è½åœ°â€”â€”ä»€ä¹ˆåœºæ™¯é€‰ä»€ä¹ˆï¼Ÿ"},"type":"lvl3","url":"/introduce#id-d-ai-net-java-python","position":26},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"åœºæ™¯ Dï¼šå°† AI èƒ½åŠ›é›†æˆåˆ°ç°æœ‰çš„ .NET/Java/Python ä¸šåŠ¡ç³»ç»Ÿä¸­","lvl2":"ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®æˆ˜è½åœ°â€”â€”ä»€ä¹ˆåœºæ™¯é€‰ä»€ä¹ˆï¼Ÿ"},"content":"æ¨èï¼šSemantic Kernel\n\nç†ç”±ï¼šå¦‚æœä½ å·²ç»æœ‰æˆç†Ÿçš„åç«¯ç³»ç»Ÿï¼Œä¸éœ€è¦é‡æ„ï¼Œåªéœ€ç”¨ Semantic Kernel æŠŠç°æœ‰ API åŒ…è£…æˆ Pluginï¼Œå°±èƒ½è®© AI æŒ‡æŒ¥ç°æœ‰ä¸šåŠ¡é€»è¾‘ã€‚","type":"content","url":"/introduce#id-d-ai-net-java-python","position":27},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"åœºæ™¯ Eï¼šçº¯æ¢ç´¢ï¼Œæƒ³çœ‹çœ‹ AI è‡ªå·±èƒ½æŠ˜è…¾å‡ºä»€ä¹ˆ","lvl2":"ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®æˆ˜è½åœ°â€”â€”ä»€ä¹ˆåœºæ™¯é€‰ä»€ä¹ˆï¼Ÿ"},"type":"lvl3","url":"/introduce#id-e-ai","position":28},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl3":"åœºæ™¯ Eï¼šçº¯æ¢ç´¢ï¼Œæƒ³çœ‹çœ‹ AI è‡ªå·±èƒ½æŠ˜è…¾å‡ºä»€ä¹ˆ","lvl2":"ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®æˆ˜è½åœ°â€”â€”ä»€ä¹ˆåœºæ™¯é€‰ä»€ä¹ˆï¼Ÿ"},"content":"æ¨èï¼šAutoGPT\n\nç†ç”±ï¼šä¸ä»…å¥½ç©ï¼Œè€Œä¸”èƒ½è®©ä½ ç›´è§‚æ„Ÿå—åˆ° AI è‡ªä¸»å†³ç­–æ—¶çš„â€œæ€è€ƒè·¯å¾„â€å’Œæ½œåœ¨é£é™©ã€‚","type":"content","url":"/introduce#id-e-ai","position":29},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl2":"ç»“è¯­ï¼šæ²¡æœ‰æœ€å¥½çš„æ¡†æ¶ï¼Œåªæœ‰æœ€åˆé€‚çš„å·¥å…·"},"type":"lvl2","url":"/introduce#id-4","position":30},{"hierarchy":{"lvl1":"AIæ¡†æ¶ç®€ä»‹","lvl2":"ç»“è¯­ï¼šæ²¡æœ‰æœ€å¥½çš„æ¡†æ¶ï¼Œåªæœ‰æœ€åˆé€‚çš„å·¥å…·"},"content":"AI Agent é¢†åŸŸçš„å‘å±•é€Ÿåº¦æ˜¯æŒ‰â€œå‘¨â€è®¡ç®—çš„ã€‚\n\nå¦‚æœä½ æ˜¯åº•å±‚æå®¢ï¼Œæƒ³æŒæ§ä¸€åˆ‡ï¼Œé€‰ LangChain/LangGraphã€‚\n\nå¦‚æœä½ æ˜¯åº”ç”¨å¼€å‘è€…ï¼Œæƒ³å¿«é€Ÿæ­å»ºå¤š Agent å›¢é˜Ÿï¼ŒCrewAI æ˜¯é¦–é€‰ã€‚\n\nå¦‚æœä½ ä¸“æ³¨ä»£ç å·¥ç¨‹ï¼ŒMetaGPT ä¸å¯é”™è¿‡ã€‚\n\nå¦‚æœä½ èº«å¤„ä¼ ç»Ÿå¤§å‚ï¼ŒSemantic Kernel æœ€ç¨³å¥ã€‚\n\næœªæ¥çš„ AI å¼€å‘ï¼Œå¤§æ¦‚ç‡ä¸æ˜¯å•ä¸€æ¡†æ¶çš„å¤©ä¸‹ï¼Œè€Œæ˜¯å¤šæ¡†æ¶çš„èåˆã€‚\nåœ¨è¿™ä¸ªæ™ºèƒ½ä½“çˆ†å‘çš„å‰å¤œï¼Œé€‰å®šä¸€æŠŠè¶æ‰‹çš„å…µå™¨ï¼Œå¼€å§‹æ„å»ºä½ çš„æ•°å­—å‘˜å·¥å§ï¼","type":"content","url":"/introduce#id-4","position":31},{"hierarchy":{"lvl1":"å¿«é€Ÿå…¥é—¨"},"type":"lvl1","url":"/quickstart","position":0},{"hierarchy":{"lvl1":"å¿«é€Ÿå…¥é—¨"},"content":"ReAct Agent æ˜¯ä¸€ç§å°† æ¨ç†ï¼ˆReasoningï¼‰ä¸ è¡ŒåŠ¨ï¼ˆActingï¼‰ç»“åˆèµ·æ¥çš„æ™ºèƒ½ä½“ã€‚å®ƒæ˜¯æ™ºèƒ½ä½“çš„æ ¸å¿ƒç§‘æŠ€ï¼Œä¹Ÿæ˜¯æ™ºèƒ½ä½“æ¡†æ¶ä¸­æœ€èƒ½è¡¨ç°å…¶è‡ªä¸»æ€§çš„ç»„ä»¶ã€‚\n\nå®ƒçš„å·¥ä½œæµç¨‹éµå¾ªä¸‰æ­¥å¾ªç¯ï¼š\n\næ€è€ƒ\n\nè¡ŒåŠ¨\n\nè§‚å¯Ÿ\n\nè¿™ä¸ªå¾ªç¯ä¼šæŒç»­è¿›è¡Œï¼Œç›´åˆ° LLM åˆ¤æ–­ä»»åŠ¡å·²ç»å®Œæˆæˆ–æ— æ³•ç»§ç»­ã€‚\n\nè¿™ç§å¾ªç¯æ„å‘³ç€æ™ºèƒ½ä½“å¯ä»¥é€šè¿‡å·¥å…·è°ƒç”¨ï¼Œè‡ªåŠ¨è¡¥è¶³å½“å‰æœªçŸ¥çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ç„¶ååŸºäºæ–°è·å–çš„ä¿¡æ¯ï¼Œåšå‡ºä¸‹ä¸€æ­¥å†³ç­–ã€‚æ¯”å¦‚ä½ è¦æ™ºèƒ½ä½“æŸ¥è¯¢ä¸€ä¸ªæ•°æ®è¡¨ä¸­çš„è®°å½•ï¼Œå®ƒå¯èƒ½å°šä¸çŸ¥é“æ•°æ®åº“ä¸­æœ‰å“ªäº›è¡¨ï¼Œè¡¨ä¸­æœ‰å“ªäº›å­—æ®µã€‚ä½†æ˜¯é€šè¿‡å‡ è½®çš„ä¸»åŠ¨æŸ¥è¯¢ä¸è§‚å¯Ÿï¼Œå³ä½¿ä½ è¯¢é—®çš„ä¿¡æ¯æ¯”è¾ƒæ¨¡ç³Šï¼Œå®ƒå¤§æ¦‚ç‡ä¹Ÿèƒ½ä»è¡¨åå’Œå­—æ®µåä¸­æ¨æµ‹å‡ºä½ éœ€è¦çš„è®°å½•æ˜¯å“ªä¸€æ¡ã€‚è¿™å°±æ˜¯ ReAct Agent çš„å¨åŠ›ã€‚\n\næœ¬èŠ‚å°†ä»‹ç»ï¼š\n\nå¦‚ä½•åˆ›å»ºç®€å•çš„ ReAct Agent\n\nå¦‚ä½•åˆ›å»ºå¸¦å·¥å…·çš„ ReAct Agent\n\nå¦‚ä½•åˆ›å»ºå¸¦å·¥å…·æƒé™çš„ ReAct Agent\n\nç»“æ„åŒ–è¾“å‡º\n\næµå¼è¾“å‡º","type":"content","url":"/quickstart","position":1},{"hierarchy":{"lvl1":"å¿«é€Ÿå…¥é—¨","lvl2":"ä¸€ã€ç¯å¢ƒé…ç½®"},"type":"lvl2","url":"/quickstart#id","position":2},{"hierarchy":{"lvl1":"å¿«é€Ÿå…¥é—¨","lvl2":"ä¸€ã€ç¯å¢ƒé…ç½®"},"content":"1ï¼‰å®‰è£…ä¾èµ–\n\nä½ å¯ä»¥ä¸‹è½½ \n\næœ¬ä»“åº“ åˆ°æœ¬åœ°ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œå®‰è£…å®Œæ•´çš„ Python ä¾èµ–ï¼šcd dive-into-langgraph\npip install -r requirements.txt\n\nä¾èµ–åŒ…åˆ—è¡¨\n\nä»¥ä¸‹ä¸º requirements.txt ä¸­çš„ä¾èµ–åŒ…æ¸…å•ï¼špydantic\npython-dotenv\nlangchain[openai]\nlangchain-community\nlangchain-mcp-adapters\nlangchain-text-splitters\nlanggraph\nlanggraph-cli[inmem]\nlanggraph-supervisor\nlanggraph-checkpoint-sqlite\nlangmem\nipynbname\nfastmcp\nbs4\n\næˆ–è€…ï¼Œä½ ä¹Ÿå¯ä»¥ç›´æ¥å®‰è£… LangGraphï¼Œé‡åˆ°ç¼ºå°‘çš„ä¾èµ–å†è¡Œå®‰è£…ï¼špip install langgraph langchain\n\n2ï¼‰å¯¼å…¥ä¾èµ–\n\nä½¿ç”¨ .env.example åˆ›å»º .env æ–‡ä»¶:cp .env.example .env\n\nPS: æœ¬æ•™ç¨‹ä½¿ç”¨é˜¿é‡Œç™¾ç‚¼å¹³å°çš„æ¨¡å‹ã€‚ä½ éœ€è¦åœ¨ \n\né˜¿é‡Œç™¾ç‚¼å¹³å° æ³¨å†Œè´¦å·ï¼Œå¹¶å°†è·å¾—çš„ API å¯†é’¥å¡«å…¥ .env æ–‡ä»¶ä¸­çš„ DASHSCOPE_API_KEY å˜é‡ã€‚\n\nimport os\nfrom dotenv import load_dotenv\nfrom langchain_openai import ChatOpenAI\nfrom langchain.agents import create_agent\n\n# åŠ è½½æ¨¡å‹é…ç½®\n# è¯·äº‹å…ˆåœ¨ .env ä¸­é…ç½® DASHSCOPE_API_KEY\n_ = load_dotenv()\n\n\n\n","type":"content","url":"/quickstart#id","position":3},{"hierarchy":{"lvl1":"å¿«é€Ÿå…¥é—¨","lvl2":"äºŒã€ç®€å•çš„ Agent"},"type":"lvl2","url":"/quickstart#id-agent","position":4},{"hierarchy":{"lvl1":"å¿«é€Ÿå…¥é—¨","lvl2":"äºŒã€ç®€å•çš„ Agent"},"content":"é¦–å…ˆï¼Œåˆ›å»ºä¸€ä¸ªæœ€ç®€å•çš„ ReAct Agentã€‚\n\n# é…ç½®å¤§æ¨¡å‹æœåŠ¡\nllm = ChatOpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n    model=\"qwen3-coder-plus\",\n)\n\n# åˆ›å»ºä¸€ä¸ªç®€å•çš„Agent\nagent = create_agent(\n    model=llm,\n    system_prompt=\"You are a helpful assistant\",\n)\n\n# è¿è¡ŒAgent\nresponse = agent.invoke({'messages': 'ä½ å¥½'})\n\nresponse['messages'][-1].content\n\n\n\n# å¯è§†åŒ– Agent\nagent\n\n\n\n","type":"content","url":"/quickstart#id-agent","position":5},{"hierarchy":{"lvl1":"å¿«é€Ÿå…¥é—¨","lvl2":"ä¸‰ã€å¸¦å·¥å…·è°ƒç”¨çš„ Agent"},"type":"lvl2","url":"/quickstart#id-agent-1","position":6},{"hierarchy":{"lvl1":"å¿«é€Ÿå…¥é—¨","lvl2":"ä¸‰ã€å¸¦å·¥å…·è°ƒç”¨çš„ Agent"},"content":"æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå¸¦å·¥å…·è°ƒç”¨çš„ ReAct Agentï¼Œå®ƒä¼šæ ¹æ®éœ€æ±‚è‡ªä¸»å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·ã€‚\n\n# ä¸€ä¸ªå·¥å…·å‡½æ•°\ndef get_weather(city: str) -> str:\n    \"\"\"Get weather for a given city.\"\"\"\n    return f\"It's always sunny in {city}!\"\n\n# åˆ›å»ºå¸¦å·¥å…·è°ƒç”¨çš„Agent\ntool_agent = create_agent(\n    model=llm,\n    tools=[get_weather],\n    system_prompt=\"You are a helpful assistant\",\n)\n\n# è¿è¡ŒAgent\nresponse = tool_agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n)\n\nresponse['messages'][-1].content\n\n\n\n# å¯è§†åŒ– Agent\ntool_agent\n\n\n\n","type":"content","url":"/quickstart#id-agent-1","position":7},{"hierarchy":{"lvl1":"å¿«é€Ÿå…¥é—¨","lvl2":"å››ã€ä½¿ç”¨ ToolRuntime æ§åˆ¶å·¥å…·æƒé™"},"type":"lvl2","url":"/quickstart#id-toolruntime","position":8},{"hierarchy":{"lvl1":"å¿«é€Ÿå…¥é—¨","lvl2":"å››ã€ä½¿ç”¨ ToolRuntime æ§åˆ¶å·¥å…·æƒé™"},"content":"ä¸‹é¢åˆ›å»ºä¸€ä¸ªå¸¦ runtime çš„å·¥å…·ï¼Œruntime ç±»å‹ä¸º ToolRuntimeã€‚å½“æˆ‘ä»¬è°ƒç”¨ Agent æ—¶ï¼Œä¼šå°†è¿™ä¸ª runtime é€šè¿‡ context å‚æ•°ä¼ é€’ç»™å·¥å…·ã€‚å·¥å…·å†æ ¹æ® runtime ä¸­çš„ä¿¡æ¯ï¼Œåˆ¤æ–­å½“å‰è°ƒç”¨æ˜¯å¦å…·å¤‡æ‰§è¡Œæƒé™ã€‚\n\nfrom typing import Literal, Any\nfrom pydantic import BaseModel\nfrom langchain.tools import tool, ToolRuntime\n\nclass Context(BaseModel):\n    authority: Literal[\"admin\", \"user\"]\n\n# åˆ›å»ºå¸¦æƒé™æ§åˆ¶çš„toolï¼Œä¾èµ–ToolRuntimeçš„å†…å®¹è¿›è¡Œåˆ¤æ–­\n@tool\ndef math_add(runtime: ToolRuntime[Context, Any], a: int, b: int) -> int:\n    \"\"\"Add two numbers together.\"\"\"\n    authority = runtime.context.authority\n    # åªæœ‰adminç”¨æˆ·å¯ä»¥è®¿é—®åŠ æ³•å·¥å…·\n    if authority != \"admin\":\n        raise PermissionError(\"User does not have permission to add numbers\")\n    return a + b\n\n# åˆ›å»ºå¸¦å·¥å…·è°ƒç”¨çš„Agent\ntool_agent = create_agent(\n    model=llm,\n    tools=[get_weather, math_add],\n    system_prompt=\"You are a helpful assistant\",\n)\n\n# åœ¨è¿è¡ŒAgentæ—¶æ³¨å…¥context\nresponse = tool_agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"è¯·è®¡ç®— 8234783 + 94123832 = ?\"}]},\n    config={\"configurable\": {\"thread_id\": \"1\"}},\n    context=Context(authority=\"admin\"),\n)\n\n\n\nfor message in response['messages']:\n    message.pretty_print()\n\n\n\n# éªŒè¯è®¡ç®—ç»“æœæ˜¯å¦æ­£ç¡®\n8234783 + 94123832\n\n\n\n","type":"content","url":"/quickstart#id-toolruntime","position":9},{"hierarchy":{"lvl1":"å¿«é€Ÿå…¥é—¨","lvl2":"äº”ã€ç»“æ„åŒ–è¾“å‡º"},"type":"lvl2","url":"/quickstart#id-1","position":10},{"hierarchy":{"lvl1":"å¿«é€Ÿå…¥é—¨","lvl2":"äº”ã€ç»“æ„åŒ–è¾“å‡º"},"content":"è‹¥æƒ³è·å¾—ç»“æ„åŒ–è¾“å‡ºï¼ˆStructured Outputï¼‰ï¼Œå¯ä»¥åœ¨ create_agent å‡½æ•°çš„ response_format å‚æ•°è¿›è¡Œè®¾å®šã€‚åœ¨ä¸‹é¢è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ç”¨ BaseModel å®šä¹‰è¾“å‡ºæ ¼å¼ï¼Œç„¶ååœ¨ response_format ä¸­æŒ‡å®šè¯¥æ ¼å¼ã€‚\n\nfrom pydantic import BaseModel, Field\n\nclass CalcInfo(BaseModel):\n    \"\"\"Calculation information.\"\"\"\n    output: int = Field(description=\"The calculation result\")\n\n\n\n# åˆ›å»ºå¸¦ç»“æ„åŒ–è¾“å‡ºçš„Agent\nstructured_agent = create_agent(\n    model=llm,\n    tools=[get_weather, math_add],\n    system_prompt=\"You are a helpful assistant\",\n    response_format=CalcInfo,\n)\n\nresponse = structured_agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"è¯·è®¡ç®— 8234783 + 94123832 = ?\"}]},\n    config={\"configurable\": {\"thread_id\": \"1\"}},\n    context=Context(authority=\"admin\"),\n)\n\n\n\nfor message in response['messages']:\n    message.pretty_print()\n\n\n\nresponse['messages'][-1]\n\n\n\n","type":"content","url":"/quickstart#id-1","position":11},{"hierarchy":{"lvl1":"å¿«é€Ÿå…¥é—¨","lvl2":"å…­ã€æµå¼è¾“å‡º"},"type":"lvl2","url":"/quickstart#id-2","position":12},{"hierarchy":{"lvl1":"å¿«é€Ÿå…¥é—¨","lvl2":"å…­ã€æµå¼è¾“å‡º"},"content":"ä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼Œæ›´å¤šä¿¡æ¯è¯·å‚é˜… \n\nstreaming.\n\nagent = create_agent(\n    model=llm,\n    tools=[get_weather],\n)\n\nfor chunk in agent.stream(  \n    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n    stream_mode=\"updates\",\n):\n    for step, data in chunk.items():\n        print(f\"step: {step}\")\n        print(f\"content: {data['messages'][-1].content_blocks}\")\n\n","type":"content","url":"/quickstart#id-2","position":13},{"hierarchy":{"lvl1":"æ·±åº¦Agent"},"type":"lvl1","url":"/deep-agents","position":0},{"hierarchy":{"lvl1":"æ·±åº¦Agent"},"content":"deepagents å¯ä»¥çœ‹ä½œæ˜¯ LangChain å›¢é˜Ÿå‡ºå“çš„ DeepResearch. æœ¬èŠ‚é€šè¿‡æŸ¥è¯¢ä¸€ä¸ªè¿‘æœŸæ–°é—»ï¼Œæ£€éªŒ Deep Agents æ˜¯å¦æœ‰ä¸»åŠ¨è°ƒç”¨æœç´¢ï¼Œè·å–å¤–éƒ¨ä¿¡æ¯çš„èƒ½åŠ›ã€‚\n\nè¿™é‡Œåªæ˜¯ç®€å• quickstart ä¸€ä¸‹ï¼Œæ›´å¤šä¿¡æ¯å¤§å®¶å»å®˜ç½‘çœ‹å§ï¼\n\n# !pip install deepagents ddgs\n\n\n\n1ï¼‰åŠ è½½æ¨¡å‹\n\nimport os\nfrom datetime import datetime\nfrom dotenv import load_dotenv\nfrom ddgs import DDGS\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.tools import tool\nfrom deepagents import create_deep_agent\n\n# åŠ è½½æ¨¡å‹é…ç½®\n_ = load_dotenv()\n\n# åŠ è½½æ¨¡å‹\nllm = ChatOpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n    model=\"qwen3-coder-plus\",\n    temperature=0.7,\n)\n\n\n\n2ï¼‰åˆ›å»ºæœç´¢å·¥å…·\n\nDDGS æ˜¯æˆ‘æ‰¾åˆ°çš„ä¸€æ¬¾å…è´¹çš„ã€æ— éœ€ API_KEY å³å¯ç›´æ¥ä½¿ç”¨çš„ç½‘ç»œæœç´¢æœåŠ¡ã€‚æˆ‘ä»¬ç”¨å®ƒæ›¿ä»£å®˜æ–¹æ¨èçš„ Tavily.\n\n# åˆ›å»º ddgs å®¢æˆ·ç«¯\nddgs = DDGS()\n\ndef internet_search(\n    query: str,\n    max_results: int = 3,\n) -> str:\n    \"\"\"\n    ä½¿ç”¨äº’è”ç½‘æœç´¢æŒ‡å®šå…³é”®è¯å¹¶è¿”å›æ ¼å¼åŒ–ç»“æœã€‚\n\n    Args:\n        query: æœç´¢å…³é”®è¯æˆ–é—®é¢˜ã€‚\n        max_results: è¿”å›çš„æœ€å¤§ç»“æœæ¡æ•°ã€‚\n\n    Returns:\n        åŒ…å«æ¯æ¡æœç´¢ç»“æœçš„æ ‡é¢˜ã€æ‘˜è¦ä¸é“¾æ¥çš„å­—ç¬¦ä¸²ã€‚\n    \"\"\"\n    results = list(\n        ddgs.text(\n            query=query,\n            region=\"wt-wt\",  # wt-wt zh\n            timelimit='y',\n            safesearch='off',  # moderate off\n            page=1,\n            backend='auto',\n            max_results=max_results,\n        )\n    )\n\n    content = \"\"\n    for i, r in enumerate(results, 1):\n        content += f\"ã€ç»“æœ {i}ã€‘\\n\"\n        content += f\"æ ‡é¢˜: {r['title']}\\n\"\n        content += f\"æ‘˜è¦: {r['body']}\\n\"\n        content += f\"é“¾æ¥: {r['href']}\\n\\n\"\n\n    return content\n\n\n\n# æµ‹è¯•\nres = internet_search(query=\"ç¾é£Ÿ å››å·\")\nprint(res)\n\n\n\n3ï¼‰åˆ›å»ºæ·±åº¦ä»£ç†\n\n# System prompt to steer the agent to be an expert researcher\nresearch_instructions = \"\"\"ä½ æ˜¯ä¸€åèµ„æ·±ç ”ç©¶å‘˜ã€‚ä½ çš„å·¥ä½œæ˜¯è¿›è¡Œå…¨é¢æ·±å…¥çš„ç ”ç©¶ï¼Œå¹¶æ’°å†™ä¸€ä»½ç²¾ç‚¼çš„æŠ¥å‘Šã€‚\n\nä½ å¯ä»¥ä½¿ç”¨äº’è”ç½‘æœç´¢å·¥å…·ä½œä¸ºè·å–ä¿¡æ¯çš„ä¸»è¦æ–¹å¼ã€‚\n\n## `internet_search`\n\nä½¿ç”¨è¯¥å·¥å…·å¯¹æŒ‡å®šæŸ¥è¯¢è¿›è¡Œäº’è”ç½‘æœç´¢ã€‚ä½ å¯ä»¥è®¾ç½®è¿”å›ç»“æœçš„æœ€å¤§æ•°é‡ã€‚\n\nå¯¹äºè¯¥å·¥å…·çš„ query å‚æ•°ï¼Œæ¯æ¬¡æœ€å¤šè¾“å…¥ **2ä¸ª** å…³é”®è¯ã€‚ä¸”å…³é”®è¯ä¹‹é—´å¿…é¡»ç”¨ç©ºæ ¼åˆ†å¼€ã€‚è‹¥ä¸éµå®ˆæ­¤æ¡è§„å®šï¼Œå·¥å…·å°†è¿”å›æ— æ„ä¹‰å†…å®¹ã€‚\n\næ­£ç¡®ç”¨ä¾‹ï¼š\n\n- å—äº¬\n- ç¾é£Ÿ å››å·\n\né”™è¯¯ç”¨ä¾‹ï¼š\n\n- ç¾é£Ÿ å››å· 2025\n\næ³¨æ„ï¼Œå½“å…³é”®è¯æ•°é‡ä¸º2ä¸ªçš„æ—¶å€™ï¼Œå¿…é¡»å°†2ä¸ªè¯ä¸­æ›´é‡è¦çš„é‚£ä¸ªæ”¾åœ¨å‰é¢ã€‚\n\"\"\"\n\n@tool\ndef get_today_date() -> str:\n    \"\"\"è·å–ä»Šå¤©çš„æ—¥æœŸ\"\"\"\n    return datetime.now().strftime(\"%Y-%m-%d\")\n\nagent = create_deep_agent(\n    model=llm,\n    tools=[internet_search, get_today_date],\n    system_prompt=research_instructions\n)\n\n\n\n4ï¼‰è¿è¡Œ Agent\n\næˆ‘ä»¬çš„é—®é¢˜æ˜¯ï¼šæ–°ä¸Šä»»çš„ç»åˆ©ç»´äºšæ€»ç»Ÿæ˜¯è°ï¼Ÿè¯·ä»‹ç»ä¸€ä¸‹è¿™ä½æ€»ç»Ÿã€‚\n\nå› ä¸ºæ˜¨å¤©ï¼ˆ2025 å¹´ 11 æœˆ 8 æ—¥ï¼‰ç»åˆ©ç»´äºšæ€»ç»Ÿ ç½—å¾·é‡Œæˆˆãƒ»å¸•æ–¯ãƒ»ä½©é›·æ‹‰ åˆšåˆšä¸Šä»»ï¼Œè¿™æ¡ä¿¡æ¯è‚¯å®šä¸åœ¨é¢„è®­ç»ƒæ•°æ®é‡Œã€‚æ‰€ä»¥å¯ä»¥ç”¨è¿™ä¸ªé—®é¢˜éªŒè¯ Deep Agents æ˜¯å¦çœŸçš„è”ç½‘äº†ã€‚\n\nresult = agent.invoke({\"messages\": [\n    {\"role\": \"user\", \"content\": \"æ–°ä¸Šä»»çš„ç»åˆ©ç»´äºšæ€»ç»Ÿæ˜¯è°ï¼Ÿè¯·ä»‹ç»ä¸€ä¸‹è¿™ä½æ€»ç»Ÿã€‚\"}\n]})\n\n# æœ€ç»ˆå›å¤\nprint(result[\"messages\"][-1].content)\n\n\n\n# æ€è€ƒè¿‡ç¨‹\nfor message in result[\"messages\"]:\n    message.pretty_print()\n\n","type":"content","url":"/deep-agents","position":1},{"hierarchy":{"lvl1":"è°ƒè¯•é¡µé¢"},"type":"lvl1","url":"/langgraph-cli","position":0},{"hierarchy":{"lvl1":"è°ƒè¯•é¡µé¢"},"content":"LangGraph ä¸ºå¤§å®¶æä¾›äº†æ–¹ä¾¿çš„è°ƒè¯•é¡µé¢ï¼Œè¿™ä¸ªåŠŸèƒ½ç”± \n\nLangGraph CLI æä¾›ã€‚\n\nâš ï¸ è¯·æ³¨æ„ï¼Œè¿™ä¸ªåŠŸèƒ½ä¸æ˜¯ç«¯ä¾§çš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä½¿ç”¨è¯¥åŠŸèƒ½å¿…é¡»è”ç½‘ï¼Œä¸”ä½ çš„ä¿¡æ¯ä¼šå‘é€åˆ° LangChain å›¢é˜Ÿçš„æœåŠ¡å™¨ã€‚å› æ­¤è¯·ä¸è¦åœ¨è¯¥é¡µé¢è®¿é—®æ•æ„Ÿæ•°æ®ï¼\n\nè°ƒè¯•é¡µé¢ä¼šé“¾æ¥åˆ° LangSmith çš„ç½‘ç«™ï¼Œé¡µé¢å¦‚ä¸‹ï¼š\n\n","type":"content","url":"/langgraph-cli","position":1},{"hierarchy":{"lvl1":"è°ƒè¯•é¡µé¢","lvl2":"ä¸€ã€langsmith"},"type":"lvl2","url":"/langgraph-cli#id-langsmith","position":2},{"hierarchy":{"lvl1":"è°ƒè¯•é¡µé¢","lvl2":"ä¸€ã€langsmith"},"content":"LangSmith æ˜¯ç”± LangChain å›¢é˜Ÿæ¨å‡ºçš„ LLM åº”ç”¨çš„æ•°æ®åˆ†æå¹³å°ï¼Œå®ƒèƒ½å¸®åŠ©å¼€å‘è€…å¯è§†åŒ–åœ°ç®¡ç†å’Œä¼˜åŒ–æ•´ä¸ªåº”ç”¨å¼€å‘æµç¨‹ã€‚LangSmith æ˜¯ä¸€ä¸ªä»˜è´¹ PaaSï¼Œä½†æä¾›éƒ¨åˆ†å…è´¹åŠŸèƒ½ã€‚\n\n","type":"content","url":"/langgraph-cli#id-langsmith","position":3},{"hierarchy":{"lvl1":"è°ƒè¯•é¡µé¢","lvl2":"äºŒã€langgraph-cli"},"type":"lvl2","url":"/langgraph-cli#id-langgraph-cli","position":4},{"hierarchy":{"lvl1":"è°ƒè¯•é¡µé¢","lvl2":"äºŒã€langgraph-cli"},"content":"","type":"content","url":"/langgraph-cli#id-langgraph-cli","position":5},{"hierarchy":{"lvl1":"è°ƒè¯•é¡µé¢","lvl3":"1ï¼‰å®‰è£…ä¾èµ–","lvl2":"äºŒã€langgraph-cli"},"type":"lvl3","url":"/langgraph-cli#id-1","position":6},{"hierarchy":{"lvl1":"è°ƒè¯•é¡µé¢","lvl3":"1ï¼‰å®‰è£…ä¾èµ–","lvl2":"äºŒã€langgraph-cli"},"content":"ä½¿ç”¨æœåŠ¡å‰ï¼Œå…ˆå®‰è£…ä¾èµ–ï¼špip install \"langgraph-cli[inmem]\"","type":"content","url":"/langgraph-cli#id-1","position":7},{"hierarchy":{"lvl1":"è°ƒè¯•é¡µé¢","lvl3":"2ï¼‰å¼€å‘ Agent åç«¯","lvl2":"äºŒã€langgraph-cli"},"type":"lvl3","url":"/langgraph-cli#id-2-agent","position":8},{"hierarchy":{"lvl1":"è°ƒè¯•é¡µé¢","lvl3":"2ï¼‰å¼€å‘ Agent åç«¯","lvl2":"äºŒã€langgraph-cli"},"content":"è¿™é‡Œï¼Œæˆ‘ä»¬å¼€å‘ä¸€ä¸ªç®€å•çš„ Agent ä½œä¸ºè¯¥è°ƒè¯•é¡µé¢çš„åç«¯ã€‚ä»£ç å¦‚ä¸‹ï¼šimport os\nfrom dotenv import load_dotenv\nfrom langchain_openai import ChatOpenAI\nfrom langchain.agents import create_agent\n\n# åŠ è½½æ¨¡å‹é…ç½®\n_ = load_dotenv()\n\n# é…ç½®å¤§æ¨¡å‹æœåŠ¡\nllm = ChatOpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n    model=\"qwen3-coder-plus\",\n)\n\n# åˆ›å»ºAgent\nagent = create_agent(model=llm)\n\n# langgraph-cli å…¥å£å‡½æ•°\ndef get_app():\n    return agent\n\n\nSource: \n\nsimple_agent.py","type":"content","url":"/langgraph-cli#id-2-agent","position":9},{"hierarchy":{"lvl1":"è°ƒè¯•é¡µé¢","lvl3":"3ï¼‰ç¼–å†™é…ç½®æ–‡ä»¶","lvl2":"äºŒã€langgraph-cli"},"type":"lvl3","url":"/langgraph-cli#id-3","position":10},{"hierarchy":{"lvl1":"è°ƒè¯•é¡µé¢","lvl3":"3ï¼‰ç¼–å†™é…ç½®æ–‡ä»¶","lvl2":"äºŒã€langgraph-cli"},"content":"langgraph-cli é»˜è®¤çš„é…ç½®æ–‡ä»¶å« langgraph.json.\n\nè‹¥ä½¿ç”¨å…¶ä»–æ–‡ä»¶åï¼Œåœ¨å¯åŠ¨æœåŠ¡æ—¶ï¼Œéœ€è¦ä½¿ç”¨ --config å‚æ•°æŒ‡å®šä½ çš„ json æ–‡ä»¶åã€‚{\n    \"dependencies\": [\n        \"./\"\n    ],\n    \"graphs\": {\n        \"supervisor\": \"./simple_agent.py:get_app\"\n    },\n    \"env\": \"./.env\"\n}","type":"content","url":"/langgraph-cli#id-3","position":11},{"hierarchy":{"lvl1":"è°ƒè¯•é¡µé¢","lvl3":"4ï¼‰å¯åŠ¨ langgraph-cli","lvl2":"äºŒã€langgraph-cli"},"type":"lvl3","url":"/langgraph-cli#id-4-langgraph-cli","position":12},{"hierarchy":{"lvl1":"è°ƒè¯•é¡µé¢","lvl3":"4ï¼‰å¯åŠ¨ langgraph-cli","lvl2":"äºŒã€langgraph-cli"},"content":"åœ¨å‘½ä»¤è¡Œå¯åŠ¨æœåŠ¡ï¼š# å¦‚æœä½ çš„é…ç½®æ–‡ä»¶æ˜¯é»˜è®¤çš„ langgraph.json\nlanggraph dev\n\n# å¦‚æœä½ çš„é…ç½®æ–‡ä»¶æ˜¯ [your_agent].json\nlanggraph dev --config [your_agent].json\n\nè¿è¡Œåä¼šè‡ªåŠ¨è·³è½¬åˆ°æµè§ˆå™¨çš„è°ƒè¯•é¡µé¢ã€‚\n\nç”±äºè¿™ä¸ª Chat é¡µé¢ä¸æ˜¯å¼€æºçš„ï¼Œä¸å»ºè®®å°†å…¶ç”¨äºç”Ÿäº§ç¯å¢ƒã€‚å¦‚æœä½ éœ€è¦ä¸€ä¸ªæ›¿ä»£çš„å¼€æºå‰ç«¯ Chat é¡µé¢ï¼Œå¯å‚è€ƒæˆ‘çš„ \n\nclickhouse-chatbi é¡¹ç›®ã€‚è¯¥é¡¹ç›®ä½¿ç”¨äº† Next.js çš„ \n\nnextjs-ai-chatbot æ¨¡æ¿ã€‚è¯¥æ¨¡æ¿å…¼å…·ç°ä»£çš„å¤–è§‚å’Œæ˜“ç”¨çš„åŠŸèƒ½ï¼Œå®ä¹ƒå¿«æ·å¼€å‘çš„ä¸äºŒä¹‹é€‰ã€‚","type":"content","url":"/langgraph-cli#id-4-langgraph-cli","position":13},{"hierarchy":{"lvl1":"å¼€å‘æ¡ˆä¾‹"},"type":"lvl1","url":"/development-case","position":0},{"hierarchy":{"lvl1":"å¼€å‘æ¡ˆä¾‹"},"content":"","type":"content","url":"/development-case","position":1},{"hierarchy":{"lvl1":"å•†ä¸šæ¡ˆä¾‹"},"type":"lvl1","url":"/business-case","position":0},{"hierarchy":{"lvl1":"å•†ä¸šæ¡ˆä¾‹"},"content":"","type":"content","url":"/business-case","position":1},{"hierarchy":{"lvl1":"çŠ¶æ€å›¾"},"type":"lvl1","url":"/stategraph","position":0},{"hierarchy":{"lvl1":"çŠ¶æ€å›¾"},"content":"åœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨ LangGraph åˆ›å»º ReAct Agentã€‚ä½†æ˜¯ï¼ŒæŠŠä»»åŠ¡äº¤ç»™ Agent ç­‰äºæŠŠæ§åˆ¶æƒä¹Ÿäº¤äº†å‡ºå»ã€‚å¦‚æœä½ ä¸å¸Œæœ› Agent æ‹¥æœ‰å¦‚æ­¤é«˜çš„æ§åˆ¶æƒï¼Œè€Œæ˜¯å¸Œæœ›æµç¨‹å®Œå…¨å—ä½ æ§åˆ¶ï¼Œé‚£ä¹ˆä½ å¯ä»¥ä½¿ç”¨ çŠ¶æ€å›¾ï¼ˆStateGraphï¼‰æ¥åˆ›å»ºå·¥ä½œæµã€‚\n\nimport os\nfrom dotenv import load_dotenv\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.graph import StateGraph, MessagesState, START, END\nfrom langchain_core.messages import SystemMessage, HumanMessage\nfrom langchain_core.tools import tool\n\n# å…³é”®èŠ‚ç‚¹ï¼šToolNode\nfrom langgraph.prebuilt import ToolNode\nfrom langchain_core.runnables import RunnableConfig\n\n# åŠ è½½æ¨¡å‹é…ç½®\n_ = load_dotenv()\n\n\n\næœ¬èŠ‚å®ç°äº†ä¸€ä¸ªç®€å•çš„å·¥ä½œæµã€‚è¯¥å·¥ä½œæµæ¥å…¥ä¸€ä¸ªå¯æŸ¥è¯¢å¤©æ°”çš„å·¥å…·ã€‚åŒºåˆ«äº ReAct Agent å¯ä»¥è‡ªä¸»å®ç°å·¥å…·è°ƒç”¨ï¼Œè¿™é‡Œæˆ‘ä»¬é€šè¿‡â€œæ¡ä»¶è¾¹â€ï¼Œæ‰‹åŠ¨ç¼–å†™å·¥å…·çš„è§¦å‘é€»è¾‘ã€‚\n\nä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬éœ€è¦å…ˆåˆ›å»ºä¸‰æ ·ä¸œè¥¿ï¼š\n\nåŠ©æ‰‹èŠ‚ç‚¹ï¼šè£…è½½äº† LLMï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·\n\nå·¥å…·èŠ‚ç‚¹ï¼šä¸€ä¸ªå¯è·å–åŸå¸‚å¤©æ°”çš„å·¥å…·ã€‚è¿™é‡Œè¢«æˆ‘ä»¬ç®€åŒ–ï¼Œå¯¹ä»»ä½•åŸå¸‚å‡è¾“å‡ºæ™´å¤©\n\næ¡ä»¶è¾¹ï¼šè¿æ¥åŠ©æ‰‹èŠ‚ç‚¹ä¸å·¥å…·èŠ‚ç‚¹ã€‚æ ¹æ®åŠ©æ‰‹èŠ‚ç‚¹çš„è¾“å‡ºï¼Œå†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·ï¼ˆå³å¯¹åº”ä¸‹å›¾ä¸­çš„2æ¡è™šçº¿ï¼‰\n\n# åŠ è½½æ¨¡å‹\nllm = ChatOpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n    model=\"qwen3-coder-plus\",\n    temperature=0.7,\n)\n\n# å·¥å…·å‡½æ•°\n@tool\ndef get_weather(city: str) -> str:\n    \"\"\"Get weather for a given city.\"\"\"\n    return f\"It's always sunny in {city}!\"\n\n# åˆ›å»ºå·¥å…·èŠ‚ç‚¹\ntools = [get_weather]\ntool_node = ToolNode(tools)\n\n# åˆ›å»ºå¸¦å·¥å…·çš„LLMåŠ©æ‰‹èŠ‚ç‚¹\ndef assistant(state: MessagesState, config: RunnableConfig):\n    system_prompt = 'You are a helpful assistant that can check weather.'\n    all_messages = [SystemMessage(system_prompt)] + state['messages']\n    model = llm.bind_tools(tools)\n    return {'messages': [model.invoke(all_messages)]}\n\n# åˆ›å»ºæ¡ä»¶è¾¹\ndef should_continue(state: MessagesState, config: RunnableConfig):\n    messages = state['messages']\n    last_message = messages[-1]\n    # å¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯æ˜¯LLå†³å®šä½¿ç”¨å·¥å…·è°ƒç”¨ï¼Œåˆ™ç»§ç»­\n    if last_message.tool_calls:\n        return 'continue'\n    # å¦åˆ™ï¼Œç»“æŸ\n    return 'end'\n\n\n\næœ‰äº†è¿™ä¸‰æ ·ä¸œè¥¿ï¼Œåªæ˜¯æœ‰äº†æ„å»ºçŠ¶æ€å›¾ï¼ˆStateGraphï¼‰çš„åŸºç¡€åŸæ–™ã€‚è¦è®©çŠ¶æ€å›¾è¿è¡Œèµ·æ¥ï¼Œè¿˜éœ€è¦ å®šä¹‰èŠ‚ç‚¹å’Œè¾¹ä¹‹é—´çš„å…³ç³»ã€‚åœ¨ä¸‹é¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬å…ˆå°†èŠ‚ç‚¹æ·»åŠ åˆ° StateGraph å®ä¾‹ä¸­ï¼Œç„¶åä»¥æ­£ç¡®çš„é¡ºåºæ¡¥æ¥å®ƒä»¬ã€‚è¿™æ ·æˆ‘ä»¬å°±è·å¾—äº†ä¸€ä¸ªå¯ä»¥è¿è¡Œçš„å·¥ä½œæµã€‚\n\n# åˆ›å»ºå›¾\nbuilder = StateGraph(MessagesState)\n\n# æ·»åŠ èŠ‚ç‚¹\nbuilder.add_node('assistant', assistant)\nbuilder.add_node('tool', tool_node)\n\n# æ·»åŠ è¾¹ï¼ˆä»STARTåˆ°assistantï¼‰\nbuilder.add_edge(START, 'assistant')\n\n# æ·»åŠ æ¡ä»¶è¾¹ï¼ˆæ ¹æ®assistantçš„è¾“å‡ºï¼Œå†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·ï¼‰\nbuilder.add_conditional_edges(\n    # æ¡ä»¶è¾¹è¿æ¥çš„èŠ‚ç‚¹  \n    'assistant', \n    # æ¡ä»¶è¾¹åˆ¤æ–­é€»è¾‘\n    should_continue,\n    # æ¡ä»¶è¾¹åˆ¤æ–­é€»è¾‘ä¸ºTrueæ—¶ï¼Œè°ƒç”¨toolèŠ‚ç‚¹\n    {\n        'continue': 'tool',\n        'end': END,\n    },\n)\n\n# æ·»åŠ è¾¹ï¼šè°ƒç”¨å·¥å…·èŠ‚ç‚¹åå›åˆ°assistant\nbuilder.add_edge('tool', 'assistant')\n\n# ç¼–è¯‘å›¾\nmy_graph = builder.compile(name='my-graph')\nmy_graph\n\n\n\nNote\n\n\n\næœ‰å‘å›¾åˆ†ä¸ºï¼š\n\næœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰\n\næœ‰å‘å¾ªç¯å›¾ï¼ˆDCGï¼‰\n\nä»å¯è§†åŒ–ç»“æœæ¥çœ‹ï¼ŒåŠ©æ‰‹èŠ‚ç‚¹ assistant ä¸å·¥å…·èŠ‚ç‚¹ tool ä¹‹é—´å­˜åœ¨å¾ªç¯è°ƒç”¨ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åˆ›å»ºçš„æ˜¯ æœ‰å‘å¾ªç¯å›¾ã€‚ä¸‹é¢æ¥çœ‹ä¸€ä¸‹ï¼Œå½“è¯¢é—®ä¸Šæµ·å¤©æ°”æ—¶ï¼Œå·¥ä½œæµçš„è¿è¡Œè¿‡ç¨‹ã€‚\n\n# è°ƒç”¨å›¾\nresponse = my_graph.invoke({'messages': [HumanMessage(content='ä¸Šæµ·å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ')]})\nfor message in response['messages']:\n    message.pretty_print()\n\n","type":"content","url":"/stategraph","position":1},{"hierarchy":{"lvl1":"ä¸­é—´ä»¶"},"type":"lvl1","url":"/middleware","position":0},{"hierarchy":{"lvl1":"ä¸­é—´ä»¶"},"content":"ä¸­é—´ä»¶ï¼ˆmiddlewareï¼‰æ˜¯æœ¬æ¬¡æ›´æ–°ä¸­æœ€äº®çœ¼çš„ç‰¹æ€§ï¼Œè¯¸å¤šæ–°åŠŸèƒ½å‡è—‰ç”±ä¸­é—´ä»¶å®ç°ï¼Œæ¯”å¦‚äººæœºäº¤äº’ã€åŠ¨æ€ç³»ç»Ÿæç¤ºè¯ã€åŠ¨æ€æ³¨å…¥ä¸Šä¸‹æ–‡ç­‰ç­‰ã€‚å¯ä»¥å°†ä¸­é—´ä»¶è§†ä¸ºä¸€ç§é’©å­å‡½æ•°ã€‚é€šè¿‡å‘å·¥ä½œæµé¢„åŸ‹ä¸­é—´ä»¶ï¼Œèƒ½å¤Ÿå®ç°å·¥ä½œæµçš„é«˜æ•ˆæ‹“å±•å’Œå¯å®šåˆ¶åŒ–ã€‚\n\nLangChain å¯é€šè¿‡ \n\nè£…é¥°å™¨ åˆ›å»º è‡ªå®šä¹‰ä¸­é—´ä»¶ã€‚\n\nè£…é¥°å™¨åˆ—è¡¨ï¼ˆç‚¹å‡»å±•å¼€ï¼‰\n\nDECORATOR\n\nDESCRIPTION\n\n@before_agent\n\nåœ¨ Agent æ‰§è¡Œå‰æ‰§è¡Œé€»è¾‘\n\n@after_agent\n\nåœ¨ Agent æ‰§è¡Œåæ‰§è¡Œé€»è¾‘\n\n@before_model\n\nåœ¨æ¯æ¬¡æ¨¡å‹è°ƒç”¨å‰æ‰§è¡Œé€»è¾‘\n\n@after_model\n\nåœ¨æ¯æ¬¡æ¨¡å‹æ”¶åˆ°å“åº”åæ‰§è¡Œé€»è¾‘\n\n@wrap_model_call\n\næ§åˆ¶æ¨¡å‹çš„è°ƒç”¨è¿‡ç¨‹\n\n@wrap_tool_call\n\næ§åˆ¶å·¥å…·çš„è°ƒç”¨è¿‡ç¨‹\n\n@dynamic_prompt\n\nåŠ¨æ€ç”Ÿæˆç³»ç»Ÿæç¤ºè¯\n\n@hook_config\n\né…ç½®é’©å­è¡Œä¸º\n\nè£…é¥°å™¨ç±»å‹ å†³å®šä¸­é—´ä»¶åœ¨å·¥ä½œæµä¸­çš„æ‰§è¡Œä½ç½®ã€‚æ¯”å¦‚ä½¿ç”¨ @before_model è£…é¥°å™¨ï¼Œèƒ½å¤Ÿåœ¨æ¨¡å‹è°ƒç”¨å‰æ‰§è¡Œè‡ªå®šä¹‰é€»è¾‘ã€‚è¢«è£…é¥°å‡½æ•° è´Ÿè´£è¿™æ®µè‡ªå®šä¹‰é€»è¾‘çš„å…·ä½“å®ç°ã€‚è¿™ä¹ˆè¯´å¯èƒ½æœ‰ç‚¹æŠ½è±¡ã€‚æ²¡å…³ç³»ï¼Œæœ¬èŠ‚æä¾›äº†å››ä¸ªä¾‹å­ï¼Œçœ‹å®Œä½ è‚¯å®šèƒ½å¤Ÿæ„Ÿæ‚Ÿåˆ°ä¸­é—´ä»¶çš„ä½¿ç”¨æ–¹æ³•ï¼š\n\né¢„ç®—æ§åˆ¶\n\næ¶ˆæ¯æˆªæ–­\n\næ•æ„Ÿè¯è¿‡æ»¤\n\nPII æ£€æµ‹ï¼ˆä¸ªäººéšç§ä¿¡æ¯æ£€æµ‹ï¼‰","type":"content","url":"/middleware","position":1},{"hierarchy":{"lvl1":"ä¸­é—´ä»¶","lvl2":"ä¸€ã€é¢„ç®—æ§åˆ¶"},"type":"lvl2","url":"/middleware#id","position":2},{"hierarchy":{"lvl1":"ä¸­é—´ä»¶","lvl2":"ä¸€ã€é¢„ç®—æ§åˆ¶"},"content":"éšç€å¯¹è¯è½®æ¬¡å¢åŠ ï¼Œæ¯æ¬¡è¯·æ±‚æºå¸¦çš„å¯¹è¯è®°å½•ä¹Ÿä¼šè¶Šæ¥è¶Šé•¿ï¼Œä»è€Œå¯¼è‡´è¯·æ±‚è´¹ç”¨ä¸Šå‡ã€‚ä¸ºäº†æ§åˆ¶é¢„ç®—ï¼Œå¯ä»¥è®¾å®šåœ¨å¯¹è¯è½®æ¬¡è¶…è¿‡æŸä¸ªé˜ˆå€¼åï¼Œåˆ‡æ¢åˆ°ä½è´¹ç‡æ¨¡å‹ã€‚è¿™ä¸ªåŠŸèƒ½å¯ä»¥é€šè¿‡è‡ªå®šä¹‰ä¸­é—´ä»¶å®ç°ã€‚\n\nimport os\nfrom dotenv import load_dotenv\nfrom langchain_openai import ChatOpenAI\nfrom langchain.agents import create_agent\nfrom langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\nfrom langchain_core.messages import HumanMessage\nfrom langgraph.graph import MessagesState\n\n# åŠ è½½æ¨¡å‹é…ç½®\n_ = load_dotenv()\n\n# ä½è´¹ç‡æ¨¡å‹\nbasic_model = ChatOpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n    model=\"qwen3-coder-plus\",\n)\n\n# é«˜è´¹ç‡æ¨¡å‹\nadvanced_model = ChatOpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n    model=\"qwen3-max\",\n)\n\n\n\nç”±äºæˆ‘ä»¬çš„ä¿®æ”¹æ¶‰åŠåˆ°æ¨¡å‹æ¨ç†æœ¬èº«ï¼Œ@before_model å’Œ @after_model åœ¨è¿™é‡Œå·²ç»ä¸å¤Ÿç”¨äº†ã€‚æˆ‘ä»¬ä½¿ç”¨èƒ½å¹²æ¶‰æ¨¡å‹è°ƒç”¨çš„ \n\n@wrap_model_call è£…é¥°å™¨ã€‚å…·ä½“é€»è¾‘ç”±è¢«è£…é¥°å‡½æ•° dynamic_model_selection å®ç°ï¼šå½“å†å²å¯¹è¯è¶…è¿‡ 5 æ¡æ—¶ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°ä½è´¹ç‡æ¨¡å‹ã€‚\n\n@wrap_model_call\ndef dynamic_model_selection(request: ModelRequest, handler) -> ModelResponse:\n    \"\"\"Choose model based on conversation complexity.\"\"\"\n    message_count = len(request.state[\"messages\"])\n\n    if message_count > 5:\n        # Use a basic model for longer conversations\n        model = basic_model\n    else:\n        model = advanced_model\n\n    request.model = model\n    print(f\"message_count: {message_count}\")\n    print(f\"model_name: {model.model_name}\")\n\n    return handler(request)\n\nagent = create_agent(\n    model=advanced_model,  # Default model\n    middleware=[dynamic_model_selection]\n)\n\n\n\nä»ä¸‹é¢çš„ä¾‹å­å¯ä»¥çœ‹åˆ°ï¼Œå½“å†å²å¯¹è¯æ•° message_count è¶…è¿‡ 5 æ¡æ—¶ï¼Œç¡®å®ä»é«˜è´¹ç‡æ¨¡å‹ qwen3-max åˆ‡æ¢åˆ°ä½è´¹ç‡æ¨¡å‹ qwen3-coder-plusã€‚æˆ‘ä»¬æ­£ç¡®åœ°å®ç°äº†é¢„ç®—æ§åˆ¶åŠŸèƒ½ï¼\n\nstate: MessagesState = {\"messages\": []}\nitems = ['æ±½è½¦', 'é£æœº', 'æ‘©æ‰˜è½¦', 'è‡ªè¡Œè½¦']\nfor idx, i in enumerate(items):\n    print(f\"\\n=== Round {idx+1} ===\")\n    state[\"messages\"] += [HumanMessage(content=f\"{i}æœ‰å‡ ä¸ªè½®å­ï¼Œè¯·ç®€å•å›ç­”\")]\n    result = agent.invoke(state)\n    state[\"messages\"] = result[\"messages\"]\n    print(f'content: {result[\"messages\"][-1].content}')\n\n\n\n","type":"content","url":"/middleware#id","position":3},{"hierarchy":{"lvl1":"ä¸­é—´ä»¶","lvl2":"äºŒã€æ¶ˆæ¯æˆªæ–­"},"type":"lvl2","url":"/middleware#id-1","position":4},{"hierarchy":{"lvl1":"ä¸­é—´ä»¶","lvl2":"äºŒã€æ¶ˆæ¯æˆªæ–­"},"content":"æ™ºèƒ½ä½“çš„ä¸Šä¸‹æ–‡å­˜åœ¨é•¿åº¦é™åˆ¶ã€‚ä¸€æ—¦è¶…è¿‡é™åˆ¶ï¼Œå°±éœ€è¦å¯¹ä¸Šä¸‹æ–‡è¿›è¡Œå‹ç¼©ã€‚åœ¨ä¼—å¤šæ–¹æ³•ä¸­ï¼Œæˆªæ–­æ˜¯æœ€ç®€å•ç²—æš´ã€æ˜“äºå®ç°çš„æ–¹æ³•ã€‚æ¶ˆæ¯æˆªæ–­åŠŸèƒ½å¯ä»¥é€šè¿‡ @before_model è£…é¥°å™¨å®ç°ã€‚\n\nfrom langchain.messages import RemoveMessage\nfrom langgraph.graph.message import REMOVE_ALL_MESSAGES\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langchain.agents import create_agent, AgentState\nfrom langchain.agents.middleware import before_model\nfrom langgraph.runtime import Runtime\nfrom langchain_core.runnables import RunnableConfig\nfrom typing import Any\n\n\n\næˆ‘ä»¬å°è¯•ä¸€ç§æˆªæ–­ç­–ç•¥ï¼šåœ¨ä¿ç•™æœ€è¿‘æ¶ˆæ¯çš„åŒæ—¶ï¼Œé¢å¤–ä¿ç•™ç¬¬ä¸€æ¡æ¶ˆæ¯ã€‚åœ¨ä¸‹é¢çš„ä¾‹å­ä¸­ï¼Œç”±äºæˆ‘ä»¬åœ¨ç¬¬ä¸€æ¡æ¶ˆæ¯ä¸­å‘Šè¯‰æ™ºèƒ½ä½“ã€Œæˆ‘æ˜¯ bobã€ï¼Œå› æ­¤å®ƒè®°å¾—æˆ‘æ˜¯ bob.\n\n@before_model\ndef trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n    messages = state[\"messages\"]\n\n    if len(messages) <= 3:\n        return None  # No changes needed\n\n    first_msg = messages[0]\n    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n    new_messages = [first_msg] + recent_messages\n\n    return {\n        \"messages\": [\n            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n            *new_messages\n        ]\n    }\n\nagent = create_agent(\n    basic_model,\n    middleware=[trim_messages],\n    checkpointer=InMemorySaver(),\n)\n\nconfig: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n\ndef agent_invoke(agent):\n    agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n    agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n    agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n    final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n    \n    final_response[\"messages\"][-1].pretty_print()\n\nagent_invoke(agent)\n\n\n\nå½“ç„¶ï¼Œè¿™ä¸ªè¡¨ç°ä¸è¶³ä»¥è¯´æ˜æˆªæ–­ä¸­é—´ä»¶çœŸçš„ç”Ÿæ•ˆäº†ã€‚è‹¥è¿™ä¸ªä¸­é—´ä»¶ä»æœªç”Ÿæ•ˆï¼Œä¹Ÿä¼šæœ‰è¿™æ ·çš„ç»“æœã€‚ä¸ºäº†è¯æ˜å®ƒçœŸçš„ç”Ÿæ•ˆäº†ï¼Œæˆ‘ä»¬å†æ¬¡ä¿®æ”¹æˆªæ–­ç­–ç•¥ã€‚è¿™æ¬¡åªä¿ç•™æœ€åä¸¤æ¡å¯¹è¯è®°å½•ã€‚å¦‚æœæ™ºèƒ½ä½“ä¸è®°å¾—æˆ‘æ˜¯ bobï¼Œè¯´æ˜æˆªæ–­ä¸­é—´ä»¶ç¡®å®èµ·ä½œç”¨äº†ã€‚\n\n@before_model\ndef trim_without_first_message(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n    messages = state[\"messages\"]\n\n    return {\n        \"messages\": [\n            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n            *messages[-2:]\n        ]\n    }\n\nagent = create_agent(\n    basic_model,\n    middleware=[trim_without_first_message],\n    checkpointer=InMemorySaver(),\n)\n\nagent_invoke(agent)\n\n\n\nç°åœ¨æ™ºèƒ½ä½“ä¸è®°å¾—æˆ‘æ˜¯è°ï¼Œè¯´æ˜ä¸­é—´ä»¶ç¡®å®ç”Ÿæ•ˆäº†ï¼\n\n","type":"content","url":"/middleware#id-1","position":5},{"hierarchy":{"lvl1":"ä¸­é—´ä»¶","lvl2":"ä¸‰ã€æ•æ„Ÿè¯è¿‡æ»¤"},"type":"lvl2","url":"/middleware#id-2","position":6},{"hierarchy":{"lvl1":"ä¸­é—´ä»¶","lvl2":"ä¸‰ã€æ•æ„Ÿè¯è¿‡æ»¤"},"content":"æŠ¤æ ï¼ˆGuardrailsï¼‰æ˜¯æ™ºèƒ½ä½“æä¾›çš„ä¸€ç±»å†…å®¹å®‰å…¨èƒ½åŠ›çš„ç»Ÿç§°ã€‚å¤§æ¨¡å‹æœ¬èº«å…·å¤‡ä¸€å®šçš„å†…å®¹é£æ§èƒ½åŠ›ï¼Œä½†å¾ˆå®¹æ˜“è¢«çªç ´ã€‚æœç´¢ã€Œå¤§æ¨¡å‹ç ´ç”²ã€å°±èƒ½æ‰¾åˆ°æ­¤ç±»æ•™ç¨‹ã€‚æ™ºèƒ½ä½“å¯ä»¥åœ¨æ¨¡å‹ä¹‹å¤–ï¼Œæä¾›é¢å¤–çš„å®‰å…¨ä¿æŠ¤ã€‚è¿™æ˜¯é€šè¿‡å·¥ç¨‹ä¸Šçš„å¼ºåˆ¶æ£€æŸ¥å®ç°çš„ã€‚\n\nåœ¨ LangGraph ä¸­ï¼ŒæŠ¤æ å¯ä»¥é€šè¿‡ä¸­é—´ä»¶è½»æ¾å®ç°ã€‚ä¸‹é¢æˆ‘ä»¬å®ç°ä¸€ä¸ªç®€å•çš„æŠ¤æ ï¼šè‹¥ç”¨æˆ·çš„æœ€æ–°æ¶ˆæ¯ä¸­åŒ…å«æŸäº›æ•æ„Ÿè¯ï¼Œæ™ºèƒ½ä½“å°†æ‹’ç»å›ç­”ã€‚\n\nfrom typing import Any\n\nfrom langchain.agents.middleware import before_agent, AgentState\nfrom langgraph.runtime import Runtime\n\nbanned_keywords = [\"hack\", \"exploit\", \"malware\"]\n\n@before_agent(can_jump_to=[\"end\"])\ndef content_filter(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n    # Get the first user message\n    if not state[\"messages\"]:\n        return None\n\n    last_message = state[\"messages\"][-1]\n    if last_message.type != \"human\":\n        return None\n\n    content = last_message.content.lower()\n\n    # Check for banned keywords\n    for keyword in banned_keywords:\n        if keyword in content:\n            # Block execution before any processing\n            return {\n                \"messages\": [{\n                    \"role\": \"assistant\",\n                    \"content\": \"I cannot process requests containing inappropriate content. Please rephrase your request.\"\n                }],\n                \"jump_to\": \"end\"\n            }\n\n    return None\n\nagent = create_agent(\n    model=basic_model,\n    middleware=[content_filter],\n)\n\n# This request will be blocked before any processing\nresult = agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"How do I hack into a database?\"}]\n})\n\n\n\nfor message in result[\"messages\"]:\n    message.pretty_print()\n\n\n\n","type":"content","url":"/middleware#id-2","position":7},{"hierarchy":{"lvl1":"ä¸­é—´ä»¶","lvl2":"å››ã€PII æ£€æµ‹"},"type":"lvl2","url":"/middleware#id-pii","position":8},{"hierarchy":{"lvl1":"ä¸­é—´ä»¶","lvl2":"å››ã€PII æ£€æµ‹"},"content":"æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ç»§ç»­ç¼–å†™æŠ¤æ ã€‚\n\nPIIï¼ˆPersonally Identifiable Informationï¼‰æ£€æµ‹å¯ä»¥å‘ç°ç”¨æˆ·è¾“å…¥ä¸­çš„é‚®ç®±ã€IPã€åœ°å€ã€é“¶è¡Œå¡ç­‰éšç§ä¿¡æ¯ï¼Œå¹¶åšå‡ºå¤„ç½®ã€‚\n\nä¸‹é¢çš„ä¾‹å­æ¥æºäºç”Ÿæ´»ã€‚æˆ‘ä»¬ç»å¸¸æŠŠæŠ¥é”™å¤åˆ¶ç»™å¤§æ¨¡å‹ï¼Œè®©å®ƒå¸®å¿™ debugã€‚ä½†æŠ¥é”™ä¸­å¯èƒ½åŒ…å«ä¸ªäººéšç§ä¿¡æ¯ã€‚é’ˆå¯¹è¿™ç§æƒ…å†µï¼Œé‡‡ç”¨ä»¥ä¸‹ä¸¤ç§æ–¹æ³•è¿›è¡Œå¤„ç½®ï¼š\n\næ‹’ç»å›ç­”é—®é¢˜\n\nå±è”½éšç§ä¿¡æ¯\n\nfrom textwrap import dedent\nfrom pydantic import BaseModel, Field\n\n# å¯ä¿¡ä»»çš„æ¨¡å‹ï¼Œä¸€èˆ¬æ˜¯æœ¬åœ°æ¨¡å‹ï¼Œä¸ºäº†æ–¹ä¾¿ï¼Œè¿™é‡Œä¾ç„¶ä½¿ç”¨qwen\ntrusted_model = ChatOpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n    model=\"qwen3-coder-plus\",\n)\n\n# ç”¨äºæ ¼å¼åŒ–æ™ºèƒ½ä½“è¾“å‡ºï¼Œè‹¥å‘ç°æ•æ„Ÿä¿¡æ¯è¿”å›Trueï¼Œæ²¡å‘ç°è¿”å›False\nclass PiiCheck(BaseModel):\n    \"\"\"Structured output indicating whether text contains PII.\"\"\"\n    is_pii: bool = Field(description=\"Whether the text contains PII\")\n\ndef message_with_pii(pii_middleware):\n    agent = create_agent(\n        model=basic_model,\n        middleware=[pii_middleware],\n    )\n\n    # This request will be blocked before any processing\n    result = agent.invoke({\n        \"messages\": [{\n            \"role\": \"user\",\n            \"content\": dedent(\n                \"\"\"\n                File \"/home/luochang/proj/agent.py\", line 53, in my_agent\n                    agent = create_react_agent(\n                            ^^^^^^^^^^^^^^^^^^^\n                File \"/home/luochang/miniconda3/lib/python3.12/site-packages/typing_extensions.py\", line 2950, in wrapper\n                    return arg(*args, **kwargs)\n                        ^^^^^^^^^^^^^^^^^^^^\n                File \"/home/luochang/miniconda3/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py\", line 566, in create_react_agent\n                    model = cast(BaseChatModel, model).bind_tools(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n                AttributeError: 'RunnableLambda' object has no attribute 'bind_tools'\n    \n                ---\n    \n                ä¸ºå•¥æŠ¥é”™\n                \"\"\").strip()\n        }]\n    })\n\n    return result\n\n\n\nğŸ‰ å¤„ç½®æ–¹å¼ä¸€ï¼šå¦‚é‡éšç§ä¿¡æ¯ï¼Œæ‹’ç»å›å¤ã€‚\n\n@before_agent(can_jump_to=[\"end\"])\ndef content_blocker(state: AgentState,  runtime: Runtime) -> dict[str, Any] | None:\n    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n    # Get the first user message\n    if not state[\"messages\"]:\n        return None\n\n    last_message = state[\"messages\"][-1]\n    if last_message.type != \"human\":\n        return None\n\n    content = last_message.content.lower()\n    prompt = (\n        \"ä½ æ˜¯ä¸€ä¸ªéšç§ä¿æŠ¤åŠ©æ‰‹ã€‚è¯·è¯†åˆ«ä¸‹é¢æ–‡æœ¬ä¸­æ¶‰åŠä¸ªäººå¯è¯†åˆ«ä¿¡æ¯ï¼ˆPIIï¼‰ï¼Œ\"\n        \"ä¾‹å¦‚ï¼šå§“åã€èº«ä»½è¯å·ã€æŠ¤ç…§å·ã€ç”µè¯å·ç ã€é‚®ç®±ã€ä½å€ã€é“¶è¡Œå¡å·ã€ç¤¾äº¤è´¦å·ã€è½¦ç‰Œç­‰ã€‚\"\n        \"ç‰¹åˆ«æ³¨æ„ï¼Œè‹¥ä»£ç ã€æ–‡ä»¶è·¯å¾„ä¸­åŒ…å«ç”¨æˆ·åï¼Œä¹Ÿåº”è¢«è§†ä¸ºæ•æ„Ÿä¿¡æ¯ã€‚\"\n        \"è‹¥åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼Œè¯·è¿”å›{\\\"is_pii\\\": True}ï¼Œå¦åˆ™è¿”å›{\\\"is_pii\\\": False}ã€‚\"\n        \"è¯·ä¸¥æ ¼ä»¥ json æ ¼å¼è¿”å›ï¼Œå¹¶ä¸”åªè¾“å‡º jsonã€‚æ–‡æœ¬å¦‚ä¸‹ï¼š\\n\\n\" + content\n    )\n\n    pii_agent = trusted_model.with_structured_output(PiiCheck)\n    result = pii_agent.invoke(prompt)\n\n    if result.is_pii is True:\n        # Block execution before any processing\n        return {\n            \"messages\": [{\n                \"role\": \"assistant\",\n                \"content\": \"I cannot process requests containing inappropriate content. Please rephrase your request.\"\n            }],\n            \"jump_to\": \"end\"\n        }\n    else:\n        print(\"No PII found\")\n\n    return None\n\n\n\nresult = message_with_pii(pii_middleware=content_blocker)\n\nfor message in result[\"messages\"]:\n    message.pretty_print()\n\n\n\nğŸ€ å¤„ç½®æ–¹å¼äºŒï¼šå¦‚é‡æ•æ„Ÿä¿¡æ¯ï¼Œä½¿ç”¨ä¸€ä¸²  ***** å·å±è”½éšç§ä¿¡æ¯ã€‚\n\n@before_agent(can_jump_to=[\"end\"])\ndef content_filter(state: AgentState,  runtime: Runtime) -> dict[str, Any] | None:\n    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n    # Get the first user message\n    if not state[\"messages\"]:\n        return None\n\n    last_message = state[\"messages\"][-1]\n    if last_message.type != \"human\":\n        return None\n\n    content = last_message.content.lower()\n    prompt = (\n        \"ä½ æ˜¯ä¸€ä¸ªéšç§ä¿æŠ¤åŠ©æ‰‹ã€‚è¯·è¯†åˆ«ä¸‹é¢æ–‡æœ¬ä¸­æ¶‰åŠä¸ªäººå¯è¯†åˆ«ä¿¡æ¯ï¼ˆPIIï¼‰ï¼Œ\"\n        \"ä¾‹å¦‚ï¼šå§“åã€èº«ä»½è¯å·ã€æŠ¤ç…§å·ã€ç”µè¯å·ç ã€é‚®ç®±ã€ä½å€ã€é“¶è¡Œå¡å·ã€ç¤¾äº¤è´¦å·ã€è½¦ç‰Œç­‰ã€‚\"\n        \"ç‰¹åˆ«æ³¨æ„ï¼Œè‹¥ä»£ç ã€æ–‡ä»¶è·¯å¾„ä¸­åŒ…å«ç”¨æˆ·åï¼Œä¹Ÿåº”è¢«è§†ä¸ºæ•æ„Ÿä¿¡æ¯ã€‚\"\n        \"è‹¥åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼Œè¯·è¿”å›{\\\"is_pii\\\": True}ï¼Œå¦åˆ™è¿”å›{\\\"is_pii\\\": False}ã€‚\"\n        \"è¯·ä¸¥æ ¼ä»¥ json æ ¼å¼è¿”å›ï¼Œå¹¶ä¸”åªè¾“å‡º jsonã€‚æ–‡æœ¬å¦‚ä¸‹ï¼š\\n\\n\" + content\n    )\n\n    pii_agent = trusted_model.with_structured_output(PiiCheck)\n    result = pii_agent.invoke(prompt)\n\n    if result.is_pii is True:\n        mask_prompt = (\n            \"ä½ æ˜¯ä¸€ä¸ªéšç§ä¿æŠ¤åŠ©æ‰‹ã€‚è¯·å°†ä¸‹é¢æ–‡æœ¬ä¸­çš„æ‰€æœ‰ä¸ªäººå¯è¯†åˆ«ä¿¡æ¯ï¼ˆPIIï¼‰ç”¨æ˜Ÿå·ï¼ˆ*ï¼‰æ›¿æ¢ã€‚\"\n            \"ä»…æ›¿æ¢æ•æ„Ÿç‰‡æ®µï¼Œå…¶ä»–æ–‡æœ¬ä¿æŒä¸å˜ã€‚\"\n            \"åªè¾“å‡ºå¤„ç†åçš„æ–‡æœ¬ï¼Œä¸è¦ä»»ä½•è§£é‡Šæˆ–é¢å¤–å†…å®¹ã€‚æ–‡æœ¬å¦‚ä¸‹ï¼š\\n\\n\" + last_message.content\n        )\n        masked_message = basic_model.invoke(mask_prompt)\n        return {\n            \"messages\": [{\n                \"role\": \"assistant\",\n                \"content\": masked_message.content\n            }]\n        }\n    else:\n        print(\"No PII found\")\n\n    return None\n\n\n\nresult = message_with_pii(pii_middleware=content_filter)\n\nfor message in result[\"messages\"]:\n    message.pretty_print()\n\n","type":"content","url":"/middleware#id-pii","position":9},{"hierarchy":{"lvl1":"äººæœºäº¤äº’"},"type":"lvl1","url":"/human-in-the-loop","position":0},{"hierarchy":{"lvl1":"äººæœºäº¤äº’"},"content":"äººæœºäº¤äº’ï¼ˆHuman-in-the-loop, HITLï¼‰æŒ‡æ™ºèƒ½ä½“ä¸ºäº†å‘äººç±»ç´¢è¦æ‰§è¡Œæƒé™æˆ–é¢å¤–ä¿¡æ¯è€Œä¸»åŠ¨ä¸­æ–­ï¼Œå¹¶åœ¨è·å¾—äººç±»åé¦ˆåç»§ç»­æ‰§è¡Œçš„è¿‡ç¨‹ã€‚\n\nLangGraph å†…ç½®äººæœºäº¤äº’ä¸­é—´ä»¶ HumanInTheLoopMiddlewareã€‚è§¦å‘äººæœºäº¤äº’æ—¶ï¼ŒHITL ä¼šå°†å½“å‰çŠ¶æ€ä¿å­˜åˆ° \n\ncheckpointer çŸ­æœŸè®°å¿†ä¸­ï¼Œå¹¶ç­‰å¾…äººç±»å›å¤ã€‚å¾…è·å¾—å›å¤åï¼Œå†å°†çŠ¶æ€ä»æ£€æŸ¥ç‚¹ä¸­æ¢å¤å‡ºæ¥ï¼Œç»§ç»­æ‰§è¡Œä»»åŠ¡ã€‚\n\nNote\n\n\næœ¬ä¾‹åªæ˜¯æ¼”ç¤º checkpoint åœ¨äººæœºäº¤äº’ä¸­çš„ä½œç”¨ï¼Œæ— æ‰€è°“çº¿ç¨‹ç»“æŸåè®°å¿†æ˜¯å¦ä¿æŒï¼Œå› æ­¤ä½¿ç”¨å†…å­˜å­˜å‚¨ InMemorySaverã€‚åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œè¯·ä½¿ç”¨æŒä¹…åŒ–æ£€æŸ¥ç‚¹ï¼Œä¾‹å¦‚ï¼š\n\nSqliteSaver\n\nPostgresSaver\n\nMongoDBSaver\n\nRedisSaver\n\nimport os\nimport uuid\nfrom dotenv import load_dotenv\nfrom langchain_openai import ChatOpenAI\nfrom langchain.agents import create_agent\nfrom langchain.agents.middleware import HumanInTheLoopMiddleware\nfrom langchain_core.tools import tool\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.types import Command\n\n# åŠ è½½æ¨¡å‹é…ç½®\n_ = load_dotenv()\n\n\n\nåœ¨ä¸‹é¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ HITL ä¸­é—´ä»¶ï¼Œä¸ºä¸‰ç§å·¥å…·é…ç½®äº†äººå·¥å®¡æ‰¹æµç¨‹ã€‚\n\n# é…ç½®å¤§æ¨¡å‹æœåŠ¡\nllm = ChatOpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n    model=\"qwen3-coder-plus\",\n)\n\n# å·¥å…·å‡½æ•°\n@tool\ndef get_weather(city: str) -> str:\n    \"\"\"Get weather for a given city.\"\"\"\n    return f\"It's always sunny in {city}!\"\n\n@tool\ndef add_numbers(a: float, b: float) -> float:\n    \"\"\"Add two numbers and return the sum.\"\"\"\n    return a + b\n\n@tool\ndef calculate_bmi(weight_kg: float, height_m: float) -> float:\n    \"\"\"Calculate BMI given weight in kg and height in meters.\"\"\"\n    if height_m <= 0 or weight_kg <= 0:\n        raise ValueError(\"height_m and weight_kg must be greater than 0.\")\n    return weight_kg / (height_m ** 2)\n\n# åˆ›å»ºå¸¦å·¥å…·è°ƒç”¨çš„Agent\ntool_agent = create_agent(\n    model=llm,\n    tools=[get_weather, add_numbers, calculate_bmi],\n    middleware=[\n        HumanInTheLoopMiddleware( \n            interrupt_on={\n                # æ— éœ€è§¦å‘äººå·¥å®¡æ‰¹\n                \"get_weather\": False,\n                # éœ€è¦å®¡æ‰¹ï¼Œä¸”å…è®¸approve,edit,rejectä¸‰ç§å®¡æ‰¹ç±»å‹\n                \"add_numbers\": True,\n                # éœ€è¦å®¡æ‰¹ï¼Œå…è®¸approve,rejectä¸¤ç§å®¡æ‰¹ç±»å‹\n                \"calculate_bmi\": {\"allowed_decisions\": [\"approve\", \"reject\"]},\n            },\n            description_prefix=\"Tool execution pending approval\",\n        ),\n    ],\n    checkpointer=InMemorySaver(),\n    system_prompt=\"You are a helpful assistant\",\n)\n\n\n\n# è¿è¡ŒAgent\nconfig = {'configurable': {'thread_id': str(uuid.uuid4())}}\nresult = tool_agent.invoke(\n    {\"messages\": [{\n        \"role\": \"user\",\n        \"content\": \"æˆ‘èº«é«˜180cmï¼Œä½“é‡180æ–¤ï¼Œæˆ‘çš„BMIæ˜¯å¤šå°‘\"\n        # \"content\": \"what is the weather in sf\"\n    }]},\n    config=config,\n)\n\n# result['messages'][-1].content\nresult.get('__interrupt__')\n\n\n\nä»ä¸­æ–­ä¿¡æ¯æ¥çœ‹ï¼Œæ™ºèƒ½ä½“å·²è§¦å‘ calculate_bmi å·¥å…·è°ƒç”¨ï¼Œå¹¶è¿›å…¥ç­‰å¾…å®¡æ‰¹çŠ¶æ€ã€‚ä¸‹é¢æˆ‘ä»¬å‘æ™ºèƒ½ä½“å‘é€ã€Œå®¡æ‰¹é€šè¿‡ã€æŒ‡ä»¤ï¼Œä½¿å…¶æ¢å¤è¿è¡Œã€‚\n\n# Resume with approval decision\nresult = tool_agent.invoke(\n    Command(\n        resume={\"decisions\": [{\"type\": \"approve\"}]}  # or \"edit\", \"reject\"\n    ), \n    config=config\n)\n\nresult['messages'][-1].content\n\n\n\nNote\n\n\né™¤äº† HITL ä¹‹å¤–ï¼ŒLangChain è¿˜æä¾›äº†å¤šç§ å†…ç½®ä¸­é—´ä»¶ï¼Œå®Œæ•´åˆ—è¡¨å¯ä»¥åœ¨æ¥å£æ–‡æ¡£ \n\nmiddleware-classes ä¸­æ‰¾åˆ°ã€‚è¿™é‡Œä»…åˆ—å‡ºå‡ ä¸ªç¤ºä¾‹ï¼š\n\nCLASS\n\nDESCRIPTION\n\nSummarizationMiddleware\n\nåœ¨æ¥è¿‘ token ä¸Šé™æ—¶è‡ªåŠ¨å°†å¯¹è¯å†å²è¿›è¡Œæ‘˜è¦\n\nModelCallLimitMiddleware\n\né™åˆ¶æ¨¡å‹è°ƒç”¨æ¬¡æ•°ä»¥é˜²æ­¢æˆæœ¬è¿‡é«˜\n\nToolCallLimitMiddleware\n\né€šè¿‡é™åˆ¶è°ƒç”¨æ¬¡æ•°æ¥æ§åˆ¶å·¥å…·æ‰§è¡Œ\n\nModelFallbackMiddleware\n\nå½“ä¸»æ¨¡å‹å¤±è´¥æ—¶è‡ªåŠ¨å›é€€åˆ°å¤‡ç”¨æ¨¡å‹\n\n......\n\n......\n\nå‚è€ƒæ–‡æ¡£ï¼š\n\nlangchainâ€‹/humanâ€‹-inâ€‹-theâ€‹-loop\n\nlangchainâ€‹/shortâ€‹-termâ€‹-memory\n\nlangchainâ€‹/longâ€‹-termâ€‹-memory\n\nlanggraphâ€‹/persistence\n\nlanggraphâ€‹/useâ€‹-timeâ€‹-travel\n\nlanggraphâ€‹/addâ€‹-memory","type":"content","url":"/human-in-the-loop","position":1},{"hierarchy":{"lvl1":"è®°å¿†"},"type":"lvl1","url":"/memory","position":0},{"hierarchy":{"lvl1":"è®°å¿†"},"content":"è®°å¿†ï¼ˆMemoryï¼‰æ˜¯ä¸€ä¸ªå¯é€‰æ¨¡å—ã€‚å¦‚éå¿…è¦ï¼Œä½ æ— éœ€å‘æ™ºèƒ½ä½“æ·»åŠ  Memory æ¨¡å—ã€‚å› ä¸º StateGraph æœ¬èº«å°±å«æœ‰å†å²æ¶ˆæ¯åˆ—è¡¨ messagesï¼Œè¶³ä»¥æ»¡è¶³æœ€åŸºç¡€çš„â€œè®°å¿†â€éœ€æ±‚ã€‚\n\néœ€è¦æ·»åŠ  Memory æ¨¡å—çš„æƒ…å†µåŒ…æ‹¬ï¼š\n\nå†å²æ¶ˆæ¯å¤ªå¤šï¼Œéœ€è¦ç”¨å¤–éƒ¨å·¥å…·å­˜å‚¨è®°å¿†\n\nè§¦å‘äººå·¥å¹²é¢„ï¼ˆ\n\ninterruptï¼‰æ—¶ï¼Œä¸´æ—¶ä¿å­˜ Agent çš„çŠ¶æ€\n\nè·¨å¯¹è¯æå–ç”¨æˆ·åå¥½ ç­‰ç­‰\n\nLangGraph å°†è®°å¿†åˆ†ä¸ºï¼š\n\nçŸ­æœŸè®°å¿†ï¼ˆMemorySaverï¼‰\n\né•¿æœŸè®°å¿†ï¼ˆMemoryStoreï¼‰\n\næ­¤å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ª \n\nLangMem ä¹Ÿæä¾›è®°å¿†å­˜å–åŠŸèƒ½ã€‚\n\nPS: ä¸çŸ¥é“ä¸ºå•¥å¼€å‘å›¢é˜ŸæŠŠè®°å¿†æ¨¡å—åˆ†å¾—è¿™ä¹ˆç¨€ç¢ã€‚æ„Ÿè§‰è¿™äº›æ¨¡å—è¿˜ä¸æˆç†Ÿï¼Œåè¾¹å˜åŠ¨ä¼šæ¯”è¾ƒå¤§ã€‚\n\nimport os\nfrom dotenv import load_dotenv\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.graph import StateGraph, MessagesState, START, END\nfrom langgraph.checkpoint.memory import InMemorySaver\n\n# åŠ è½½æ¨¡å‹é…ç½®\n_ = load_dotenv()\n\n# åŠ è½½æ¨¡å‹\nmodel = ChatOpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n    model=\"qwen3-coder-plus\",\n    temperature=0.7,\n)\n\n# åˆ›å»ºåŠ©æ‰‹èŠ‚ç‚¹\ndef assistant(state: MessagesState):\n    return {'messages': [model.invoke(state['messages'])]}\n\n\n\n","type":"content","url":"/memory","position":1},{"hierarchy":{"lvl1":"è®°å¿†","lvl2":"ä¸€ã€çŸ­æœŸè®°å¿†"},"type":"lvl2","url":"/memory#id","position":2},{"hierarchy":{"lvl1":"è®°å¿†","lvl2":"ä¸€ã€çŸ­æœŸè®°å¿†"},"content":"çŸ­æœŸè®°å¿†ï¼ˆå·¥ä½œè®°å¿†ï¼‰ä¸€èˆ¬ç”¨äºä¸´æ—¶å­˜å‚¨ï¼Œä¸å½“å‰å¯¹è¯å†…å®¹å¼ºç›¸å…³ã€‚ä¸ä¾èµ–ä¸Šä¸‹æ–‡çš„è®°å¿†æ–¹å¼ä¸åŒï¼ŒçŸ­æœŸè®°å¿†å¯ä»¥ä¸»åŠ¨è®°ä½é‡è¦çš„å†…å®¹ï¼Œå¢åŠ å·¥ç¨‹ç¨³å®šæ€§ã€‚","type":"content","url":"/memory#id","position":3},{"hierarchy":{"lvl1":"è®°å¿†","lvl3":"1ï¼‰åœ¨ StateGraph ä¸­ä½¿ç”¨çŸ­æœŸè®°å¿†","lvl2":"ä¸€ã€çŸ­æœŸè®°å¿†"},"type":"lvl3","url":"/memory#id-1-stategraph","position":4},{"hierarchy":{"lvl1":"è®°å¿†","lvl3":"1ï¼‰åœ¨ StateGraph ä¸­ä½¿ç”¨çŸ­æœŸè®°å¿†","lvl2":"ä¸€ã€çŸ­æœŸè®°å¿†"},"content":"ä¸ºäº†æ–¹ä¾¿æ¼”ç¤ºï¼Œæˆ‘ä»¬ä½¿ç”¨ InMemorySaver å­˜å‚¨çŸ­æœŸè®°å¿†ã€‚è¿™æ„å‘³ç€çŸ­æœŸè®°å¿†å­˜å‚¨åœ¨å†…å­˜ä¸­ã€‚å¦‚æœé€€å‡ºå½“å‰ç¨‹åºï¼Œè®°å¿†å°†ä¼šæ¶ˆå¤±ã€‚\n\n# åˆ›å»ºçŸ­æœŸè®°å¿†\ncheckpointer = InMemorySaver()\n\n# åˆ›å»ºå›¾\nbuilder = StateGraph(MessagesState)\n\n# æ·»åŠ èŠ‚ç‚¹\nbuilder.add_node('assistant', assistant)\n\n# æ·»åŠ è¾¹\nbuilder.add_edge(START, 'assistant')\nbuilder.add_edge('assistant', END)\n\ngraph = builder.compile(checkpointer=checkpointer)\n\n# å‘Šè¯‰æ™ºèƒ½ä½“æˆ‘å« luochang\nresult = graph.invoke(\n    {'messages': ['hi! i am luochang']},\n    {\"configurable\": {\"thread_id\": \"1\"}},\n)\n\nfor message in result['messages']:\n    message.pretty_print()\n\n\n\n# è®©æ™ºèƒ½ä½“è¯´å‡ºæˆ‘çš„åå­—\nresult = graph.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"What is my name?\"}]},\n    {\"configurable\": {\"thread_id\": \"1\"}},  \n)\n\nfor message in result['messages']:\n    message.pretty_print()\n\n\n\n","type":"content","url":"/memory#id-1-stategraph","position":5},{"hierarchy":{"lvl1":"è®°å¿†","lvl3":"2ï¼‰åœ¨ create_agent ä¸­ä½¿ç”¨çŸ­æœŸè®°å¿†","lvl2":"ä¸€ã€çŸ­æœŸè®°å¿†"},"type":"lvl3","url":"/memory#id-2-create-agent","position":6},{"hierarchy":{"lvl1":"è®°å¿†","lvl3":"2ï¼‰åœ¨ create_agent ä¸­ä½¿ç”¨çŸ­æœŸè®°å¿†","lvl2":"ä¸€ã€çŸ­æœŸè®°å¿†"},"content":"\n\nfrom langchain.agents import create_agent\n\n# åˆ›å»ºçŸ­æœŸè®°å¿†\ncheckpointer = InMemorySaver()\n\nagent = create_agent(\n    model=model,\n    checkpointer=checkpointer\n)\n\n# å‘Šè¯‰æ™ºèƒ½ä½“æˆ‘å« luochang\nresult = agent.invoke(\n    {'messages': ['hi! i am luochang']},\n    {\"configurable\": {\"thread_id\": \"2\"}},\n)\n\nfor message in result['messages']:\n    message.pretty_print()\n\n\n\n# è®©æ™ºèƒ½ä½“è¯´å‡ºæˆ‘çš„åå­—\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"What is my name?\"}]},\n    {\"configurable\": {\"thread_id\": \"2\"}},  \n)\n\nfor message in result['messages']:\n    message.pretty_print()\n\n\n\nä¸ºäº†éªŒè¯ InMemorySaver æ˜¯å¦çœŸçš„æœ‰æ•ˆæœï¼Œå¯ä»¥å°† checkpointer=checkpointer æ³¨é‡Šåï¼Œå†è§‚å¯Ÿæ™ºèƒ½ä½“èƒ½ä¸èƒ½æ­£ç¡®å›å¤æˆ‘çš„åå­—ã€‚\n\n","type":"content","url":"/memory#id-2-create-agent","position":7},{"hierarchy":{"lvl1":"è®°å¿†","lvl3":"3ï¼‰ä½¿ç”¨å¤–éƒ¨æ•°æ®åº“æ”¯æŒçš„çŸ­æœŸè®°å¿†","lvl2":"ä¸€ã€çŸ­æœŸè®°å¿†"},"type":"lvl3","url":"/memory#id-3","position":8},{"hierarchy":{"lvl1":"è®°å¿†","lvl3":"3ï¼‰ä½¿ç”¨å¤–éƒ¨æ•°æ®åº“æ”¯æŒçš„çŸ­æœŸè®°å¿†","lvl2":"ä¸€ã€çŸ­æœŸè®°å¿†"},"content":"å¦‚æœä½¿ç”¨ SQLite ä¿å­˜å½“å‰å·¥ä½œçŠ¶æ€ï¼Œå³ä½¿é€€å‡ºç¨‹åºï¼Œä¾ç„¶èƒ½åœ¨ä¸‹æ¬¡è¿›å…¥æ—¶æ¢å¤ä¸Šæ¬¡é€€å‡ºæ—¶çš„çŠ¶æ€ï¼Œæˆ‘ä»¬æ¥æµ‹è¯•è¿™ä¸€ç‚¹ã€‚\n\nåœ¨ä½¿ç”¨ SQLite ä½œä¸ºçŸ­æœŸè®°å¿†çš„å¤–éƒ¨æ•°æ®åº“ä¹‹å‰ï¼Œéœ€è¦å®‰è£…ä¸€ä¸ª Python åŒ…ä»¥æ”¯æŒè¿™é¡¹åŠŸèƒ½ï¼špip install langgraph-checkpoint-sqlite\n\n# åˆ é™¤SQLiteæ•°æ®åº“\nif os.path.exists(\"short-memory.db\"):\n    os.remove(\"short-memory.db\")\n\n\n\nimport os\nimport sqlite3\n\nfrom dotenv import load_dotenv\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.checkpoint.sqlite import SqliteSaver\nfrom langchain.agents import create_agent\n\n# åŠ è½½æ¨¡å‹é…ç½®\n_ = load_dotenv()\n\n# åŠ è½½æ¨¡å‹\nmodel = ChatOpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n    model=\"qwen3-coder-plus\",\n    temperature=0.7,\n)\n\n# åˆ›å»ºsqliteæ”¯æŒçš„çŸ­æœŸè®°å¿†\ncheckpointer = SqliteSaver(\n    sqlite3.connect(\"short-memory.db\", check_same_thread=False)\n)\n\n# åˆ›å»ºAgent\nagent = create_agent(\n    model=model,\n    checkpointer=checkpointer,\n)\n\n# å‘Šè¯‰æ™ºèƒ½ä½“æˆ‘å« luochang\nresult = agent.invoke(\n    {'messages': ['hi! i am luochang']},\n    {\"configurable\": {\"thread_id\": \"3\"}},\n)\n\nfor message in result['messages']:\n    message.pretty_print()\n\n\n\né‡å¯ Jupyter Notebook åçœ‹æ™ºèƒ½ä½“èƒ½å¦ä» SQLite ä¸­è¯»å–å…³äºæˆ‘åå­—çš„è®°å¿†ã€‚\n\nåœ¨ Kernel -> Restart Kernel... ä¸­é‡å¯æœåŠ¡ã€‚ç„¶åè¿è¡Œä»¥ä¸‹ä»£ç ã€‚\n\nimport os\nimport sqlite3\n\nfrom dotenv import load_dotenv\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.checkpoint.sqlite import SqliteSaver\nfrom langchain.agents import create_agent\n\n# åŠ è½½æ¨¡å‹é…ç½®\n_ = load_dotenv()\n\n# åŠ è½½æ¨¡å‹\nmodel = ChatOpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n    model=\"qwen3-coder-plus\",\n    temperature=0.7,\n)\n\n# åˆ›å»ºsqliteæ”¯æŒçš„çŸ­æœŸè®°å¿†\ncheckpointer = SqliteSaver(\n    sqlite3.connect(\"short-memory.db\", check_same_thread=False)\n)\n\n# åˆ›å»ºAgent\nagent = create_agent(\n    model=model,\n    checkpointer=checkpointer,\n)\n\n# è®©æ™ºèƒ½ä½“å›å¿†æˆ‘çš„åå­—\nresult = agent.invoke(\n    {'messages': ['What is my name?']},\n    {\"configurable\": {\"thread_id\": \"3\"}},\n)\n\nfor message in result['messages']:\n    message.pretty_print()\n\n\n\n","type":"content","url":"/memory#id-3","position":9},{"hierarchy":{"lvl1":"è®°å¿†","lvl2":"äºŒã€é•¿æœŸè®°å¿†"},"type":"lvl2","url":"/memory#id-1","position":10},{"hierarchy":{"lvl1":"è®°å¿†","lvl2":"äºŒã€é•¿æœŸè®°å¿†"},"content":"\n\nimport os\nfrom dotenv import load_dotenv\nfrom openai import OpenAI\nfrom langchain_core.runnables import RunnableConfig\nfrom langchain.agents import create_agent\nfrom langchain.tools import tool, ToolRuntime\nfrom langgraph.store.memory import InMemoryStore\nfrom dataclasses import dataclass\n\nEMBED_MODEL = \"text-embedding-v4\"\nEMBED_DIM = 1024\n\n# åŠ è½½æ¨¡å‹é…ç½®\n_ = load_dotenv()\n\n# ç”¨äºè·å–text embeddingçš„æ¥å£\nclient = OpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n)\n\n# åŠ è½½æ¨¡å‹\nmodel = ChatOpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n    model=\"qwen3-coder-plus\",\n    temperature=0.7,\n)\n\n\n\n# embeddingç”Ÿæˆå‡½æ•°\ndef embed(texts: list[str]) -> list[list[float]]:\n    response = client.embeddings.create(\n        model=EMBED_MODEL,\n        input=texts,\n        dimensions=EMBED_DIM,\n    )\n\n    return [item.embedding for item in response.data]\n\n# æµ‹è¯•èƒ½å¦æ­£å¸¸ç”Ÿæˆtext embedding\ntexts = [\n    \"LangGraphçš„ä¸­é—´ä»¶éå¸¸å¼ºå¤§\",\n    \"LangGraphçš„MCPä¹Ÿå¾ˆå¥½ç”¨\",\n]\nvectors = embed(texts)\n\nlen(vectors), len(vectors[0])\n\n\n\n","type":"content","url":"/memory#id-1","position":11},{"hierarchy":{"lvl1":"è®°å¿†","lvl3":"1ï¼‰ç›´æ¥è¯»å†™é•¿æœŸè®°å¿†","lvl2":"äºŒã€é•¿æœŸè®°å¿†"},"type":"lvl3","url":"/memory#id-1-1","position":12},{"hierarchy":{"lvl1":"è®°å¿†","lvl3":"1ï¼‰ç›´æ¥è¯»å†™é•¿æœŸè®°å¿†","lvl2":"äºŒã€é•¿æœŸè®°å¿†"},"content":"\n\n# InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use.\nstore = InMemoryStore(index={\"embed\": embed, \"dims\": EMBED_DIM})\n\n# æ·»åŠ ä¸¤æ¡ç”¨æˆ·æ•°æ®\nnamespace = (\"users\", )\nkey = \"user_1\"\nstore.put(\n    namespace,\n    key,\n    {\n        \"rules\": [\n            \"User likes short, direct language\",\n            \"User only speaks English & python\",\n        ],\n        \"rule_id\": \"3\",\n    },\n)\n\nstore.put( \n    (\"users\",),  # Namespace to group related data together (users namespace for user data)\n    \"user_2\",  # Key within the namespace (user ID as key)\n    {\n        \"name\": \"John Smith\",\n        \"language\": \"English\",\n    }  # Data to store for the given user\n)\n\n# get the \"memory\" by ID\nitem = store.get(namespace, \"a-memory\") \n\n# search for \"memories\" within this namespace, filtering on content equivalence, sorted by vector similarity\nitems = store.search( \n    namespace, filter={\"rule_id\": \"3\"}, query=\"language preferences\"\n)\n\nitems\n\n\n\n","type":"content","url":"/memory#id-1-1","position":13},{"hierarchy":{"lvl1":"è®°å¿†","lvl3":"2ï¼‰ä½¿ç”¨å·¥å…·è¯»å–é•¿æœŸè®°å¿†","lvl2":"äºŒã€é•¿æœŸè®°å¿†"},"type":"lvl3","url":"/memory#id-2","position":14},{"hierarchy":{"lvl1":"è®°å¿†","lvl3":"2ï¼‰ä½¿ç”¨å·¥å…·è¯»å–é•¿æœŸè®°å¿†","lvl2":"äºŒã€é•¿æœŸè®°å¿†"},"content":"\n\n@dataclass\nclass Context:\n    user_id: str\n\n@tool\ndef get_user_info(runtime: ToolRuntime[Context]) -> str:\n    \"\"\"Look up user info.\"\"\"\n    # Access the store - same as that provided to `create_agent`\n    store = runtime.store \n    user_id = runtime.context.user_id\n    # Retrieve data from store - returns StoreValue object with value and metadata\n    user_info = store.get((\"users\",), user_id) \n    return str(user_info.value) if user_info else \"Unknown user\"\n\nagent = create_agent(\n    model=model,\n    tools=[get_user_info],\n    # Pass store to agent - enables agent to access store when running tools\n    store=store, \n    context_schema=Context\n)\n\n# Run the agent\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"look up user information\"}]},\n    context=Context(user_id=\"user_2\") \n)\n\nfor message in result['messages']:\n    message.pretty_print()\n\n\n\n","type":"content","url":"/memory#id-2","position":15},{"hierarchy":{"lvl1":"è®°å¿†","lvl3":"3ï¼‰ä½¿ç”¨å·¥å…·å†™å…¥é•¿æœŸè®°å¿†","lvl2":"äºŒã€é•¿æœŸè®°å¿†"},"type":"lvl3","url":"/memory#id-3-1","position":16},{"hierarchy":{"lvl1":"è®°å¿†","lvl3":"3ï¼‰ä½¿ç”¨å·¥å…·å†™å…¥é•¿æœŸè®°å¿†","lvl2":"äºŒã€é•¿æœŸè®°å¿†"},"content":"\n\nfrom typing_extensions import TypedDict\n\n# InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production.\nstore = InMemoryStore() \n\n@dataclass\nclass Context:\n    user_id: str\n\n# TypedDict defines the structure of user information for the LLM\nclass UserInfo(TypedDict):\n    name: str\n\n# Tool that allows agent to update user information (useful for chat applications)\n@tool\ndef save_user_info(user_info: UserInfo, runtime: ToolRuntime[Context]) -> str:\n    \"\"\"Save user info.\"\"\"\n    # Access the store - same as that provided to `create_agent`\n    store = runtime.store \n    user_id = runtime.context.user_id \n    # Store data in the store (namespace, key, data)\n    store.put((\"users\",), user_id, user_info) \n    return \"Successfully saved user info.\"\n\nagent = create_agent(\n    model=model,\n    tools=[save_user_info],\n    store=store,\n    context_schema=Context\n)\n\n# Run the agent\nagent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"My name is John Smith\"}]},\n    # user_id passed in context to identify whose information is being updated\n    context=Context(user_id=\"user_123\") \n)\n\n# You can access the store directly to get the value\nstore.get((\"users\",), \"user_123\").value\n\n","type":"content","url":"/memory#id-3-1","position":17},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹"},"type":"lvl1","url":"/context","position":0},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹"},"content":"ä¸Šä¸‹æ–‡å·¥ç¨‹ï¼ˆContext Engineeringï¼‰å¯¹äº Agent å¾—å‡ºæ­£ç¡®çš„ç»“æœè‡³å…³é‡è¦ã€‚æ¨¡å‹å›ç­”ä¸å¥½ï¼Œå¾ˆå¤šæ—¶å€™ä¸æ˜¯å› ä¸ºèƒ½åŠ›ä¸è¶³ï¼Œè€Œæ˜¯å› ä¸ºæ²¡æœ‰è·å¾—è¶³ä»¥æ¨æ–­å‡ºæ­£ç¡®ç»“æœçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚é€šè¿‡ä¸Šä¸‹æ–‡å·¥ç¨‹ï¼Œå¢å¼º Agent è·å–å’Œç®¡ç†ä¸Šä¸‹æ–‡çš„èƒ½åŠ›ï¼Œæ˜¯å¾ˆæœ‰å¿…è¦çš„ã€‚\n\nLangGraph å°†ä¸Šä¸‹æ–‡åˆ†ä¸ºä¸‰ç§ç±»å‹ï¼š\n\næ¨¡å‹ä¸Šä¸‹æ–‡ï¼ˆModel Contextï¼‰\n\nå·¥å…·ä¸Šä¸‹æ–‡ï¼ˆTool Contextï¼‰\n\nç”Ÿå‘½å‘¨æœŸä¸Šä¸‹æ–‡ï¼ˆLife-cycle Contextï¼‰\n\næ— è®ºå“ªç§ Contextï¼Œéƒ½éœ€è¦å®šä¹‰å®ƒçš„ Schemaã€‚åœ¨è¿™æ–¹é¢ï¼ŒLangGraph æä¾›äº†ç›¸å½“é«˜çš„è‡ªç”±åº¦ï¼Œä½ å¯ä»¥ä½¿ç”¨ dataclassesã€pydanticã€TypedDict è¿™äº›åŒ…çš„ä»»æ„ä¸€ä¸ªåˆ›å»ºä½ çš„ Context Schema.\n\n# !pip install ipynbname\n\n\n\nimport os\nimport uuid\nimport sqlite3\n\nfrom typing import Callable\nfrom dotenv import load_dotenv\nfrom dataclasses import dataclass\nfrom langchain_openai import ChatOpenAI\nfrom langchain.tools import tool, ToolRuntime\nfrom langchain.agents import create_agent\nfrom langchain.agents.middleware import dynamic_prompt, wrap_model_call, ModelRequest, ModelResponse, SummarizationMiddleware\nfrom langgraph.graph import StateGraph, MessagesState, START, END\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.store.memory import InMemoryStore\nfrom langgraph.store.sqlite import SqliteStore\n\n# åŠ è½½æ¨¡å‹é…ç½®\n_ = load_dotenv()\n\n# åŠ è½½æ¨¡å‹\nllm = ChatOpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n    model=\"qwen3-coder-plus\",\n    temperature=0.7,\n)\n\n\n\n","type":"content","url":"/context","position":1},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹","lvl2":"ä¸€ã€åŠ¨æ€ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯"},"type":"lvl2","url":"/context#id","position":2},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹","lvl2":"ä¸€ã€åŠ¨æ€ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯"},"content":"ä¸Šä¸‹æ–‡å·¥ç¨‹ä¸å‰åºç« èŠ‚çš„ä¸­é—´ä»¶ï¼ˆmiddlewareï¼‰å’Œè®°å¿†ï¼ˆmemoryï¼‰å¯†ä¸å¯åˆ†ã€‚ä¸Šä¸‹æ–‡çš„å…·ä½“å®ç°ä¾èµ–ä¸­é—´ä»¶ï¼Œè€Œä¸Šä¸‹æ–‡çš„å­˜å‚¨åˆ™ä¾èµ–è®°å¿†ç³»ç»Ÿã€‚å…·ä½“æ¥è®²ï¼ŒLangGraph é¢„ç½®äº† @dynamic_prompt ä¸­é—´ä»¶ï¼Œç”¨äºåŠ¨æ€ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯ã€‚\n\næ—¢ç„¶æ˜¯åŠ¨æ€ä¿®æ”¹ï¼Œè‚¯å®šéœ€è¦æŸä¸ªæ¡ä»¶æ¥è§¦å‘ä¿®æ”¹ã€‚é™¤äº†å¼€å‘è§¦å‘é€»è¾‘ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä»æ™ºèƒ½ä½“ä¸­è·å–è§¦å‘é€»è¾‘æ‰€éœ€çš„å³æ—¶å˜é‡ã€‚è¿™äº›å˜é‡é€šå¸¸å­˜å‚¨åœ¨ä»¥ä¸‹ä¸‰ä¸ªå­˜å‚¨ä»‹è´¨ä¸­ï¼š\n\nè¿è¡Œæ—¶ï¼ˆRuntimeï¼‰- æ‰€æœ‰èŠ‚ç‚¹å…±äº«ä¸€ä¸ª Runtimeã€‚åŒä¸€æ—¶åˆ»ï¼Œæ‰€æœ‰èŠ‚ç‚¹å–åˆ°çš„ Runtime çš„å€¼æ˜¯ç›¸åŒçš„ã€‚ä¸€èˆ¬ç”¨äºå­˜å‚¨æ—¶æ•ˆæ€§è¦æ±‚è¾ƒé«˜çš„ä¿¡æ¯ã€‚\n\nçŸ­æœŸè®°å¿†ï¼ˆStateï¼‰- åœ¨èŠ‚ç‚¹ä¹‹é—´æŒ‰é¡ºåºä¼ é€’ï¼Œæ¯ä¸ªèŠ‚ç‚¹æ¥æ”¶ä¸Šä¸€ä¸ªèŠ‚ç‚¹å¤„ç†åçš„ Stateã€‚ä¸»è¦ç”¨äºå­˜å‚¨ Prompt å’Œ AI Messageã€‚\n\né•¿æœŸè®°å¿†ï¼ˆStoreï¼‰- è´Ÿè´£æŒä¹…åŒ–å­˜å‚¨ï¼Œå¯ä»¥è·¨ Workflow / Agent ä¿å­˜ä¿¡æ¯ã€‚å¯ä»¥ç”¨æ¥å­˜ç”¨æˆ·åå¥½ã€ä»¥å‰ç®—è¿‡çš„ç»Ÿè®¡å€¼ç­‰ã€‚\n\nä»¥ä¸‹ä¸‰ä¸ªä¾‹å­ï¼Œåˆ†åˆ«æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ¥è‡ª Runtimeã€Stateã€Store ä¸­çš„ä¸Šä¸‹æ–‡ï¼Œç¼–å†™è§¦å‘æ¡ä»¶ã€‚","type":"content","url":"/context#id","position":3},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹","lvl3":"1ï¼‰ä½¿ç”¨ State ç®¡ç†ä¸Šä¸‹æ–‡","lvl2":"ä¸€ã€åŠ¨æ€ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯"},"type":"lvl3","url":"/context#id-1-state","position":4},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹","lvl3":"1ï¼‰ä½¿ç”¨ State ç®¡ç†ä¸Šä¸‹æ–‡","lvl2":"ä¸€ã€åŠ¨æ€ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯"},"content":"åˆ©ç”¨ State ä¸­è•´å«çš„ä¿¡æ¯æ“çºµ system prompt.\n\n@dynamic_prompt\ndef state_aware_prompt(request: ModelRequest) -> str:\n    # request.messages is a shortcut for request.state[\"messages\"]\n    message_count = len(request.messages)\n\n    base = \"You are a helpful assistant.\"\n\n    if message_count > 6:\n        base += \"\\nThis is a long conversation - be extra concise.\"\n\n    # ä¸´æ—¶æ‰“å°baseçœ‹æ•ˆæœ\n    print(base)\n\n    return base\n\nagent = create_agent(\n    model=llm,\n    middleware=[state_aware_prompt]\n)\n\nresult = agent.invoke(\n    {\"messages\": [\n        {\"role\": \"user\", \"content\": \"å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"},\n        {\"role\": \"assistant\", \"content\": \"å¹¿å·å¤©æ°”å¾ˆå¥½\"},\n        {\"role\": \"user\", \"content\": \"åƒç‚¹ä»€ä¹ˆå¥½å‘¢\"},\n        {\"role\": \"assistant\", \"content\": \"è¦ä¸è¦åƒé¦™èŒ…é³—é±¼ç…²\"},\n        {\"role\": \"user\", \"content\": \"é¦™èŒ…æ˜¯ä»€ä¹ˆ\"},\n        {\"role\": \"assistant\", \"content\": \"é¦™èŒ…åˆåæŸ æª¬è‰ï¼Œå¸¸è§äºæ³°å¼å†¬é˜´åŠŸæ±¤ã€è¶Šå—çƒ¤è‚‰\"},\n        {\"role\": \"user\", \"content\": \"auv é‚£è¿˜ç­‰ä»€ä¹ˆï¼Œå’±åƒå»å§\"},\n    ]},\n)\n\nfor message in result['messages']:\n    message.pretty_print()\n\n\n\næŠŠ message_count > 6 é‡Œçš„ 6 æ”¹æˆ 7ï¼Œè¯•è¯•çœ‹ä¼šå‘ç”Ÿä»€ä¹ˆã€‚\n\n","type":"content","url":"/context#id-1-state","position":5},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹","lvl3":"2ï¼‰ä½¿ç”¨ Store ç®¡ç†ä¸Šä¸‹æ–‡","lvl2":"ä¸€ã€åŠ¨æ€ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯"},"type":"lvl3","url":"/context#id-2-store","position":6},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹","lvl3":"2ï¼‰ä½¿ç”¨ Store ç®¡ç†ä¸Šä¸‹æ–‡","lvl2":"ä¸€ã€åŠ¨æ€ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯"},"content":"\n\n@dataclass\nclass Context:\n    user_id: str\n\n@dynamic_prompt\ndef store_aware_prompt(request: ModelRequest) -> str:\n    user_id = request.runtime.context.user_id\n\n    # Read from Store: get user preferences\n    store = request.runtime.store\n    user_prefs = store.get((\"preferences\",), user_id)\n\n    base = \"You are a helpful assistant.\"\n\n    if user_prefs:\n        style = user_prefs.value.get(\"communication_style\", \"balanced\")\n        base += f\"\\nUser prefers {style} responses.\"\n\n    return base\n\nstore = InMemoryStore()\n\nagent = create_agent(\n    model=llm,\n    middleware=[store_aware_prompt],\n    context_schema=Context,\n    store=store,\n)\n\n# é¢„ç½®ä¸¤æ¡åå¥½ä¿¡æ¯\nstore.put((\"preferences\",), \"user_1\", {\"communication_style\": \"Chinese\"})\nstore.put((\"preferences\",), \"user_2\", {\"communication_style\": \"Korean\"})\n\n\n\n# ç”¨æˆ·1å–œæ¬¢ä¸­æ–‡å›å¤\nresult = agent.invoke(\n    {\"messages\": [\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Please be extra concise.\"},\n        {\"role\": \"user\", \"content\": 'What is a \"hold short line\"?'}\n    ]},\n    context=Context(user_id=\"user_1\"),\n)\n\nfor message in result['messages']:\n    message.pretty_print()\n\n\n\n# ç”¨æˆ·2å–œæ¬¢éŸ©æ–‡å›å¤\nresult = agent.invoke(\n    {\"messages\": [\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Please be extra concise.\"},\n        {\"role\": \"user\", \"content\": 'What is a \"hold short line\"?'}\n    ]},\n    context=Context(user_id=\"user_2\"),\n)\n\nfor message in result['messages']:\n    message.pretty_print()\n\n\n\n","type":"content","url":"/context#id-2-store","position":7},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹","lvl3":"3ï¼‰ä½¿ç”¨ Runtime ç®¡ç†ä¸Šä¸‹æ–‡","lvl2":"ä¸€ã€åŠ¨æ€ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯"},"type":"lvl3","url":"/context#id-3-runtime","position":8},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹","lvl3":"3ï¼‰ä½¿ç”¨ Runtime ç®¡ç†ä¸Šä¸‹æ–‡","lvl2":"ä¸€ã€åŠ¨æ€ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯"},"content":"\n\n@dataclass\nclass Context:\n    user_role: str\n    deployment_env: str\n\n@dynamic_prompt\ndef context_aware_prompt(request: ModelRequest) -> str:\n    # Read from Runtime Context: user role and environment\n    user_role = request.runtime.context.user_role\n    env = request.runtime.context.deployment_env\n\n    base = \"You are a helpful assistant.\"\n\n    if user_role == \"admin\":\n        base += \"\\nYou can use the get_weather tool.\"\n    else:\n        base += \"\\nYou are prohibited from using the get_weather tool.\"\n\n    if env == \"production\":\n        base += \"\\nBe extra careful with any data modifications.\"\n\n    return base\n\n@tool\ndef get_weather(city: str) -> str:\n    \"\"\"Get weather for a given city.\"\"\"\n    return f\"It's always sunny in {city}!\"\n\nagent = create_agent(\n    model=llm,\n    tools=[get_weather],\n    middleware=[context_aware_prompt],\n    context_schema=Context,\n    checkpointer=InMemorySaver(),\n)\n\n\n\n# åˆ©ç”¨ Runtime ä¸­çš„ä¸¤ä¸ªå˜é‡ï¼ŒåŠ¨æ€æ§åˆ¶ System prompt\n# å°† user_role è®¾ä¸º adminï¼Œå…è®¸ä½¿ç”¨å¤©æ°”æŸ¥è¯¢å·¥å…·\nconfig = {'configurable': {'thread_id': str(uuid.uuid4())}}\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}]},\n    context=Context(user_role=\"admin\", deployment_env=\"production\"),\n    config=config,\n)\n\nfor message in result['messages']:\n    message.pretty_print()\n\n\n\n# è‹¥å°† user_role æ”¹ä¸º viewerï¼Œåˆ™æ— æ³•ä½¿ç”¨å¤©æ°”æŸ¥è¯¢å·¥å…·\nconfig = {'configurable': {'thread_id': str(uuid.uuid4())}}\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}]},\n    context=Context(user_role=\"viewer\", deployment_env=\"production\"),\n    config=config,\n)\n\nfor message in result['messages']:\n    message.pretty_print()\n\n\n\nresult['messages']\n\n\n\n","type":"content","url":"/context#id-3-runtime","position":9},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹","lvl2":"äºŒã€åŠ¨æ€ä¿®æ”¹æ¶ˆæ¯åˆ—è¡¨"},"type":"lvl2","url":"/context#id-1","position":10},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹","lvl2":"äºŒã€åŠ¨æ€ä¿®æ”¹æ¶ˆæ¯åˆ—è¡¨"},"content":"LangGraph é¢„åˆ¶äº†åŠ¨æ€ä¿®æ”¹æ¶ˆæ¯åˆ—è¡¨ï¼ˆMessagesï¼‰çš„ä¸­é—´ä»¶ @wrap_model_callã€‚ä¸Šä¸€èŠ‚å·²ç»æ¼”ç¤ºå¦‚ä½•ä» Stateã€Storeã€Runtime ä¸­è·å–ä¸Šä¸‹æ–‡ï¼Œæœ¬èŠ‚å°†ä¸å†ä¸€ä¸€æ¼”ç¤ºã€‚åœ¨ä¸‹é¢è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ Runtime å°†æœ¬åœ°æ–‡ä»¶çš„å†…å®¹æ³¨å…¥æ¶ˆæ¯åˆ—è¡¨ã€‚\n\n@dataclass\nclass FileContext:\n    uploaded_files: list[dict]\n\n@wrap_model_call\ndef inject_file_context(\n    request: ModelRequest,\n    handler: Callable[[ModelRequest], ModelResponse]\n) -> ModelResponse:\n    \"\"\"Inject context about files user has uploaded this session.\"\"\"\n    uploaded_files = request.runtime.context.uploaded_files\n\n    try:\n        base_dir = os.path.dirname(os.path.abspath(__file__))\n    except Exception as e:\n        import ipynbname\n        import os\n        notebook_path = ipynbname.path()\n        base_dir = os.path.dirname(notebook_path)\n\n    file_sections = []\n    for file in uploaded_files:\n        name, ftype = \"\", \"\"\n        path = file.get(\"path\")\n        if path:\n            base_filename = os.path.basename(path)\n            stem, ext = os.path.splitext(base_filename)\n            name = stem or base_filename\n            ftype = (ext.lstrip(\".\") if ext else None)\n\n            # æ„å»ºæ–‡ä»¶æè¿°å†…å®¹\n            content_list = [f\"åç§°: {name}\"]\n            if ftype:\n                content_list.append(f\"ç±»å‹: {ftype}\")\n\n            # è§£æç›¸å¯¹è·¯å¾„ä¸ºç»å¯¹è·¯å¾„\n            abs_path = path if os.path.isabs(path) else os.path.join(base_dir, path)\n\n            # è¯»å–æ–‡ä»¶å†…å®¹\n            content_block = \"\"\n            if abs_path and os.path.exists(abs_path):\n                try:\n                    with open(abs_path, \"r\", encoding=\"utf-8\") as f:\n                        content_block = f.read()\n                except Exception as e:\n                    content_block = f\"[è¯»å–æ–‡ä»¶é”™è¯¯ '{abs_path}': {e}]\"\n            else:\n                content_block = \"[æ–‡ä»¶è·¯å¾„ç¼ºå¤±æˆ–æœªæ‰¾åˆ°]\"\n\n            section = (\n                f\"---\\n\"\n                f\"{chr(10).join(content_list)}\\n\\n\"\n                f\"{content_block}\\n\"\n                f\"---\"\n            )\n            file_sections.append(section)\n\n        file_context = (\n            \"å·²åŠ è½½çš„ä¼šè¯æ–‡ä»¶ï¼š\\n\"\n            f\"{chr(10).join(file_sections)}\"\n            \"\\nå›ç­”é—®é¢˜æ—¶è¯·å‚è€ƒè¿™äº›æ–‡ä»¶ã€‚\"\n        )\n\n        # Inject file context before recent messages\n        messages = [  \n            *request.messages,\n            {\"role\": \"user\", \"content\": file_context},\n        ]\n        request = request.override(messages=messages)  \n\n    return handler(request)\n\nagent = create_agent(\n    model=llm,\n    middleware=[inject_file_context],\n    context_schema=FileContext,\n)\n\n\n\nresult = agent.invoke(\n    {\n        \"messages\": [{\n            \"role\": \"user\",\n            \"content\": \"å…³äºä¸Šæµ·åœ°é“çš„æ— è„¸ä¹˜å®¢ï¼Œæœ‰ä»€ä¹ˆéœ€è¦æ³¨æ„çš„ï¼Ÿ\",\n        }],\n    },\n    context=FileContext(uploaded_files=[{\"path\": \"./docs/rule_horror.md\"}]),\n)\n\nfor message in result['messages']:\n    message.pretty_print()\n\n\n\n","type":"content","url":"/context#id-1","position":11},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹","lvl2":"ä¸‰ã€åœ¨å·¥å…·ä¸­ä½¿ç”¨ä¸Šä¸‹æ–‡"},"type":"lvl2","url":"/context#id-2","position":12},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹","lvl2":"ä¸‰ã€åœ¨å·¥å…·ä¸­ä½¿ç”¨ä¸Šä¸‹æ–‡"},"content":"ä¸‹é¢ï¼Œæˆ‘ä»¬å°è¯•åœ¨å·¥å…·ä¸­ä½¿ç”¨å­˜å‚¨åœ¨ SqliteStore ä¸­çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚\n\n# åˆ é™¤SQLiteæ•°æ®åº“\nif os.path.exists(\"user-info.db\"):\n    os.remove(\"user-info.db\")\n\n# åˆ›å»ºSQLiteå­˜å‚¨\nconn = sqlite3.connect(\"user-info.db\", check_same_thread=False, isolation_level=None)\nconn.execute(\"PRAGMA journal_mode=WAL;\")\nconn.execute(\"PRAGMA busy_timeout = 30000;\")\n\nstore = SqliteStore(conn)\n\n# é¢„ç½®ä¸¤æ¡ç”¨æˆ·ä¿¡æ¯\nstore.put((\"user_info\",), \"æŸ³å¦‚çƒŸ\", {\"description\": \"æ¸…å†·æ‰å¥³ï¼Œèº«æ€€ç»æŠ€ï¼Œä¸ºå¯»èº«ä¸–ä¹‹è°œè¸å…¥æ±Ÿæ¹–ã€‚\", \"birthplace\": \"å´å…´å¿\"})\nstore.put((\"user_info\",), \"è‹æ…•ç™½\", {\"description\": \"å­¤å‚²å‰‘å®¢ï¼Œå‰‘æ³•è¶…ç¾¤ï¼ŒèƒŒè´Ÿå®¶æ—è¡€ä»‡ï¼Œéšäºå¸‚äº•è¿½å¯»çœŸç›¸ã€‚\", \"birthplace\": \"æ­å¿\"})\n\n\n\n","type":"content","url":"/context#id-2","position":13},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹","lvl3":"1ï¼‰åŸºç¡€ç”¨ä¾‹","lvl2":"ä¸‰ã€åœ¨å·¥å…·ä¸­ä½¿ç”¨ä¸Šä¸‹æ–‡"},"type":"lvl3","url":"/context#id-1-1","position":14},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹","lvl3":"1ï¼‰åŸºç¡€ç”¨ä¾‹","lvl2":"ä¸‰ã€åœ¨å·¥å…·ä¸­ä½¿ç”¨ä¸Šä¸‹æ–‡"},"content":"ä½¿ç”¨ ToolRuntime\n\n@tool\ndef fetch_user_data(\n    user_id: str,\n    runtime: ToolRuntime\n) -> str:\n    \"\"\"\n    Fetch user information from the in-memory store.\n\n    :param user_id: The unique identifier of the user.\n    :param runtime: The tool runtime context injected by the framework.\n    :return: The user's description string if found; an empty string otherwise.\n    \"\"\"\n    store = runtime.store\n    user_info = store.get((\"user_info\",), user_id)\n\n    user_desc = \"\"\n    if user_info:\n        user_desc = user_info.value.get(\"description\", \"\")\n\n    return user_desc\n\nagent = create_agent(\n    model=llm,\n    tools=[fetch_user_data],\n    store=store,\n)\n\n\n\nresult = agent.invoke({\n    \"messages\": [{\n        \"role\": \"user\",\n        \"content\": \"äº”åˆ†é’Ÿä¹‹å†…ï¼Œæˆ‘è¦æŸ³å¦‚çƒŸçš„å…¨éƒ¨ä¿¡æ¯\"\n    }]\n})\n\nfor message in result['messages']:\n    message.pretty_print()\n\n\n\n","type":"content","url":"/context#id-1-1","position":15},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹","lvl3":"2ï¼‰å¤æ‚ä¸€ç‚¹çš„ä¾‹å­","lvl2":"ä¸‰ã€åœ¨å·¥å…·ä¸­ä½¿ç”¨ä¸Šä¸‹æ–‡"},"type":"lvl3","url":"/context#id-2-1","position":16},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹","lvl3":"2ï¼‰å¤æ‚ä¸€ç‚¹çš„ä¾‹å­","lvl2":"ä¸‰ã€åœ¨å·¥å…·ä¸­ä½¿ç”¨ä¸Šä¸‹æ–‡"},"content":"ä½¿ç”¨ ToolRuntime[Context]\n\n@dataclass\nclass Context:\n    key: str\n\n@tool\ndef fetch_user_data(\n    user_id: str,\n    runtime: ToolRuntime[Context]\n) -> str:\n    \"\"\"\n    Fetch user information from the in-memory store.\n\n    :param user_id: The unique identifier of the user.\n    :param runtime: The tool runtime context injected by the framework.\n    :return: The user's description string if found; an empty string otherwise.\n    \"\"\"\n    key = runtime.context.key\n\n    store = runtime.store\n    user_info = store.get((\"user_info\",), user_id)\n\n    user_desc = \"\"\n    if user_info:\n        user_desc = user_info.value.get(key, \"\")\n\n    return f\"{key}: {user_desc}\"\n\nagent = create_agent(\n    model=llm,\n    tools=[fetch_user_data],\n    store=store,\n)\n\n\n\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"äº”åˆ†é’Ÿä¹‹å†…ï¼Œæˆ‘è¦æŸ³å¦‚çƒŸçš„å…¨éƒ¨ä¿¡æ¯\"}]},\n    context=Context(key=\"birthplace\"),\n)\n\nfor message in result['messages']:\n    message.pretty_print()\n\n\n\n","type":"content","url":"/context#id-2-1","position":17},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹","lvl3":"å››ã€å‹ç¼©ä¸Šä¸‹æ–‡","lvl2":"ä¸‰ã€åœ¨å·¥å…·ä¸­ä½¿ç”¨ä¸Šä¸‹æ–‡"},"type":"lvl3","url":"/context#id-3","position":18},{"hierarchy":{"lvl1":"ä¸Šä¸‹æ–‡å·¥ç¨‹","lvl3":"å››ã€å‹ç¼©ä¸Šä¸‹æ–‡","lvl2":"ä¸‰ã€åœ¨å·¥å…·ä¸­ä½¿ç”¨ä¸Šä¸‹æ–‡"},"content":"LangChain æä¾›äº†å†…ç½®çš„ä¸­é—´ä»¶ SummarizationMiddleware ç”¨äºå‹ç¼©ä¸Šä¸‹æ–‡ã€‚è¯¥ä¸­é—´ä»¶ç»´æŠ¤çš„æ˜¯å…¸å‹çš„ ç”Ÿå‘½å‘¨æœŸä¸Šä¸‹æ–‡ï¼Œä¸ æ¨¡å‹ä¸Šä¸‹æ–‡ å’Œ å·¥å…·ä¸Šä¸‹æ–‡ çš„ç¬æ€æ›´æ–°ä¸åŒï¼Œç”Ÿå‘½å‘¨æœŸä¸Šä¸‹æ–‡ä¼šæŒç»­æ›´æ–°ï¼šæŒç»­å°†æ—§æ¶ˆæ¯æ›¿æ¢ä¸ºæ‘˜è¦ã€‚\n\né™¤éä¸Šä¸‹æ–‡è¶…é•¿ï¼Œå¯¼è‡´æ¨¡å‹èƒ½åŠ›é™ä½ï¼Œå¦åˆ™ä¸éœ€è¦ä½¿ç”¨ SummarizationMiddlewareã€‚ä¸€èˆ¬æ¥è¯´ï¼Œè§¦å‘æ‘˜è¦å¾—å€¼å¯ä»¥è®¾å¾—è¾ƒå¤§ã€‚æ¯”å¦‚ï¼š\n\nmax_tokens_before_summary: 3000\n\nmessages_to_keep: 20\n\nå¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºä¸Šä¸‹æ–‡è…åï¼ˆContext Rotï¼‰çš„ä¿¡æ¯ï¼ŒChroma å›¢é˜Ÿåœ¨ 2025 å¹´ 7 æœˆ 14 æ—¥å‘å¸ƒçš„ \n\nContext Rot: How Increasing Input Tokens Impacts LLM Performanceï¼Œç³»ç»Ÿæ€§åœ°æ­ç¤ºäº†é•¿ä¸Šä¸‹æ–‡å¯¼è‡´æ¨¡å‹æ€§èƒ½é€€åŒ–çš„ç°è±¡ã€‚\n\n# åˆ›å»ºçŸ­æœŸè®°å¿†\ncheckpointer = InMemorySaver()\n\n# åˆ›å»ºå¸¦å†…ç½®æ‘˜è¦ä¸­é—´ä»¶çš„Agent\n# ä¸ºäº†è®©é…ç½®èƒ½åœ¨æˆ‘ä»¬çš„ä¾‹å­é‡Œç”Ÿæ•ˆï¼Œè¿™é‡Œçš„è§¦å‘å€¼è®¾å¾—å¾ˆå°\nagent = create_agent(\n    model=llm,\n    middleware=[\n        SummarizationMiddleware(\n            model=llm,\n            max_tokens_before_summary=40,  # Trigger summarization at 40 tokens\n            messages_to_keep=1,  # Keep last 1 messages after summary\n        ),\n    ],\n)\n\n\n\nresult = agent.invoke(\n    {\"messages\": [\n        {\"role\": \"user\", \"content\": \"å¹¿å·ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"},\n        {\"role\": \"assistant\", \"content\": \"å¹¿å·å¤©æ°”å¾ˆå¥½\"},\n        {\"role\": \"user\", \"content\": \"åƒç‚¹ä»€ä¹ˆå¥½å‘¢\"},\n        {\"role\": \"assistant\", \"content\": \"è¦ä¸è¦åƒé¦™èŒ…é³—é±¼ç…²\"},\n        {\"role\": \"user\", \"content\": \"é¦™èŒ…æ˜¯ä»€ä¹ˆ\"},\n        {\"role\": \"assistant\", \"content\": \"é¦™èŒ…åˆåæŸ æª¬è‰ï¼Œå¸¸è§äºæ³°å¼å†¬é˜´åŠŸæ±¤ã€è¶Šå—çƒ¤è‚‰\"},\n        {\"role\": \"user\", \"content\": \"auv é‚£è¿˜ç­‰ä»€ä¹ˆï¼Œå’±åƒå»å§\"},\n    ]},\n    checkpointer=checkpointer,\n)\n\nfor message in result['messages']:\n    message.pretty_print()\n\n","type":"content","url":"/context#id-3","position":19},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨"},"type":"lvl1","url":"/mcp-server","position":0},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨"},"content":"æœ¬èŠ‚ï¼Œæˆ‘ä»¬å°†åœ¨ LangGraph ä¸­æ¥å…¥ MCP Serverã€‚åœ¨æ¥å…¥ MCP Server ä¹‹å‰ï¼Œå¿…é¡»å¾—æœ‰ MCP Serverã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬å¾—å¼€å‘ä¸€ä¸ª MCP Serverã€‚è¿™å¯æ˜¯æˆ‘çš„è€æœ¬è¡Œã€‚åœ¨\n\nã€Šæ–°ç“¶è£…æ—§é…’ï¼šçº¸ç‰Œé­”æœ¯ MCPã€‹ä¸€æ–‡ä¸­ï¼Œæˆ‘å·²ç»æ€»ç»“å‡ºä¸€å¥—é«˜æ•ˆçš„å¼€å‘æ–¹æ³•äº†ã€‚åˆ›å»º MCP Server çš„å®Œæ•´ä»£ç ï¼Œæˆ‘æ”¾åœ¨ä»“åº“çš„ \n\nmcp_server è·¯å¾„ä¸‹ï¼Œå¦‚æœ‰å…´è¶£å¯å¾€ä¸€è§‚ã€‚","type":"content","url":"/mcp-server","position":1},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl2":"ä¸€ã€å¼€å‘ MCP æœåŠ¡"},"type":"lvl2","url":"/mcp-server#id-mcp","position":2},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl2":"ä¸€ã€å¼€å‘ MCP æœåŠ¡"},"content":"","type":"content","url":"/mcp-server#id-mcp","position":3},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl3":"1ï¼‰å¤©æ°” MCP","lvl2":"ä¸€ã€å¼€å‘ MCP æœåŠ¡"},"type":"lvl3","url":"/mcp-server#id-1-mcp","position":4},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl3":"1ï¼‰å¤©æ°” MCP","lvl2":"ä¸€ã€å¼€å‘ MCP æœåŠ¡"},"content":"ä»¥ get_weather_mcp ä¸ºä¾‹ï¼Œæˆ‘ä»¬è¦æŠŠè¿™ä¸ª MCP å†™æˆä¸€ä¸ª Python åŒ…ã€‚å½“ç„¶ä»…ä¾›æœ¬åœ°ä½¿ç”¨ï¼Œå¦‚æœä½ æƒ³ä¼ åˆ° PyPI ä¸Šå½“ç„¶å¯ä»¥ï¼Œä½†é‚£å°±æ˜¯å¦å¤–çš„æµç¨‹äº†ï¼Œæ•¬è¯·å‚è€ƒæˆ‘çš„åšå®¢ \n\nã€ŠPyPI æ‰“åŒ…å°è®°ã€‹ã€‚\n\nä¸ºäº†è®©å®ƒè¢«è¯†åˆ«ä¸º Python åŒ…ï¼Œæˆ‘ä»¬è¦åœ¨é¡¹ç›®ä¸‹ï¼Œæ–°å»ºä¸€ä¸ª __init__.py æ–‡ä»¶ã€‚ç„¶åæŠŠä¸»é€»è¾‘å†™åœ¨ server.py ä¸­ï¼Œæ¥ç€åœ¨ __main__.py ä¸­ä½¿ç”¨ from . import server å¼•å…¥å®ƒã€‚æœ€åç”¨ streamable-http çš„æ–¹å¼éƒ¨ç½²å®ƒï¼šdef http():\n    \"\"\"streamable-http entry point for the package.\"\"\"\n    asyncio.run(server.mcp.run(transport=\"http\",\n                               host=host,\n                               port=port,\n                               path=\"/mcp\"))\n\nå†™åˆ°è¿™é‡Œå°±é½æ´»äº†ã€‚è¿™é‡Œä½¿ç”¨ __main__.py æ˜¯æœ‰å°å·§æ€çš„ï¼Œè¿™æ ·æˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªåŒ…ä½œä¸ºæ¨¡å—ç›´æ¥åœ¨å‘½ä»¤è¡Œä½¿ç”¨ã€‚ä»€ä¹ˆæ„æ€å‘¢ï¼Ÿå°±æ˜¯æˆ‘ä»¬ç”¨ python -m [åŒ…å] å°±ç­‰äºç›´æ¥è¿è¡Œäº† __main__.py è¿™ä¸ªç‰¹æ®Šæ–‡ä»¶ã€‚ç”±äºæˆ‘ä»¬å…ˆå‰åœ¨è¯¥ç‰¹æ®Šæ–‡ä»¶ä¸­å¯åŠ¨äº† http() å‡½æ•°ï¼Œè¿™æ ·å°±èƒ½å¿«æ·æ–¹ä¾¿åœ°æŠŠ MCP Server å¯åŠ¨èµ·æ¥äº†ï¼å¯¹äºæˆ‘ä»¬çš„ get_weather_mcpï¼Œå¯åŠ¨å‘½ä»¤å¦‚ä¸‹ï¼špython -m get_weather_mcp","type":"content","url":"/mcp-server#id-1-mcp","position":5},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl3":"2ï¼‰ç®—æ•° MCP","lvl2":"ä¸€ã€å¼€å‘ MCP æœåŠ¡"},"type":"lvl3","url":"/mcp-server#id-2-mcp","position":6},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl3":"2ï¼‰ç®—æ•° MCP","lvl2":"ä¸€ã€å¼€å‘ MCP æœåŠ¡"},"content":"è¿™è¿˜éœ€è¦èµ˜è¿°å—ï¼Ÿå¼€å‘æµç¨‹ç…§æŠ„ä¸Šé¢çš„æ­¥éª¤ã€‚\n\nçœŸçš„æ˜¯è¶…çº§æ¨¡ç‰ˆåŒ–ã€‚__init__.py å’Œ __main__.py å‡ ä¹å®Œå…¨ç›¸åŒã€‚\n\nå”¯ä¸€éœ€è¦æ”¹åŠ¨çš„æ˜¯ __main__.pyã€‚éœ€è¦æŠŠç«¯å£ port æ”¹æˆæ–°å·ç ï¼Œä¸€èˆ¬æ¥è¯´åŠ  1 å°±è¡Œã€‚è¿™é‡Œæˆ‘ä»¬æŠŠ 8000 æ”¹æˆ 8001ï¼Œå…¶ä»–ä¸å˜ï¼š# -*- coding: utf-8 -*-\nimport asyncio\nimport os\n\nfrom . import server\n\n\nhost = os.getenv('HOST', '127.0.0.1')\nport = int(os.getenv('PORT', 8001))\n\n\ndef stdio():\n    \"\"\"Stdio entry point for the package.\"\"\"\n    asyncio.run(server.mcp.run(transport=\"stdio\"))\n\n\ndef http():\n    \"\"\"streamable-http entry point for the package.\"\"\"\n    asyncio.run(server.mcp.run(transport=\"http\",\n                               host=host,\n                               port=port,\n                               path=\"/mcp\"))\n\n\nif __name__ == \"__main__\":\n    http()","type":"content","url":"/mcp-server#id-2-mcp","position":7},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl3":"äºŒã€ä½¿ç”¨ supervisord ç®¡ç† MCP æœåŠ¡","lvl2":"ä¸€ã€å¼€å‘ MCP æœåŠ¡"},"type":"lvl3","url":"/mcp-server#id-supervisord-mcp","position":8},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl3":"äºŒã€ä½¿ç”¨ supervisord ç®¡ç† MCP æœåŠ¡","lvl2":"ä¸€ã€å¼€å‘ MCP æœåŠ¡"},"content":"supervisord æ˜¯ä¸€ä¸ª è¿›ç¨‹ç®¡ç†å·¥å…·ã€‚ä½ å‘Šè¯‰å®ƒæœ‰å“ªäº› MCP è¦è·‘ï¼Œå®ƒä¼šå®ˆæŠ¤ä½ çš„ MCP å®å®ã€‚å½“ MCP æŒ‚æ‰çš„æ—¶å€™ï¼Œsupervisord èƒ½å¤Ÿè‡ªåŠ¨æ‹‰èµ· MCPã€‚è¿™äº›å†…å®¹åœ¨æˆ‘çš„åšå®¢ \n\nã€Šåå°ç®¡ç†å·¥å…·ä»‹ç»ã€‹ ä¸­æœ‰åšç®€ç•¥çš„ä»‹ç»ï¼ˆä½†æ›´å¤šæ˜¯å…³äº systemd å’Œ pm2 çš„ï¼‰ã€‚\n\né¦–å…ˆï¼Œæˆ‘ä»¬æ‰“å¼€é¡¹ç›®çš„ mcp_server è·¯å¾„ï¼Œåœ¨è¿™é‡Œåˆ›å»ºä¸€ä¸ªé…ç½®æ–‡ä»¶ mcp_supervisor.confï¼Œæ¥ç»™ supervisord ä½¿ç”¨ã€‚æˆ‘çš„é…ç½®å¦‚ä¸‹ï¼š[unix_http_server]\nfile=/tmp/supervisor.sock\n\n[supervisord]\nlogfile=/tmp/supervisord.log\nlogfile_maxbytes=50MB\nlogfile_backups=10\nloglevel=info\npidfile=/tmp/supervisord.pid\nnodaemon=false\nminfds=1024\nminprocs=200\n\n[rpcinterface:supervisor]\nsupervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface\n\n[supervisorctl]\nserverurl=unix:///tmp/supervisor.sock\n\n[program:math_mcp]\ncommand=python -m mcp_server.math_mcp\ndirectory=..\nautostart=true\nautorestart=true\nstartsecs=5\nstopwaitsecs=10\nstdout_logfile=/tmp/math_mcp.log\nstderr_logfile=/tmp/math_mcp_err.log\n\n[program:weather_mcp]\ncommand=python -m mcp_server.get_weather_mcp\ndirectory=..\nautostart=true\nautorestart=true\nstartsecs=5\nstopwaitsecs=10\nstdout_logfile=/tmp/weather_mcp.log\nstderr_logfile=/tmp/weather_mcp_err.log\n\n[group:mcp_servers]\nprograms=math_mcp,weather_mcp\n\nè‡³æ­¤ï¼Œmath_mcpã€weather_mcp çš„é…ç½®å°±å®Œæˆäº†ã€‚è¿™ç§ä¸œè¥¿æ²¡å¿…è¦è‡ªå·±å†™ï¼Œæˆ‘è®© \n\nTRAE å¸®æˆ‘å†™çš„ã€‚ä¸‹é¢æ˜¯å…³äºå¸¸ç”¨å‘½ä»¤çš„è¯´æ˜ï¼","type":"content","url":"/mcp-server#id-supervisord-mcp","position":9},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl3":"1ï¼‰å®‰è£… supervisord","lvl2":"ä¸€ã€å¼€å‘ MCP æœåŠ¡"},"type":"lvl3","url":"/mcp-server#id-1-supervisord","position":10},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl3":"1ï¼‰å®‰è£… supervisord","lvl2":"ä¸€ã€å¼€å‘ MCP æœåŠ¡"},"content":"pip install supervisor","type":"content","url":"/mcp-server#id-1-supervisord","position":11},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl3":"2ï¼‰å¯åŠ¨ supervisord","lvl2":"ä¸€ã€å¼€å‘ MCP æœåŠ¡"},"type":"lvl3","url":"/mcp-server#id-2-supervisord","position":12},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl3":"2ï¼‰å¯åŠ¨ supervisord","lvl2":"ä¸€ã€å¼€å‘ MCP æœåŠ¡"},"content":"supervisord -c ./mcp_supervisor.conf","type":"content","url":"/mcp-server#id-2-supervisord","position":13},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl3":"3ï¼‰å…³é—­ supervisord","lvl2":"ä¸€ã€å¼€å‘ MCP æœåŠ¡"},"type":"lvl3","url":"/mcp-server#id-3-supervisord","position":14},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl3":"3ï¼‰å…³é—­ supervisord","lvl2":"ä¸€ã€å¼€å‘ MCP æœåŠ¡"},"content":"pkill -f supervisord","type":"content","url":"/mcp-server#id-3-supervisord","position":15},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl3":"4ï¼‰æ£€æŸ¥ç«¯å£çŠ¶æ€","lvl2":"ä¸€ã€å¼€å‘ MCP æœåŠ¡"},"type":"lvl3","url":"/mcp-server#id-4","position":16},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl3":"4ï¼‰æ£€æŸ¥ç«¯å£çŠ¶æ€","lvl2":"ä¸€ã€å¼€å‘ MCP æœåŠ¡"},"content":"lsof -i :8000\nlsof -i :8001\n\n","type":"content","url":"/mcp-server#id-4","position":17},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl2":"ä¸‰ã€åœ¨ LangGraph ä¸­ä½¿ç”¨ MCP"},"type":"lvl2","url":"/mcp-server#id-langgraph-mcp","position":18},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl2":"ä¸‰ã€åœ¨ LangGraph ä¸­ä½¿ç”¨ MCP"},"content":"åœ¨ä½¿ç”¨ä¹‹å‰ï¼Œéœ€è¦å®‰è£…é…é€‚è¯¥åŠŸèƒ½çš„ Python åŒ…ï¼špip install langchain-mcp-adapters\n\næˆ‘ä¹Ÿæ˜¯æœäº†å¼€å‘å›¢é˜Ÿï¼Œä¾æˆ‘çœ‹ LangChainã€LangGraph ä¸å¦‚åˆæˆä¸€ä¸ªåŒ…ã€‚è¿˜è¦æˆ‘ä»¬å»åŠŸèƒ½åœ¨å“ªä¸ªåŒ…é‡Œï¼ŒçœŸè´¹åŠ²ï¼è€Œä¸”å„ç§åŠŸèƒ½ä¹Ÿè¢«æ‹†å¾—ç¨€ç¢ï¼Œçœ‹çœ‹æˆ‘åˆ°ç›®å‰ä¸ºæ­¢éƒ½å®‰è£…å¤šå°‘åŒ…äº†ï¼šlangchain[openai]\nlangchain-mcp-adapters\nlanggraph\nlanggraph-cli[inmem]\nlanggraph-supervisor\nlanggraph-checkpoint-sqlite\n\nè‹¥é LangGraph 1.0 æ›´æ–°äº†ä¸å°‘å¥½åŠŸèƒ½ï¼Œæˆ‘æ˜¯æ‰“å¿ƒçœ¼é‡Œçœ‹ä¸ä¸Šè¿™ä¸ªå¼€æºé¡¹ç›®ã€‚è¡·å¿ƒç¥æ„¿åèµ·ä¹‹ç§€ \n\nAgentScope å¸æ”¶ LangGraph 1.0 çš„é•¿å¤„å¹¶è¶…è¶Šå®ƒã€‚å½“ç„¶åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘ä»¬å¾—æ‰¿è®¤ LangGraph çš„åœ°ä½ã€‚å®ƒè™½ä¸å®Œç¾ï¼Œä½†ä¾ç„¶æ˜¯æœ€å¼ºå¤§çš„é‚£ä¸ªã€‚","type":"content","url":"/mcp-server#id-langgraph-mcp","position":19},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl3":"1ï¼‰å¯åŠ¨ MCP æœåŠ¡","lvl2":"ä¸‰ã€åœ¨ LangGraph ä¸­ä½¿ç”¨ MCP"},"type":"lvl3","url":"/mcp-server#id-1-mcp-1","position":20},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl3":"1ï¼‰å¯åŠ¨ MCP æœåŠ¡","lvl2":"ä¸‰ã€åœ¨ LangGraph ä¸­ä½¿ç”¨ MCP"},"content":"æˆ‘ä»¬åªå¯åŠ¨å¤©æ°” MCPã€‚ç®—æ•° MCP ç¨åæˆ‘ä»¬å°†ä»¥ stdio çš„æ–¹å¼è°ƒç”¨ï¼Œæ— éœ€å•ç‹¬å¯åŠ¨æœåŠ¡ã€‚\n\nå¯åŠ¨ get_weather_mcpï¼špython -m mcp_server.get_weather_mcp \n\næµ‹è¯• MCP Server æ˜¯å¦æˆåŠŸå¯åŠ¨ï¼š\n\n# !lsof -i :8000\n\n\n\n","type":"content","url":"/mcp-server#id-1-mcp-1","position":21},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl3":"2ï¼‰æ¥å…¥ MCP æœåŠ¡","lvl2":"ä¸‰ã€åœ¨ LangGraph ä¸­ä½¿ç”¨ MCP"},"type":"lvl3","url":"/mcp-server#id-2-mcp-1","position":22},{"hierarchy":{"lvl1":"MCPæœåŠ¡å™¨","lvl3":"2ï¼‰æ¥å…¥ MCP æœåŠ¡","lvl2":"ä¸‰ã€åœ¨ LangGraph ä¸­ä½¿ç”¨ MCP"},"content":"ä½¿ç”¨ MultiServerMCPClient æ¥å…¥ MCP Server.\n\nimport os\n\nfrom dotenv import load_dotenv\nfrom langchain_openai import ChatOpenAI\nfrom langchain_mcp_adapters.client import MultiServerMCPClient  \nfrom langchain.agents import create_agent\n\n# åŠ è½½æ¨¡å‹é…ç½®\n_ = load_dotenv()\n\n# åŠ è½½æ¨¡å‹\nllm = ChatOpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n    model=\"qwen3-coder-plus\",\n    temperature=0.7,\n)\n\nasync def mcp_agent():\n    # æˆ‘ä»¬ç”¨ä¸¤ç§æ–¹å¼å¯åŠ¨ MCP Serverï¼šstdio å’Œ streamable_http\n    client = MultiServerMCPClient(  \n        {\n            \"math\": {\n                \"command\": \"python\",\n                \"args\": [os.path.abspath(\"./mcp_server/math_mcp/server.py\")],\n                \"transport\": \"stdio\",\n            },\n            \"weather\": {\n                \"url\": \"http://localhost:8000/mcp\",\n                \"transport\": \"streamable_http\",\n            }\n        }\n    )\n    \n    tools = await client.get_tools()\n    agent = create_agent(\n        llm,\n        tools=tools,\n    )\n\n    return agent\n\nasync def use_mcp(messages):\n    agent = await mcp_agent()\n    response = await agent.ainvoke(messages)\n    return response\n\n\n\nåœ¨ Jupyter Notebook ä¸­ï¼Œä½¿ç”¨ response = await use_mcp(messages) å‘½ä»¤è°ƒç”¨å‡½æ•°ã€‚ä½†æ˜¯åœ¨ .py æ–‡ä»¶ä¸­ï¼Œè¿™ç§è°ƒç”¨æ–¹æ³•ä¼šå¤±è´¥ã€‚\n\n# è°ƒç”¨å¤©æ°” MCP\nmessages = {\"messages\": [{\"role\": \"user\", \"content\": \"ç¦å·å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}]}\nresponse = await use_mcp(messages)\nresponse[\"messages\"][-1].content\n\n\n\n# è°ƒç”¨ç®—æ•° MCPï¼Œç”±äºæ˜¯ stdioï¼Œå¯åŠ¨ä¼šæ…¢ä¸€ç‚¹\nmessages = {\"messages\": [{\"role\": \"user\", \"content\": \"è®¡ç®— (3 + 5) * 12\"}]}\nresponse = await use_mcp(messages)\nresponse[\"messages\"][-1].content\n\n\n\nåœ¨ .py æ–‡ä»¶ä¸­ï¼Œåº”è¯¥ä½¿ç”¨ asyncioï¼Œæ”¹åŠ¨éƒ¨åˆ†å¦‚ä¸‹ï¼šimport asyncio\n\nasync def main():\n    # è°ƒç”¨å¤©æ°” MCP\n    messages = {\"messages\": [{\"role\": \"user\", \"content\": \"ç¦å·å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}]}\n    response = await use_mcp(messages)\n    print(response[\"messages\"][-1].content)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n","type":"content","url":"/mcp-server#id-2-mcp-1","position":23},{"hierarchy":{"lvl1":"ç›‘ç£è€…æ¨¡å¼"},"type":"lvl1","url":"/supervisor","position":0},{"hierarchy":{"lvl1":"ç›‘ç£è€…æ¨¡å¼"},"content":"å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMAS, Multi-Agent Systemsï¼‰æœ‰å¾ˆå¤šç§æ¨¡å¼ï¼Œæ¯”å¦‚ Supervisor å’Œ Handoffã€‚\n\nç›®å‰æœ€å®ç”¨çš„ä¾ç„¶æ˜¯ç›‘ç£è€…æ¨¡å¼ï¼ˆSupervisorï¼‰ã€‚å®ƒçš„å·¥ä½œæµç¨‹æ˜¯è¿™æ ·çš„ï¼š\n\nä¸€ä¸ª Agent å……å½“ç›‘ç£è€…ï¼Œè´Ÿè´£å°†ä»»åŠ¡æ‹†è§£æˆå…·ä½“æ­¥éª¤ï¼Œäº¤ç»™ å·¥å…·èŠ‚ç‚¹ æˆ– å·¥å…· Agent æ‰§è¡Œ\n\nå·¥ä½œèŠ‚ç‚¹å°†æ‰§è¡Œç»“æœè¿”å›ç»™ç›‘ç£è€…ï¼Œå†ç”±ç›‘ç£è€…æ±‡æ€»ç»“æœï¼Œè¿”å›ç»™ç”¨æˆ·\n\næ‰§è¡Œæµç¨‹å¦‚ä¸‹ï¼šflowchart LR\n    A[ç”¨æˆ·] --> B[Supervisor]\n    B -.-> C[å·¥å…·èŠ‚ç‚¹]\n    B -.-> D[å·¥å…·Agent 1]\n    B -.-> E[å·¥å…·Agent 2]\n    C -.-> B\n    D -.-> B\n    E -.-> B\n    B --> F[AIå›å¤]\n\nåœ¨ LangGraph ä¸­ï¼Œæœ‰ä¸¤ç§å®ç°ç›‘ç£è€…æ¨¡å¼çš„å…·ä½“æ–¹æ³•ï¼š\n\nä½¿ç”¨ LangChain çš„ \n\ntool-calling å®ç°\n\nä½¿ç”¨ \n\nlanggraphâ€‹-supervisor åŒ…å®ç°\n\nä¸‹é¢æˆ‘å°†ä¾æ¬¡å®ç°ä¸¤ç§æ–¹æ³•ã€‚\n\nimport os\n\nfrom dotenv import load_dotenv\nfrom langchain_openai import ChatOpenAI\nfrom langchain.agents import create_agent\nfrom langchain.agents.middleware import dynamic_prompt, ModelRequest\nfrom langchain_core.tools import tool\nfrom langgraph_supervisor import create_supervisor\n\n# åŠ è½½æ¨¡å‹é…ç½®\n_ = load_dotenv()\n\n# åŠ è½½æ¨¡å‹\nllm = ChatOpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n    model=\"qwen3-coder-plus\",\n    temperature=0.7,\n)\n\n@tool\ndef add(a: float, b: float) -> float:\n    \"\"\"Add two numbers.\"\"\"\n    return a + b\n\n@tool\ndef multiply(a: float, b: float) -> float:\n    \"\"\"Multiply two numbers.\"\"\"\n    return a * b\n\n@tool\ndef divide(a: float, b: float) -> float:\n    \"\"\"Divide two numbers.\"\"\"\n    return a / b\n\n\n\n","type":"content","url":"/supervisor","position":1},{"hierarchy":{"lvl1":"ç›‘ç£è€…æ¨¡å¼","lvl2":"ä¸€ã€ä½¿ç”¨ tool-calling åŠŸèƒ½å®ç°"},"type":"lvl2","url":"/supervisor#id-tool-calling","position":2},{"hierarchy":{"lvl1":"ç›‘ç£è€…æ¨¡å¼","lvl2":"ä¸€ã€ä½¿ç”¨ tool-calling åŠŸèƒ½å®ç°"},"content":"æˆ‘ä»¬é¦–å…ˆä½¿ç”¨ create_agent åˆ›å»º subagent1 å’Œ subagent2ï¼Œåˆ†åˆ«ç”¨äºè®¡ç®— ä¸¤æ•°ç›¸åŠ  å’Œ ä¸¤æ•°ç›¸ä¹˜ã€‚ç„¶åä½¿ç”¨ @tool è£…é¥°å™¨åŒ…è£…ä¸¤ä¸ª Agentï¼Œåšæˆ call_subagent1 å’Œ call_subagent2ä¸¤ä¸ªå·¥å…·ï¼Œå®ƒä»¬ä»…ä¼ å‡º Agent çš„æœ€åä¸€æ¡ä¿¡æ¯ã€‚\n\n# åˆ›å»ºsubagent1ï¼šç”¨äºè®¡ç®—ä¸¤æ•°ç›¸åŠ \nsubagent1 = create_agent(\n    model=llm,\n    tools=[add],\n    name=\"subagent-1\",\n)\n\n@tool(\n    \"subagent-1\",\n    description=\"å¯ä»¥å‡†ç¡®åœ°è®¡ç®—ä¸¤æ•°ç›¸åŠ \"\n)\ndef call_subagent1(query: str):\n    result = subagent1.invoke({\n        \"messages\": [{\"role\": \"user\", \"content\": query}]\n    })\n    return result[\"messages\"][-1].content\n\n# åˆ›å»ºsubagent2ï¼šç”¨äºè®¡ç®—ä¸¤æ•°ç›¸ä¹˜\nsubagent2 = create_agent(\n    model=llm,\n    tools=[multiply],\n    name=\"subagent-2\",\n)\n\n@tool(\n    \"subagent-2\",\n    description=\"å¯ä»¥å‡†ç¡®åœ°è®¡ç®—ä¸¤æ•°ç›¸ä¹˜\"\n)\ndef call_subagent2(query: str):\n    result = subagent2.invoke({\n        \"messages\": [{\"role\": \"user\", \"content\": query}]\n    })\n    return result[\"messages\"][-1].content\n\n\n\nç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥å°† call_subagent1ã€call_subagent2ã€divide ä½œä¸ºå·¥å…·ï¼Œç›´æ¥ä¼ å…¥ supervisor_agent.\n\n# åˆ›å»ºsupervisor agent\nsupervisor_agent = create_agent(\n    model=llm,\n    tools=[call_subagent1, call_subagent2, divide],\n    name=\"supervisor-agent\",\n    system_prompt=\"æç¤ºï¼šå¦‚é‡ä¸¤æ•°ç›¸å‡ä»å¯ç”¨ä¸¤æ•°ç›¸åŠ å·¥å…·å®ç°ï¼Œåªéœ€å°†ä¸€ä¸ªæ•°åŠ ä¸Šå¦ä¸€ä¸ªæ•°çš„è´Ÿæ•°\",\n)\n\n\n\nä¸‹é¢ï¼Œæˆ‘ä»¬æ¥è®¡ç®— 38462 + 378 / 49 * 83723 - 123ï¼Œçœ‹å®ƒèƒ½å¦æ­£ç¡®åœ°ä½¿ç”¨æ‰€æœ‰å·¥å…·ã€‚\n\nresult = supervisor_agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"è®¡ç®— 38462 + 378 / 49 * 83723 - 123 çš„ç»“æœ\"}]}\n)\n\nfor message in result[\"messages\"]:\n    message.pretty_print()\n\n\n\n# éªŒè¯ç»“æœæ˜¯å¦æ­£ç¡®\n38462 + 378 / 49 * 83723 - 123\n\n\n\n","type":"content","url":"/supervisor#id-tool-calling","position":3},{"hierarchy":{"lvl1":"ç›‘ç£è€…æ¨¡å¼","lvl2":"äºŒã€ä½¿ç”¨ langgraph-supervisor åŒ…å®ç°"},"type":"lvl2","url":"/supervisor#id-langgraph-supervisor","position":4},{"hierarchy":{"lvl1":"ç›‘ç£è€…æ¨¡å¼","lvl2":"äºŒã€ä½¿ç”¨ langgraph-supervisor åŒ…å®ç°"},"content":"è¦ä½¿ç”¨ \n\nlanggraphâ€‹-supervisorï¼Œé¦–å…ˆéœ€è¦å®‰è£… langgraph-supervisor åŒ…ï¼špip install -U langgraph-supervisor\n\nlanggraph-supervisor æä¾›äº† create_supervisor å‡½æ•°ã€‚è¯¥å‡½æ•°æ¥å—å¤šä¸ª Agent ä½œä¸ºå…¥å‚ï¼Œå¹¶é€šè¿‡ supervisor è°ƒç”¨å®ƒä»¬ã€‚\n\nsubagent3 = create_agent(\n    model=llm,\n    tools=[divide],\n    name=\"subagent-3\",\n)\n\nsupervisor_graph = create_supervisor(\n    [subagent1, subagent2, subagent3],\n    model=llm,\n    prompt=\"æç¤ºï¼šå¦‚é‡ä¸¤æ•°ç›¸å‡ä»å¯ç”¨ä¸¤æ•°ç›¸åŠ å·¥å…·å®ç°ï¼Œåªéœ€å°†ä¸€ä¸ªæ•°åŠ ä¸Šå¦ä¸€ä¸ªæ•°çš„è´Ÿæ•°\"\n)\n\nsupervisor_app = supervisor_graph.compile()\n\n\n\nresult = supervisor_app.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"è®¡ç®— 38462 + 378 / 49 * 83723 - 123 çš„ç»“æœ\"}]}\n)\n\nfor message in result[\"messages\"]:\n    message.pretty_print()\n\n\n\n# éªŒè¯ç»“æœæ˜¯å¦æ­£ç¡®\n38462 + 378 / 49 * 83723 - 123\n\n\n\nåˆ«çœ‹ç°åœ¨å®ƒä»¬éƒ½ç®—å¯¹äº†ï¼Œå®é™…ä¸Šè¿™æ˜¯æˆ‘è¯•äº†å¥½å‡ éï¼Œå¹¶è°ƒæ•´äº† system prompt çš„ç»“æœã€‚ä½ å¤šæ¬¡å°è¯•åº”è¯¥ä¹Ÿèƒ½ roll å‡ºé”™è¯¯çš„ç»“æœã€‚æ‰€ä»¥æˆ‘å¯¹å¤šæ™ºèƒ½ä½“çš„æ•ˆæœä»æœ‰ç–‘è™‘ã€‚æˆ‘æ„Ÿè§‰ç°é˜¶æ®µå¤šæ™ºèƒ½ä½“æ˜¯ä¼šé™ä½å‡†ç¡®æ€§çš„ï¼Œèƒ½ä¸ç”¨å°±ä¸ç”¨ã€‚ä»€ä¹ˆæ—¶å€™åº”è¯¥ä½¿ç”¨å¤šæ™ºèƒ½ä½“å‘¢ï¼Ÿå¯ä»¥å‚è€ƒä»¥ä¸‹ LangGraph ç»™çš„ \n\nå»ºè®®ã€‚\n\nå¤šä»£ç†ç³»ç»Ÿåœ¨ä»¥ä¸‹æƒ…å†µä¸‹å¾ˆæœ‰ç”¨ï¼š\n\nå•ä¸ªä»£ç†æ‹¥æœ‰å¤ªå¤šå·¥å…·ï¼Œå¹¶ä¸”åœ¨ä½¿ç”¨å“ªä¸ªå·¥å…·æ–¹é¢åšå‡ºäº†é”™è¯¯çš„å†³å®šã€‚\n\nä¸Šä¸‹æ–‡æˆ–å†…å­˜å˜å¾—å¤ªå¤§ï¼Œä¸€ä¸ªä»£ç†æ— æ³•æœ‰æ•ˆè·Ÿè¸ªã€‚\n\nä»»åŠ¡éœ€è¦ä¸“ä¸šåŒ– ï¼ˆä¾‹å¦‚ï¼Œè§„åˆ’å¸ˆã€ç ”ç©¶äººå‘˜ã€æ•°å­¦ä¸“å®¶ï¼‰ã€‚","type":"content","url":"/supervisor#id-langgraph-supervisor","position":5},{"hierarchy":{"lvl1":"å¹¶è¡Œ"},"type":"lvl1","url":"/parallel","position":0},{"hierarchy":{"lvl1":"å¹¶è¡Œ"},"content":"æœ¬èŠ‚ä»‹ç»ä¸¤ç§å®ç°å¹¶è¡Œçš„æ–¹æ³•ï¼š\n\nèŠ‚ç‚¹å¹¶è¡Œ\n\nMap-reduce\n\nimport os\nimport time\nimport operator\n\nfrom dotenv import load_dotenv\nfrom typing import Annotated\nfrom datetime import datetime\nfrom pydantic import BaseModel\nfrom typing_extensions import TypedDict\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.messages import HumanMessage\nfrom langgraph.graph import StateGraph, MessagesState, START, END\nfrom langgraph.types import Send\n\n# åŠ è½½æ¨¡å‹é…ç½®\n_ = load_dotenv()\n\n# åŠ è½½æ¨¡å‹\nllm = ChatOpenAI(\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n    model=\"qwen3-max\",\n    temperature=0.7,\n)\n\n\n\n","type":"content","url":"/parallel","position":1},{"hierarchy":{"lvl1":"å¹¶è¡Œ","lvl2":"ä¸€ã€èŠ‚ç‚¹å¹¶è¡Œ"},"type":"lvl2","url":"/parallel#id","position":2},{"hierarchy":{"lvl1":"å¹¶è¡Œ","lvl2":"ä¸€ã€èŠ‚ç‚¹å¹¶è¡Œ"},"content":"èŠ‚ç‚¹å¹¶è¡Œå¾ˆå®¹æ˜“å®ç°ï¼Œä½¿ç”¨ StateGraph åˆ›å»ºå¸¦å¹¶è¡ŒèŠ‚ç‚¹çš„å·¥ä½œæµå°±å¯ä»¥ã€‚\n\nä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„èŠ‚ç‚¹å¹¶è¡Œçš„ä¾‹å­ã€‚ä½ å¯ä»¥è§‚å¯ŸèŠ‚ç‚¹è¿è¡Œçš„æ—¶é—´æˆ³ï¼Œç¡®è®¤å®ƒä»¬æ˜¯å¦çœŸçš„åœ¨å¹¶è¡Œã€‚\n\n# åˆ›å»ºå¹¶è¡ŒèŠ‚ç‚¹a\ndef node_a(state: MessagesState):\n    start_time = datetime.now()\n    print(f\"[node_a] è¿›å…¥å‡½æ•°æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]}\")\n\n    # ä½¿ç”¨ sleep æ¨¡æ‹Ÿå ç”¨æ—¶é—´\n    time.sleep(2)\n\n    end_time = datetime.now()\n    print(f\"[node_a] é€€å‡ºå‡½æ•°æ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]}\")\n\n    return {'messages': [HumanMessage(\n        content=f'èŠ‚ç‚¹aè¿è¡Œäº†{round((end_time - start_time).total_seconds(), 3)}ç§’'\n    )]}\n\n# åˆ›å»ºå¹¶è¡ŒèŠ‚ç‚¹b\ndef node_b(state: MessagesState):\n    start_time = datetime.now()\n    print(f\"[node_b] è¿›å…¥å‡½æ•°æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]}\")\n\n    # ä½¿ç”¨ sleep æ¨¡æ‹Ÿå ç”¨æ—¶é—´\n    time.sleep(4)\n\n    end_time = datetime.now()\n    print(f\"[node_b] é€€å‡ºå‡½æ•°æ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]}\")\n\n    return {'messages': [HumanMessage(\n        content=f'èŠ‚ç‚¹bè¿è¡Œäº†{round((end_time - start_time).total_seconds(), 3)}ç§’'\n    )]}\n\n# åˆ›å»ºå›¾\nbuilder = StateGraph(MessagesState)\n\n# æ·»åŠ èŠ‚ç‚¹\nbuilder.add_node('node_a', node_a)\nbuilder.add_node('node_b', node_b)\n\n# æ·»åŠ è¾¹\nbuilder.add_edge(START, 'node_a')\nbuilder.add_edge(START, 'node_b')\nbuilder.add_edge('node_a', END)\nbuilder.add_edge('node_b', END)\n\n# ç¼–è¯‘å›¾\nmy_graph = builder.compile(name='my-graph')\nmy_graph\n\n\n\n# è°ƒç”¨å›¾\nresponse = my_graph.invoke({\n    'messages': [HumanMessage(content='æ‰§è¡Œ node_a å’Œ node_b')]\n})\n\nfor message in response['messages']:\n    message.pretty_print()\n\n\n\nNote\n\n\n\nè‹¥æƒ³äº†è§£å…³äºèŠ‚ç‚¹æ‰§è¡Œé¡ºåºçš„ç»†èŠ‚ï¼Œæ¨èé˜…è¯» \n\nparallelizationâ€‹.ipynb.","type":"content","url":"/parallel#id","position":3},{"hierarchy":{"lvl1":"å¹¶è¡Œ","lvl2":"äºŒã€Map-reduce"},"type":"lvl2","url":"/parallel#id-map-reduce","position":4},{"hierarchy":{"lvl1":"å¹¶è¡Œ","lvl2":"äºŒã€Map-reduce"},"content":"å­¦è¿‡ \n\nHadoop çš„äººéƒ½çŸ¥é“ï¼Œmap-reduce æ˜¯ä¸€ä¸ªã€Œå…ˆå¹¶è¡Œï¼Œåå½’çº¦ã€çš„è¿‡ç¨‹ã€‚è¿™ä¸ªæ¦‚å¿µè¢«å€Ÿé‰´åˆ° Agent è¿™é‡Œï¼Œå˜æˆäº†ã€Œå…ˆå‘æ•£ï¼Œåæ”¶æ•›ã€ã€‚å€Ÿé‰´è¿‡æ¥ä¹‹åï¼Œå®ƒçš„å†…æ¶µå…¶å®å˜ç®€å•äº†ï¼Œç®€å•åˆ°ä¸ç”¨ LangGraph ä¹Ÿèƒ½å®ç°ã€‚é‚£ä¸ºä»€ä¹ˆè¿˜è¦ç”¨ LangGraph å‘¢ï¼Ÿå½“ç„¶æ˜¯å› ä¸ºç”¨ LangGraph å†™çš„ map-reduce æ›´æ ‡å‡†åŒ–ï¼Œå¯è¯»æ€§ä¹Ÿæ›´å¼ºä¸€äº›ã€‚\n\nNote\n\n\nğŸ™† å…«å¦çš„å¿ƒï¼Œå°±æ˜¯çˆ±ï¼ˆç¼–ç¨‹ï¼‰çš„é­”æ³•ã€‚\n\nä¸‹é¢æˆ‘ä»¬æ¥è§£å†³ä¸€ä¸ªéå¸¸å®é™…çš„é—®é¢˜ï¼šå¥³ç¥ä¸å›æ¶ˆæ¯æ€ä¹ˆåŠï¼ï¼ï¼\n\næˆ‘ä»¬ä»ä»¥ä¸‹å‡ ç§ç±»å‹çš„ç”·ç”Ÿå…¥æ‰‹ï¼š\n\nç”·ç¥\n\næš–ç”·\n\næµ·ç‹\n\nç—´æƒ…ç”·\n\nå†³ç»çš„ç”·ç”Ÿ\n\nèŒ¶èŒ¶çš„ç”·ç”Ÿ ğŸ’…ğŸ’…ğŸ’…\n\nç†æƒ³ä¸»ä¹‰çš„ç”·ç”Ÿ\n\nå–œæ¬¢å”å˜˜çš„ç”·ç”Ÿ\n\nå¤§ç”·å­ä¸»ä¹‰çš„ç”·ç”Ÿ\n\näºŒæ¬¡å…ƒè‚¥å®…\n\nä½ ä¸€å®šéå¸¸å¥½å¥‡ï¼Œä»–ä»¬ä¼šå¦‚ä½•åº”å¯¹ã€‚ä¸‹é¢æˆ‘ä»¬æ¥æ­ç§˜ã€‚\n\n1ï¼‰åˆ›å»ºä¸Šä¸‹æ–‡çš„ schema\n\n# è§’è‰²\nclass Roles(BaseModel):\n    roles: list[str]\n\n# å•ä¸ªè§’è‰²\nclass Role(BaseModel):\n    role: str\n\n# å•ä¸ªå›å¤\nclass Response(BaseModel):\n    response: str\n\n# æœ€ä½³å›å¤çš„ ID\nclass BestResponse(BaseModel):\n    id: int\n\n# å…¨å±€ä¸Šä¸‹æ–‡\nclass Overall(TypedDict):\n    roles: list[str]\n    responses: Annotated[list, operator.add]\n    best_response: str\n\n\n\n2ï¼‰åˆ›å»ºæç¤ºè¯æ¨¡ç‰ˆ\n\n# è§’è‰²çš„æç¤ºè¯\nrole_prompt = \"å¥³ç¥åˆä¸å›ä½ æ¶ˆæ¯äº†ï¼Œä½œä¸ºä¸€ä¸ª{role}ï¼Œä½ åº”è¯¥å¦‚ä½•ä¸€å¥è¯å›å¤å¥³ç¥ï¼Ÿè¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«responseå­—æ®µ\"\n\n# æœ€ä½³å›å¤çš„æç¤ºè¯\nbest_response_prompt = \"\"\"ä¸‹é¢æ˜¯å‡ ç§ç±»å‹çš„ç”·ç”Ÿï¼Œé¢å¯¹å¥³ç¥ä¸å›æ¶ˆæ¯çš„æƒ…å†µï¼Œåšå‡ºçš„ååº”ã€‚\nä½ è§‰å¾—ä»¥ä¸‹å“ªç§å›å¤æœ€èƒ½æŒ½å›å¥³ç¥çš„å¿ƒï¼Œè¯·è¿”å›å¯¹åº”çš„IDã€‚\næ³¨æ„å“¦ï¼Œç¬¬ä¸€æ¡ååº”å¯¹åº”çš„æ˜¯0å·IDã€‚å¹¶ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«idå­—æ®µ\nä¸‹é¢æ˜¯ç”·ç”Ÿä»¬çš„ååº”ï¼š\\n\\n{responses}\"\"\"\n\n\n\n3ï¼‰åˆ›å»ºèŠ‚ç‚¹\n\nè¿™é‡Œçš„é­”æ³•åœ¨äºæˆ‘ä»¬ä½¿ç”¨ \n\nSend å‡½æ•°ï¼Œå°†è§’è‰²åˆ†å‘ç»™ generate_response èŠ‚ç‚¹è¿›è¡Œè§’è‰²å›å¤ç”Ÿæˆã€‚\n\n# ä½¿ç”¨ Send å‡½æ•°åˆ†å‘è§’è‰²\ndef continue_to_responses(state: Overall):\n    return [ Send(\"generate_response\", {\"role\": r}) for r in state[\"roles\"] ]\n\n# è§’è‰²å›å¤èŠ‚ç‚¹ï¼šç”Ÿæˆæ¯ä¸ªè§’è‰²çš„å›å¤\ndef generate_response(state: Role):\n    prompt = role_prompt.format(role=state[\"role\"])\n    response = llm.with_structured_output(Response).invoke(prompt)\n    return {\"responses\": [response.response]}\n\n# æœ€ä½³å›å¤èŠ‚ç‚¹ï¼šè¿”å›æœ€ä½³å›å¤\ndef best_response(state: Overall):\n    responses = \"\\n\\n\".join(state[\"responses\"])\n    prompt = best_response_prompt.format(responses=responses)\n    response = llm.with_structured_output(BestResponse).invoke(prompt)\n    return {\"best_response\": state[\"responses\"][response.id]}\n\n\n\nNote\n\n\næˆ‘ä»¬å…è®¸ generate_response èŠ‚ç‚¹çš„ state çš„ schema ä¸ä¸Šæ¸¸èŠ‚ç‚¹ä¸åŒã€‚å› ä¸º generate_response èŠ‚ç‚¹æ˜¯å¹¶è¡Œæ‰§è¡Œçš„ï¼Œæ‰€ä»¥è¿™ä¸ª schema æ˜¯ç‰¹æ®Šçš„ï¼Œä¸éœ€è¦ä¸å…¨å±€ schemaï¼ˆOverallï¼‰ç›¸åŒã€‚\n\n4ï¼‰ç¼–è¯‘å›¾\n\n# åˆ›å»ºå›¾\nbuilder = StateGraph(Overall)\n\n# æ·»åŠ èŠ‚ç‚¹\nbuilder.add_node(\"generate_response\", generate_response)\nbuilder.add_node(\"best_response\", best_response)\n\n# æ·»åŠ è¾¹\nbuilder.add_conditional_edges(START, continue_to_responses, [\"generate_response\"])\nbuilder.add_edge(\"generate_response\", \"best_response\")\nbuilder.add_edge(\"best_response\", END)\n\n# ç¼–è¯‘å›¾\nmy_graph = builder.compile(name='best-response')\nmy_graph\n\n\n\n# è°ƒç”¨å›¾\nroles = [\"ç”·ç¥\", \"æš–ç”·\", \"æµ·ç‹\", \"ç—´æƒ…ç”·\", \"å†³ç»çš„ç”·ç”Ÿ\", \"èŒ¶èŒ¶çš„ç”·ç”Ÿ ğŸ’…ğŸ’…ğŸ’…\",\n         \"ç†æƒ³ä¸»ä¹‰çš„ç”·ç”Ÿ\", \"å–œæ¬¢å”å˜˜çš„ç”·ç”Ÿ\", \"å¤§ç”·å­ä¸»ä¹‰çš„ç”·ç”Ÿ\", \"äºŒæ¬¡å…ƒè‚¥å®…\"]\nresponse = my_graph.invoke({\"roles\": roles})\n\n\n\nfor role, resp in zip(roles, response[\"responses\"]):\n    print(f\"ã€{role}ã€‘\")\n    print(resp)\n    print()\n\n\n\nprint(\"æœ€ä½³å›å¤ï¼š\", response[\"best_response\"])\n\n\n\nNote\n\n\næ„Ÿè§‰ LangGraph æŠŠå¹¶è¡Œå†™å¤æ‚äº†ã€‚ç”¨ \n\nmultiprocessing å†™ä¸€ä¸ª toolï¼Œä¹Ÿè®¸ä¼šæ›´ç®€å•ã€‚","type":"content","url":"/parallel#id-map-reduce","position":5},{"hierarchy":{"lvl1":"é¦–é¡µ"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"é¦–é¡µ"},"content":"\n\nğŸ“–ã€ŠLangGraph 1.0 å®Œå…¨æŒ‡å— Plusç‰ˆã€‹\n\nä»é›¶å¼€å§‹ï¼ŒåŠ¨æ‰‹å®ç°å¼ºå¤§çš„æ™ºèƒ½ä½“\n\næœ¬æ•™ç¨‹åŸºäºLuoChangå¤§ä½¬çš„Dive-Into-Langgraphå…¥é—¨æ•™ç¨‹ï¼ŒåŠ å…¥å¼€å‘æ¡ˆä¾‹(Cases)ã€ä»¥åŠå•†ä¸šè§£å†³æ–¹æ¡ˆ(Solutions)ï¼Œä½œä¸ºè¿›é˜¶æ•™ç¨‹ä½¿ç”¨","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"é¦–é¡µ","lvl2":"ä¸€ã€é¡¹ç›®ä»‹ç»"},"type":"lvl2","url":"/#id","position":2},{"hierarchy":{"lvl1":"é¦–é¡µ","lvl2":"ä¸€ã€é¡¹ç›®ä»‹ç»"},"content":"2025 å¹´ 10 æœˆä¸­æ—¬ï¼ŒLangGraph å‘å¸ƒ 1.0 ç‰ˆæœ¬ã€‚å¼€å‘å›¢é˜Ÿæ‰¿è¯ºè¿™æ˜¯ä¸€ä¸ªç¨³å®šç‰ˆæœ¬ï¼Œé¢„è®¡æœªæ¥æ¥å£ä¸ä¼šå¤§æ”¹ï¼Œå› æ­¤ç°åœ¨æ­£æ˜¯å­¦ä¹ å®ƒçš„å¥½æ—¶æœºã€‚\n\nè¿™æ˜¯ä¸€ä¸ªå¼€æºç”µå­ä¹¦é¡¹ç›®ï¼Œæ—¨åœ¨å¸®åŠ© Agent å¼€å‘è€…å¿«é€ŸæŒæ¡ LangGraph æ¡†æ¶ã€‚\n\nLangGraph æ˜¯ç”± LangChain å›¢é˜Ÿå¼€å‘çš„å¼€æºæ™ºèƒ½ä½“æ¡†æ¶ã€‚å®ƒåŠŸèƒ½å¼ºå¤§ï¼Œä½ è¦çš„è®°å¿†ã€MCPã€æŠ¤æ ã€çŠ¶æ€ç®¡ç†ã€å¤šæ™ºèƒ½ä½“å®ƒå…¨éƒ½æœ‰ã€‚LangGraph é€šå¸¸ä¸ \n\nLangChain ä¸€èµ·ä½¿ç”¨ï¼šLangChain æä¾›åŸºç¡€ç»„ä»¶å’Œå·¥å…·ï¼ŒLangGraph è´Ÿè´£å·¥ä½œæµå’ŒçŠ¶æ€ç®¡ç†ã€‚å› æ­¤ï¼Œä¸¤ä¸ªåº“éƒ½éœ€è¦å­¦ä¹ ã€‚ä¸ºäº†è®©å¤§å®¶å¿«é€Ÿå…¥é—¨ï¼Œæœ¬æ•™ç¨‹å°†ä¸¤ä¸ªåº“çš„ä¸»è¦åŠŸèƒ½æå–å‡ºæ¥ï¼Œåˆ†æˆ 14 ä¸ªç« èŠ‚è¿›è¡Œä»‹ç»ã€‚","type":"content","url":"/#id","position":3},{"hierarchy":{"lvl1":"é¦–é¡µ","lvl2":"äºŒã€å®‰è£…ä¾èµ–"},"type":"lvl2","url":"/#id-1","position":4},{"hierarchy":{"lvl1":"é¦–é¡µ","lvl2":"äºŒã€å®‰è£…ä¾èµ–"},"content":"pip install -r requirements.txt\n\nä¾èµ–åŒ…åˆ—è¡¨\n\nä»¥ä¸‹ä¸º requirements.txt ä¸­çš„ä¾èµ–åŒ…æ¸…å•ï¼špydantic\npython-dotenv\nlangchain[openai]\nlangchain-community\nlangchain-mcp-adapters\nlangchain-text-splitters\nlanggraph\nlanggraph-cli[inmem]\nlanggraph-supervisor\nlanggraph-checkpoint-sqlite\nlangmem\nipynbname\nfastmcp\nbs4","type":"content","url":"/#id-1","position":5},{"hierarchy":{"lvl1":"é¦–é¡µ","lvl2":"ä¸‰ã€ç« èŠ‚ç›®å½•"},"type":"lvl2","url":"/#id-2","position":6},{"hierarchy":{"lvl1":"é¦–é¡µ","lvl2":"ä¸‰ã€ç« èŠ‚ç›®å½•"},"content":"æœ¬æ•™ç¨‹çš„å†…å®¹é€Ÿè§ˆï¼š\n\nåºå·\n\nç« èŠ‚\n\nä¸»è¦å†…å®¹\n\n0\n\nAIæ¡†æ¶è¯¦è§£\n\nä»‹ç»å½“ä¸‹ä¸»æµçš„AIæ¡†æ¶åŠå…¶ç‰¹ç‚¹\n\n1\n\nå¿«é€Ÿå…¥é—¨\n\nåˆ›å»ºä½ çš„ç¬¬ä¸€ä¸ª ReAct Agent\n\n2\n\nçŠ¶æ€å›¾\n\nä½¿ç”¨ StateGraph åˆ›å»ºå·¥ä½œæµ\n\n3\n\nä¸­é—´ä»¶\n\nä½¿ç”¨è‡ªå®šä¹‰ä¸­é—´ä»¶å®ç°å››ä¸ªåŠŸèƒ½ï¼šé¢„ç®—æ§åˆ¶ã€æ¶ˆæ¯æˆªæ–­ã€æ•æ„Ÿè¯è¿‡æ»¤ã€PII æ£€æµ‹\n\n4\n\näººæœºäº¤äº’\n\nä½¿ç”¨å†…ç½®çš„ HITL ä¸­é—´ä»¶å®ç°äººæœºäº¤äº’\n\n5\n\nè®°å¿†\n\nåˆ›å»ºçŸ­æœŸè®°å¿†ã€é•¿æœŸè®°å¿†\n\n6\n\nä¸Šä¸‹æ–‡å·¥ç¨‹\n\nä½¿ç”¨ Stateã€Storeã€Runtime ç®¡ç†ä¸Šä¸‹æ–‡\n\n7\n\nMCP Server\n\nåˆ›å»º MCP Server å¹¶æ¥å…¥ LangGraph\n\n8\n\nç›‘ç£è€…æ¨¡å¼\n\nä¸¤ç§æ–¹æ³•å®ç°ç›‘ç£è€…æ¨¡å¼ï¼štool-callingã€langgraph-supervisor\n\n9\n\nå¹¶è¡Œ\n\nå¦‚ä½•å®ç°å¹¶è¡Œï¼šèŠ‚ç‚¹å¹¶è¡Œã€Map-reduce\n\n10\n\nDeep Agents\n\nç®€å•ä»‹ç» Deep Agents\n\n11\n\nè°ƒè¯•é¡µé¢\n\nä»‹ç» langgraph-cli æä¾›çš„è°ƒè¯•é¡µé¢\n\n12\n\nå¼€å‘æ¡ˆä¾‹\n\nä»‹ç» å¸¸è§çš„æ ¸å¿ƒå¼€å‘æ¡ˆä¾‹\n\n13\n\nå•†ä¸šæ¡ˆä¾‹\n\nä»‹ç» å¸¸è§çš„å•†ä¸šæ¡ˆä¾‹\n\næœªå‡ºç°åœ¨ä¸Šè¿°ç« èŠ‚ä½†æ¯”è¾ƒé‡è¦çš„ä»£ç ï¼Œæˆ‘æ”¾åœ¨ä»“åº“çš„ tests ç›®å½•ä¸‹ï¼š\n\nä»£ç \n\nè¯´æ˜\n\n/tests/test_rag.py\n\nä½¿ç”¨ RAG å°†æœ¬åœ°æ–‡æ¡£ç‰‡æ®µæ³¨å…¥æ™ºèƒ½ä½“\n\nâ€‹/testsâ€‹/testâ€‹_langmemâ€‹.py\n\nä½¿ç”¨ LangMem ç®¡ç†æ™ºèƒ½ä½“é•¿æœŸè®°å¿†\n\nâ€‹/testsâ€‹/testâ€‹_storeâ€‹.py\n\nä½¿ç”¨ RedisStore å¿«é€Ÿè¯»å†™é•¿æœŸè®°å¿†\n\nâ€‹/testsâ€‹/testâ€‹_routerâ€‹.py\n\nå®ç°ä¸€ä¸ªç®€å•çš„æ™ºèƒ½ä½“è·¯ç”±\n\nNote\n\n\n\næ‰¿è¯ºï¼šæœ¬æ•™ç¨‹å®Œå…¨åŸºäº LangGraph v1.0 ç¼–å†™ï¼Œä¸å«ä»»ä½• v0.6 çš„å†å²æ®‹ç•™ã€‚","type":"content","url":"/#id-2","position":7},{"hierarchy":{"lvl1":"é¦–é¡µ","lvl2":"å››ã€è°ƒè¯•é¡µé¢"},"type":"lvl2","url":"/#id-3","position":8},{"hierarchy":{"lvl1":"é¦–é¡µ","lvl2":"å››ã€è°ƒè¯•é¡µé¢"},"content":"langgraph-cli æä¾›äº†ä¸€ä¸ªå¯å¿«é€Ÿå¯åŠ¨çš„è°ƒè¯•é¡µé¢ã€‚langgraph dev\n\nè¯¦è§ \n\nç¬¬11ç« ","type":"content","url":"/#id-3","position":9},{"hierarchy":{"lvl1":"é¦–é¡µ","lvl2":"äº”ã€å»¶ä¼¸é˜…è¯»"},"type":"lvl2","url":"/#id-4","position":10},{"hierarchy":{"lvl1":"é¦–é¡µ","lvl2":"äº”ã€å»¶ä¼¸é˜…è¯»"},"content":"å®˜æ–¹æ–‡æ¡£ï¼š\n\nLangChain\n\nLangGraph\n\nDeep Agents\n\nLangMem\n\nå®˜æ–¹æ•™ç¨‹ï¼š\n\nlanggraph-101\n\nlangchain-academy","type":"content","url":"/#id-4","position":11},{"hierarchy":{"lvl1":"é¦–é¡µ","lvl2":"å…­ã€å¦‚ä½•è´¡çŒ®"},"type":"lvl2","url":"/#id-5","position":12},{"hierarchy":{"lvl1":"é¦–é¡µ","lvl2":"å…­ã€å¦‚ä½•è´¡çŒ®"},"content":"æˆ‘ä»¬æ¬¢è¿ä»»ä½•å½¢å¼çš„è´¡çŒ®ï¼\n\nğŸ› æŠ¥å‘Š Bug - å‘ç°é—®é¢˜è¯·æäº¤ Issue\n\nğŸ’¡ åŠŸèƒ½å»ºè®® - æœ‰å¥½æƒ³æ³•å°±å‘Šè¯‰æˆ‘ä»¬\n\nğŸ“ å†…å®¹å®Œå–„ - å¸®åŠ©æ”¹è¿›æ•™ç¨‹å†…å®¹\n\nğŸ”§ ä»£ç ä¼˜åŒ– - æäº¤ Pull Request","type":"content","url":"/#id-5","position":13},{"hierarchy":{"lvl1":"é¦–é¡µ","lvl2":"ä¸ƒã€å¼€æºåè®®"},"type":"lvl2","url":"/#id-6","position":14},{"hierarchy":{"lvl1":"é¦–é¡µ","lvl2":"ä¸ƒã€å¼€æºåè®®"},"content":"æœ¬ä½œå“é‡‡ç”¨ \n\nçŸ¥è¯†å…±äº«ç½²å-éå•†ä¸šæ€§ä½¿ç”¨-ç›¸åŒæ–¹å¼å…±äº« 4.0 å›½é™…è®¸å¯åè®® è¿›è¡Œè®¸å¯ã€‚","type":"content","url":"/#id-6","position":15}]}